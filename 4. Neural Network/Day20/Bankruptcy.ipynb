{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bankruptcy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2-3coQI85Iu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I00mHx_s-WLO",
        "outputId": "deae27bc-e8ed-46ac-c63a-5c2bf0525f09"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF9qcqr5jdgJ"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "AhRAG4HOjdgP",
        "outputId": "9fcfa19c-4971-4068-be16-b04698300f1f"
      },
      "source": [
        "df = pd.read_csv(\"/content/Bankruptcy/Bankruptcy.csv\")\n",
        "df.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c7a1dc84-aeb4-4bd2-b2ac-db0da22ad198\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NO</th>\n",
              "      <th>D</th>\n",
              "      <th>YR</th>\n",
              "      <th>R1</th>\n",
              "      <th>R2</th>\n",
              "      <th>R3</th>\n",
              "      <th>R4</th>\n",
              "      <th>R5</th>\n",
              "      <th>R6</th>\n",
              "      <th>R7</th>\n",
              "      <th>R8</th>\n",
              "      <th>R9</th>\n",
              "      <th>R10</th>\n",
              "      <th>R11</th>\n",
              "      <th>R12</th>\n",
              "      <th>R13</th>\n",
              "      <th>R14</th>\n",
              "      <th>R15</th>\n",
              "      <th>R16</th>\n",
              "      <th>R17</th>\n",
              "      <th>R18</th>\n",
              "      <th>R19</th>\n",
              "      <th>R20</th>\n",
              "      <th>R21</th>\n",
              "      <th>R22</th>\n",
              "      <th>R23</th>\n",
              "      <th>R24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.19</td>\n",
              "      <td>10.36</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.23</td>\n",
              "      <td>3.56</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.55</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3.13</td>\n",
              "      <td>1.73</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.22</td>\n",
              "      <td>3.78</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.14</td>\n",
              "      <td>2.41</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.70</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>13.29</td>\n",
              "      <td>1.61</td>\n",
              "      <td>1.43</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>5.55</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.57</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>5.36</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.12</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>81</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>2.85</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.14</td>\n",
              "      <td>7.74</td>\n",
              "      <td>1.48</td>\n",
              "      <td>1.41</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7a1dc84-aeb4-4bd2-b2ac-db0da22ad198')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7a1dc84-aeb4-4bd2-b2ac-db0da22ad198 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7a1dc84-aeb4-4bd2-b2ac-db0da22ad198');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   NO  D  YR    R1    R2    R3    R4  ...   R18    R19   R20   R21   R22   R23   R24\n",
              "0   1  0  78  0.23  0.08  0.02  0.03  ...  0.23   3.56  0.26  1.55  0.43  0.11  0.17\n",
              "1   2  0  77  0.19  0.07  0.09  0.12  ...  0.22   3.78  1.29  1.40  0.06  0.07  0.10\n",
              "2   3  0  72  0.07  0.02  0.03  0.05  ...  0.04  13.29  1.61  1.43  0.03  0.05  0.07\n",
              "3   4  0  80  0.07  0.03  0.04  0.04  ...  0.02   5.36  1.30  1.12 -0.06 -0.08 -0.09\n",
              "4   5  0  81  0.09  0.02  0.03  0.04  ...  0.14   7.74  1.48  1.41  0.03  0.04  0.06\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqgTp3udjdgR"
      },
      "source": [
        "F = df.iloc[:,2:]\n",
        "R = df.iloc[:,1]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RADzEKkGjdgX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(F, R, test_size = 0.3, \n",
        "                                                    random_state=2022)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WI-wuVWjdgW"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)    \n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix1ZTq5sjdgY",
        "outputId": "463ebfb8-091b-4172-a69e-471858ce86e8"
      },
      "source": [
        "(X_train.shape, y_train.shape)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((92, 25), (92,))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Qj2rtyjdgZ"
      },
      "source": [
        "y_train = y_train.values\n",
        "y_test = y_test.values"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwDSbKZujdga"
      },
      "source": [
        "tf.random.set_seed(2022)\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu',input_shape=(X_train.shape[1], )), \n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  \n",
        "])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G7P06usjdgb",
        "outputId": "7c9dd725-7606-4500-9001-87205c781bb2"
      },
      "source": [
        "model.variables"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_6/kernel:0' shape=(25, 4) dtype=float32, numpy=\n",
              " array([[ 0.3820122 ,  0.16050118,  0.13587916, -0.07003993],\n",
              "        [-0.15152404, -0.15846062, -0.44167703, -0.24456531],\n",
              "        [-0.36062834,  0.02690488,  0.24716502,  0.29377836],\n",
              "        [-0.14357641, -0.00478956,  0.03873882,  0.27581936],\n",
              "        [-0.33692977,  0.1618653 , -0.12802416,  0.24038684],\n",
              "        [-0.35439783, -0.14032084, -0.43976   , -0.42288655],\n",
              "        [-0.2912249 ,  0.1945647 , -0.37005356,  0.18720293],\n",
              "        [-0.33734742, -0.30571812, -0.3245712 , -0.27869993],\n",
              "        [-0.09670699, -0.10394484,  0.39573193, -0.2890197 ],\n",
              "        [ 0.02781597,  0.10465288, -0.3708643 ,  0.01806441],\n",
              "        [ 0.20667648,  0.07320833, -0.44461268,  0.27636743],\n",
              "        [-0.06245387, -0.04011968, -0.09619015, -0.20942259],\n",
              "        [ 0.11516517, -0.06896695, -0.42879713, -0.05849329],\n",
              "        [ 0.08304358,  0.08436054,  0.25364447,  0.07343835],\n",
              "        [ 0.10485309, -0.04102618, -0.25887692, -0.3569521 ],\n",
              "        [ 0.31039244,  0.03780389,  0.4035254 , -0.00343007],\n",
              "        [ 0.41672057,  0.08347434,  0.16953814, -0.22230564],\n",
              "        [ 0.07549179,  0.39720714, -0.05747116, -0.253285  ],\n",
              "        [ 0.11098599,  0.21597135, -0.08410558,  0.4235546 ],\n",
              "        [ 0.30666143, -0.12645006, -0.45227888,  0.15202063],\n",
              "        [-0.3251285 , -0.24447346, -0.35514417,  0.27853465],\n",
              "        [ 0.44852644,  0.34962773, -0.42284143,  0.2828018 ],\n",
              "        [ 0.19243908, -0.15325475, -0.32974744, -0.34403747],\n",
              "        [-0.11793783,  0.05257219,  0.35433984,  0.29475558],\n",
              "        [-0.2224272 ,  0.04081959, -0.0477308 , -0.17359903]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_6/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_7/kernel:0' shape=(4, 1) dtype=float32, numpy=\n",
              " array([[ 0.6282985 ],\n",
              "        [ 1.0695803 ],\n",
              "        [ 0.15678167],\n",
              "        [-0.12659544]], dtype=float32)>,\n",
              " <tf.Variable 'dense_7/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJmecj6kjdgc"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bUMljUFjdgc",
        "outputId": "1ad11f09-b398-4c38-e2d3-63b8845f0d21"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 4)                 104       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109\n",
            "Trainable params: 109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcS2vR2Ijdgd",
        "outputId": "194030be-ea0f-49f9-932e-bd14ed452c99"
      },
      "source": [
        "history = model.fit( X_train,y_train,validation_data=(X_test,y_test),verbose=2,epochs=500)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "3/3 - 1s - loss: 0.6722 - accuracy: 0.5217 - val_loss: 0.6677 - val_accuracy: 0.5000 - 600ms/epoch - 200ms/step\n",
            "Epoch 2/500\n",
            "3/3 - 0s - loss: 0.6702 - accuracy: 0.5326 - val_loss: 0.6655 - val_accuracy: 0.5000 - 31ms/epoch - 10ms/step\n",
            "Epoch 3/500\n",
            "3/3 - 0s - loss: 0.6686 - accuracy: 0.5326 - val_loss: 0.6634 - val_accuracy: 0.5000 - 37ms/epoch - 12ms/step\n",
            "Epoch 4/500\n",
            "3/3 - 0s - loss: 0.6671 - accuracy: 0.5326 - val_loss: 0.6615 - val_accuracy: 0.5000 - 28ms/epoch - 9ms/step\n",
            "Epoch 5/500\n",
            "3/3 - 0s - loss: 0.6654 - accuracy: 0.5326 - val_loss: 0.6599 - val_accuracy: 0.5000 - 28ms/epoch - 9ms/step\n",
            "Epoch 6/500\n",
            "3/3 - 0s - loss: 0.6644 - accuracy: 0.5326 - val_loss: 0.6583 - val_accuracy: 0.5000 - 27ms/epoch - 9ms/step\n",
            "Epoch 7/500\n",
            "3/3 - 0s - loss: 0.6633 - accuracy: 0.5326 - val_loss: 0.6570 - val_accuracy: 0.5000 - 27ms/epoch - 9ms/step\n",
            "Epoch 8/500\n",
            "3/3 - 0s - loss: 0.6622 - accuracy: 0.5217 - val_loss: 0.6557 - val_accuracy: 0.5000 - 30ms/epoch - 10ms/step\n",
            "Epoch 9/500\n",
            "3/3 - 0s - loss: 0.6615 - accuracy: 0.5326 - val_loss: 0.6545 - val_accuracy: 0.5000 - 32ms/epoch - 11ms/step\n",
            "Epoch 10/500\n",
            "3/3 - 0s - loss: 0.6604 - accuracy: 0.5326 - val_loss: 0.6534 - val_accuracy: 0.5000 - 33ms/epoch - 11ms/step\n",
            "Epoch 11/500\n",
            "3/3 - 0s - loss: 0.6599 - accuracy: 0.5326 - val_loss: 0.6524 - val_accuracy: 0.5000 - 32ms/epoch - 11ms/step\n",
            "Epoch 12/500\n",
            "3/3 - 0s - loss: 0.6596 - accuracy: 0.5435 - val_loss: 0.6515 - val_accuracy: 0.5000 - 31ms/epoch - 10ms/step\n",
            "Epoch 13/500\n",
            "3/3 - 0s - loss: 0.6583 - accuracy: 0.5435 - val_loss: 0.6505 - val_accuracy: 0.5000 - 30ms/epoch - 10ms/step\n",
            "Epoch 14/500\n",
            "3/3 - 0s - loss: 0.6577 - accuracy: 0.5652 - val_loss: 0.6497 - val_accuracy: 0.5000 - 47ms/epoch - 16ms/step\n",
            "Epoch 15/500\n",
            "3/3 - 0s - loss: 0.6572 - accuracy: 0.5652 - val_loss: 0.6489 - val_accuracy: 0.5000 - 31ms/epoch - 10ms/step\n",
            "Epoch 16/500\n",
            "3/3 - 0s - loss: 0.6566 - accuracy: 0.5652 - val_loss: 0.6482 - val_accuracy: 0.5000 - 45ms/epoch - 15ms/step\n",
            "Epoch 17/500\n",
            "3/3 - 0s - loss: 0.6564 - accuracy: 0.5652 - val_loss: 0.6474 - val_accuracy: 0.5000 - 30ms/epoch - 10ms/step\n",
            "Epoch 18/500\n",
            "3/3 - 0s - loss: 0.6556 - accuracy: 0.5652 - val_loss: 0.6467 - val_accuracy: 0.5000 - 31ms/epoch - 10ms/step\n",
            "Epoch 19/500\n",
            "3/3 - 0s - loss: 0.6553 - accuracy: 0.5761 - val_loss: 0.6460 - val_accuracy: 0.5000 - 26ms/epoch - 9ms/step\n",
            "Epoch 20/500\n",
            "3/3 - 0s - loss: 0.6547 - accuracy: 0.5761 - val_loss: 0.6454 - val_accuracy: 0.5000 - 34ms/epoch - 11ms/step\n",
            "Epoch 21/500\n",
            "3/3 - 0s - loss: 0.6546 - accuracy: 0.5761 - val_loss: 0.6448 - val_accuracy: 0.5000 - 36ms/epoch - 12ms/step\n",
            "Epoch 22/500\n",
            "3/3 - 0s - loss: 0.6539 - accuracy: 0.5761 - val_loss: 0.6444 - val_accuracy: 0.5000 - 33ms/epoch - 11ms/step\n",
            "Epoch 23/500\n",
            "3/3 - 0s - loss: 0.6535 - accuracy: 0.5761 - val_loss: 0.6439 - val_accuracy: 0.5250 - 42ms/epoch - 14ms/step\n",
            "Epoch 24/500\n",
            "3/3 - 0s - loss: 0.6534 - accuracy: 0.5761 - val_loss: 0.6435 - val_accuracy: 0.5250 - 32ms/epoch - 11ms/step\n",
            "Epoch 25/500\n",
            "3/3 - 0s - loss: 0.6527 - accuracy: 0.5761 - val_loss: 0.6429 - val_accuracy: 0.5250 - 29ms/epoch - 10ms/step\n",
            "Epoch 26/500\n",
            "3/3 - 0s - loss: 0.6524 - accuracy: 0.5761 - val_loss: 0.6426 - val_accuracy: 0.5250 - 31ms/epoch - 10ms/step\n",
            "Epoch 27/500\n",
            "3/3 - 0s - loss: 0.6519 - accuracy: 0.5761 - val_loss: 0.6422 - val_accuracy: 0.5250 - 28ms/epoch - 9ms/step\n",
            "Epoch 28/500\n",
            "3/3 - 0s - loss: 0.6515 - accuracy: 0.5761 - val_loss: 0.6418 - val_accuracy: 0.5250 - 36ms/epoch - 12ms/step\n",
            "Epoch 29/500\n",
            "3/3 - 0s - loss: 0.6513 - accuracy: 0.5761 - val_loss: 0.6415 - val_accuracy: 0.5250 - 37ms/epoch - 12ms/step\n",
            "Epoch 30/500\n",
            "3/3 - 0s - loss: 0.6508 - accuracy: 0.5761 - val_loss: 0.6411 - val_accuracy: 0.5250 - 37ms/epoch - 12ms/step\n",
            "Epoch 31/500\n",
            "3/3 - 0s - loss: 0.6506 - accuracy: 0.5761 - val_loss: 0.6407 - val_accuracy: 0.5250 - 32ms/epoch - 11ms/step\n",
            "Epoch 32/500\n",
            "3/3 - 0s - loss: 0.6503 - accuracy: 0.5870 - val_loss: 0.6403 - val_accuracy: 0.5250 - 32ms/epoch - 11ms/step\n",
            "Epoch 33/500\n",
            "3/3 - 0s - loss: 0.6499 - accuracy: 0.5761 - val_loss: 0.6399 - val_accuracy: 0.5250 - 37ms/epoch - 12ms/step\n",
            "Epoch 34/500\n",
            "3/3 - 0s - loss: 0.6495 - accuracy: 0.5761 - val_loss: 0.6395 - val_accuracy: 0.5250 - 39ms/epoch - 13ms/step\n",
            "Epoch 35/500\n",
            "3/3 - 0s - loss: 0.6490 - accuracy: 0.5870 - val_loss: 0.6391 - val_accuracy: 0.5250 - 40ms/epoch - 13ms/step\n",
            "Epoch 36/500\n",
            "3/3 - 0s - loss: 0.6488 - accuracy: 0.5761 - val_loss: 0.6386 - val_accuracy: 0.5250 - 28ms/epoch - 9ms/step\n",
            "Epoch 37/500\n",
            "3/3 - 0s - loss: 0.6486 - accuracy: 0.5978 - val_loss: 0.6383 - val_accuracy: 0.5250 - 32ms/epoch - 11ms/step\n",
            "Epoch 38/500\n",
            "3/3 - 0s - loss: 0.6481 - accuracy: 0.5978 - val_loss: 0.6380 - val_accuracy: 0.5250 - 34ms/epoch - 11ms/step\n",
            "Epoch 39/500\n",
            "3/3 - 0s - loss: 0.6477 - accuracy: 0.5978 - val_loss: 0.6375 - val_accuracy: 0.5250 - 30ms/epoch - 10ms/step\n",
            "Epoch 40/500\n",
            "3/3 - 0s - loss: 0.6474 - accuracy: 0.5978 - val_loss: 0.6371 - val_accuracy: 0.5250 - 31ms/epoch - 10ms/step\n",
            "Epoch 41/500\n",
            "3/3 - 0s - loss: 0.6471 - accuracy: 0.5978 - val_loss: 0.6366 - val_accuracy: 0.5250 - 32ms/epoch - 11ms/step\n",
            "Epoch 42/500\n",
            "3/3 - 0s - loss: 0.6468 - accuracy: 0.6087 - val_loss: 0.6363 - val_accuracy: 0.5250 - 31ms/epoch - 10ms/step\n",
            "Epoch 43/500\n",
            "3/3 - 0s - loss: 0.6463 - accuracy: 0.6087 - val_loss: 0.6360 - val_accuracy: 0.5500 - 35ms/epoch - 12ms/step\n",
            "Epoch 44/500\n",
            "3/3 - 0s - loss: 0.6459 - accuracy: 0.5978 - val_loss: 0.6356 - val_accuracy: 0.5500 - 32ms/epoch - 11ms/step\n",
            "Epoch 45/500\n",
            "3/3 - 0s - loss: 0.6456 - accuracy: 0.5978 - val_loss: 0.6352 - val_accuracy: 0.5500 - 30ms/epoch - 10ms/step\n",
            "Epoch 46/500\n",
            "3/3 - 0s - loss: 0.6454 - accuracy: 0.6087 - val_loss: 0.6347 - val_accuracy: 0.5500 - 33ms/epoch - 11ms/step\n",
            "Epoch 47/500\n",
            "3/3 - 0s - loss: 0.6449 - accuracy: 0.6087 - val_loss: 0.6344 - val_accuracy: 0.5500 - 32ms/epoch - 11ms/step\n",
            "Epoch 48/500\n",
            "3/3 - 0s - loss: 0.6446 - accuracy: 0.6087 - val_loss: 0.6340 - val_accuracy: 0.5500 - 32ms/epoch - 11ms/step\n",
            "Epoch 49/500\n",
            "3/3 - 0s - loss: 0.6442 - accuracy: 0.6087 - val_loss: 0.6336 - val_accuracy: 0.5500 - 34ms/epoch - 11ms/step\n",
            "Epoch 50/500\n",
            "3/3 - 0s - loss: 0.6441 - accuracy: 0.6196 - val_loss: 0.6333 - val_accuracy: 0.5500 - 47ms/epoch - 16ms/step\n",
            "Epoch 51/500\n",
            "3/3 - 0s - loss: 0.6435 - accuracy: 0.6196 - val_loss: 0.6330 - val_accuracy: 0.5500 - 34ms/epoch - 11ms/step\n",
            "Epoch 52/500\n",
            "3/3 - 0s - loss: 0.6431 - accuracy: 0.6196 - val_loss: 0.6327 - val_accuracy: 0.5750 - 32ms/epoch - 11ms/step\n",
            "Epoch 53/500\n",
            "3/3 - 0s - loss: 0.6430 - accuracy: 0.6196 - val_loss: 0.6323 - val_accuracy: 0.5750 - 34ms/epoch - 11ms/step\n",
            "Epoch 54/500\n",
            "3/3 - 0s - loss: 0.6424 - accuracy: 0.6196 - val_loss: 0.6319 - val_accuracy: 0.5750 - 32ms/epoch - 11ms/step\n",
            "Epoch 55/500\n",
            "3/3 - 0s - loss: 0.6421 - accuracy: 0.6196 - val_loss: 0.6315 - val_accuracy: 0.5750 - 30ms/epoch - 10ms/step\n",
            "Epoch 56/500\n",
            "3/3 - 0s - loss: 0.6420 - accuracy: 0.6196 - val_loss: 0.6311 - val_accuracy: 0.5750 - 31ms/epoch - 10ms/step\n",
            "Epoch 57/500\n",
            "3/3 - 0s - loss: 0.6413 - accuracy: 0.6196 - val_loss: 0.6307 - val_accuracy: 0.5750 - 36ms/epoch - 12ms/step\n",
            "Epoch 58/500\n",
            "3/3 - 0s - loss: 0.6410 - accuracy: 0.6196 - val_loss: 0.6304 - val_accuracy: 0.5750 - 34ms/epoch - 11ms/step\n",
            "Epoch 59/500\n",
            "3/3 - 0s - loss: 0.6408 - accuracy: 0.6304 - val_loss: 0.6300 - val_accuracy: 0.5750 - 31ms/epoch - 10ms/step\n",
            "Epoch 60/500\n",
            "3/3 - 0s - loss: 0.6405 - accuracy: 0.6304 - val_loss: 0.6296 - val_accuracy: 0.5750 - 31ms/epoch - 10ms/step\n",
            "Epoch 61/500\n",
            "3/3 - 0s - loss: 0.6401 - accuracy: 0.6304 - val_loss: 0.6293 - val_accuracy: 0.5750 - 33ms/epoch - 11ms/step\n",
            "Epoch 62/500\n",
            "3/3 - 0s - loss: 0.6400 - accuracy: 0.6196 - val_loss: 0.6291 - val_accuracy: 0.5750 - 32ms/epoch - 11ms/step\n",
            "Epoch 63/500\n",
            "3/3 - 0s - loss: 0.6395 - accuracy: 0.6304 - val_loss: 0.6286 - val_accuracy: 0.6000 - 33ms/epoch - 11ms/step\n",
            "Epoch 64/500\n",
            "3/3 - 0s - loss: 0.6391 - accuracy: 0.6196 - val_loss: 0.6282 - val_accuracy: 0.6000 - 31ms/epoch - 10ms/step\n",
            "Epoch 65/500\n",
            "3/3 - 0s - loss: 0.6385 - accuracy: 0.6304 - val_loss: 0.6278 - val_accuracy: 0.6000 - 30ms/epoch - 10ms/step\n",
            "Epoch 66/500\n",
            "3/3 - 0s - loss: 0.6385 - accuracy: 0.6413 - val_loss: 0.6275 - val_accuracy: 0.6000 - 35ms/epoch - 12ms/step\n",
            "Epoch 67/500\n",
            "3/3 - 0s - loss: 0.6383 - accuracy: 0.6196 - val_loss: 0.6270 - val_accuracy: 0.6250 - 30ms/epoch - 10ms/step\n",
            "Epoch 68/500\n",
            "3/3 - 0s - loss: 0.6377 - accuracy: 0.6304 - val_loss: 0.6266 - val_accuracy: 0.6250 - 32ms/epoch - 11ms/step\n",
            "Epoch 69/500\n",
            "3/3 - 0s - loss: 0.6372 - accuracy: 0.6413 - val_loss: 0.6262 - val_accuracy: 0.6250 - 33ms/epoch - 11ms/step\n",
            "Epoch 70/500\n",
            "3/3 - 0s - loss: 0.6368 - accuracy: 0.6413 - val_loss: 0.6259 - val_accuracy: 0.6250 - 33ms/epoch - 11ms/step\n",
            "Epoch 71/500\n",
            "3/3 - 0s - loss: 0.6367 - accuracy: 0.6413 - val_loss: 0.6256 - val_accuracy: 0.6250 - 29ms/epoch - 10ms/step\n",
            "Epoch 72/500\n",
            "3/3 - 0s - loss: 0.6362 - accuracy: 0.6413 - val_loss: 0.6252 - val_accuracy: 0.6250 - 32ms/epoch - 11ms/step\n",
            "Epoch 73/500\n",
            "3/3 - 0s - loss: 0.6360 - accuracy: 0.6413 - val_loss: 0.6249 - val_accuracy: 0.6250 - 33ms/epoch - 11ms/step\n",
            "Epoch 74/500\n",
            "3/3 - 0s - loss: 0.6359 - accuracy: 0.6413 - val_loss: 0.6246 - val_accuracy: 0.6250 - 29ms/epoch - 10ms/step\n",
            "Epoch 75/500\n",
            "3/3 - 0s - loss: 0.6351 - accuracy: 0.6413 - val_loss: 0.6242 - val_accuracy: 0.6250 - 35ms/epoch - 12ms/step\n",
            "Epoch 76/500\n",
            "3/3 - 0s - loss: 0.6350 - accuracy: 0.6413 - val_loss: 0.6238 - val_accuracy: 0.6250 - 29ms/epoch - 10ms/step\n",
            "Epoch 77/500\n",
            "3/3 - 0s - loss: 0.6346 - accuracy: 0.6413 - val_loss: 0.6235 - val_accuracy: 0.6250 - 39ms/epoch - 13ms/step\n",
            "Epoch 78/500\n",
            "3/3 - 0s - loss: 0.6342 - accuracy: 0.6413 - val_loss: 0.6231 - val_accuracy: 0.6250 - 30ms/epoch - 10ms/step\n",
            "Epoch 79/500\n",
            "3/3 - 0s - loss: 0.6338 - accuracy: 0.6413 - val_loss: 0.6226 - val_accuracy: 0.6250 - 33ms/epoch - 11ms/step\n",
            "Epoch 80/500\n",
            "3/3 - 0s - loss: 0.6334 - accuracy: 0.6413 - val_loss: 0.6222 - val_accuracy: 0.6250 - 31ms/epoch - 10ms/step\n",
            "Epoch 81/500\n",
            "3/3 - 0s - loss: 0.6331 - accuracy: 0.6413 - val_loss: 0.6219 - val_accuracy: 0.6250 - 28ms/epoch - 9ms/step\n",
            "Epoch 82/500\n",
            "3/3 - 0s - loss: 0.6331 - accuracy: 0.6522 - val_loss: 0.6216 - val_accuracy: 0.6250 - 28ms/epoch - 9ms/step\n",
            "Epoch 83/500\n",
            "3/3 - 0s - loss: 0.6327 - accuracy: 0.6413 - val_loss: 0.6211 - val_accuracy: 0.6250 - 33ms/epoch - 11ms/step\n",
            "Epoch 84/500\n",
            "3/3 - 0s - loss: 0.6322 - accuracy: 0.6413 - val_loss: 0.6207 - val_accuracy: 0.6250 - 30ms/epoch - 10ms/step\n",
            "Epoch 85/500\n",
            "3/3 - 0s - loss: 0.6321 - accuracy: 0.6522 - val_loss: 0.6204 - val_accuracy: 0.6250 - 27ms/epoch - 9ms/step\n",
            "Epoch 86/500\n",
            "3/3 - 0s - loss: 0.6314 - accuracy: 0.6522 - val_loss: 0.6201 - val_accuracy: 0.6250 - 24ms/epoch - 8ms/step\n",
            "Epoch 87/500\n",
            "3/3 - 0s - loss: 0.6312 - accuracy: 0.6413 - val_loss: 0.6198 - val_accuracy: 0.6250 - 28ms/epoch - 9ms/step\n",
            "Epoch 88/500\n",
            "3/3 - 0s - loss: 0.6312 - accuracy: 0.6630 - val_loss: 0.6195 - val_accuracy: 0.6250 - 29ms/epoch - 10ms/step\n",
            "Epoch 89/500\n",
            "3/3 - 0s - loss: 0.6306 - accuracy: 0.6630 - val_loss: 0.6192 - val_accuracy: 0.6250 - 30ms/epoch - 10ms/step\n",
            "Epoch 90/500\n",
            "3/3 - 0s - loss: 0.6301 - accuracy: 0.6413 - val_loss: 0.6187 - val_accuracy: 0.6250 - 30ms/epoch - 10ms/step\n",
            "Epoch 91/500\n",
            "3/3 - 0s - loss: 0.6297 - accuracy: 0.6522 - val_loss: 0.6183 - val_accuracy: 0.6250 - 34ms/epoch - 11ms/step\n",
            "Epoch 92/500\n",
            "3/3 - 0s - loss: 0.6294 - accuracy: 0.6522 - val_loss: 0.6178 - val_accuracy: 0.6250 - 32ms/epoch - 11ms/step\n",
            "Epoch 93/500\n",
            "3/3 - 0s - loss: 0.6291 - accuracy: 0.6630 - val_loss: 0.6176 - val_accuracy: 0.6250 - 28ms/epoch - 9ms/step\n",
            "Epoch 94/500\n",
            "3/3 - 0s - loss: 0.6289 - accuracy: 0.6522 - val_loss: 0.6172 - val_accuracy: 0.6250 - 31ms/epoch - 10ms/step\n",
            "Epoch 95/500\n",
            "3/3 - 0s - loss: 0.6286 - accuracy: 0.6630 - val_loss: 0.6169 - val_accuracy: 0.6250 - 28ms/epoch - 9ms/step\n",
            "Epoch 96/500\n",
            "3/3 - 0s - loss: 0.6281 - accuracy: 0.6522 - val_loss: 0.6164 - val_accuracy: 0.6250 - 28ms/epoch - 9ms/step\n",
            "Epoch 97/500\n",
            "3/3 - 0s - loss: 0.6278 - accuracy: 0.6630 - val_loss: 0.6160 - val_accuracy: 0.6250 - 48ms/epoch - 16ms/step\n",
            "Epoch 98/500\n",
            "3/3 - 0s - loss: 0.6273 - accuracy: 0.6630 - val_loss: 0.6156 - val_accuracy: 0.6250 - 34ms/epoch - 11ms/step\n",
            "Epoch 99/500\n",
            "3/3 - 0s - loss: 0.6270 - accuracy: 0.6630 - val_loss: 0.6151 - val_accuracy: 0.6250 - 30ms/epoch - 10ms/step\n",
            "Epoch 100/500\n",
            "3/3 - 0s - loss: 0.6266 - accuracy: 0.6630 - val_loss: 0.6148 - val_accuracy: 0.6250 - 30ms/epoch - 10ms/step\n",
            "Epoch 101/500\n",
            "3/3 - 0s - loss: 0.6263 - accuracy: 0.6630 - val_loss: 0.6144 - val_accuracy: 0.6250 - 33ms/epoch - 11ms/step\n",
            "Epoch 102/500\n",
            "3/3 - 0s - loss: 0.6262 - accuracy: 0.6630 - val_loss: 0.6140 - val_accuracy: 0.6250 - 30ms/epoch - 10ms/step\n",
            "Epoch 103/500\n",
            "3/3 - 0s - loss: 0.6256 - accuracy: 0.6630 - val_loss: 0.6136 - val_accuracy: 0.6250 - 31ms/epoch - 10ms/step\n",
            "Epoch 104/500\n",
            "3/3 - 0s - loss: 0.6252 - accuracy: 0.6630 - val_loss: 0.6132 - val_accuracy: 0.6250 - 34ms/epoch - 11ms/step\n",
            "Epoch 105/500\n",
            "3/3 - 0s - loss: 0.6249 - accuracy: 0.6630 - val_loss: 0.6129 - val_accuracy: 0.6250 - 32ms/epoch - 11ms/step\n",
            "Epoch 106/500\n",
            "3/3 - 0s - loss: 0.6245 - accuracy: 0.6630 - val_loss: 0.6126 - val_accuracy: 0.6250 - 43ms/epoch - 14ms/step\n",
            "Epoch 107/500\n",
            "3/3 - 0s - loss: 0.6243 - accuracy: 0.6630 - val_loss: 0.6123 - val_accuracy: 0.6250 - 35ms/epoch - 12ms/step\n",
            "Epoch 108/500\n",
            "3/3 - 0s - loss: 0.6240 - accuracy: 0.6630 - val_loss: 0.6120 - val_accuracy: 0.6250 - 29ms/epoch - 10ms/step\n",
            "Epoch 109/500\n",
            "3/3 - 0s - loss: 0.6237 - accuracy: 0.6630 - val_loss: 0.6117 - val_accuracy: 0.6250 - 34ms/epoch - 11ms/step\n",
            "Epoch 110/500\n",
            "3/3 - 0s - loss: 0.6232 - accuracy: 0.6739 - val_loss: 0.6114 - val_accuracy: 0.6250 - 29ms/epoch - 10ms/step\n",
            "Epoch 111/500\n",
            "3/3 - 0s - loss: 0.6231 - accuracy: 0.6630 - val_loss: 0.6112 - val_accuracy: 0.6250 - 29ms/epoch - 10ms/step\n",
            "Epoch 112/500\n",
            "3/3 - 0s - loss: 0.6225 - accuracy: 0.6630 - val_loss: 0.6108 - val_accuracy: 0.6500 - 54ms/epoch - 18ms/step\n",
            "Epoch 113/500\n",
            "3/3 - 0s - loss: 0.6223 - accuracy: 0.6630 - val_loss: 0.6103 - val_accuracy: 0.6500 - 26ms/epoch - 9ms/step\n",
            "Epoch 114/500\n",
            "3/3 - 0s - loss: 0.6220 - accuracy: 0.6630 - val_loss: 0.6099 - val_accuracy: 0.6500 - 27ms/epoch - 9ms/step\n",
            "Epoch 115/500\n",
            "3/3 - 0s - loss: 0.6215 - accuracy: 0.6630 - val_loss: 0.6094 - val_accuracy: 0.6500 - 28ms/epoch - 9ms/step\n",
            "Epoch 116/500\n",
            "3/3 - 0s - loss: 0.6211 - accuracy: 0.6848 - val_loss: 0.6090 - val_accuracy: 0.6500 - 30ms/epoch - 10ms/step\n",
            "Epoch 117/500\n",
            "3/3 - 0s - loss: 0.6211 - accuracy: 0.6848 - val_loss: 0.6088 - val_accuracy: 0.6750 - 36ms/epoch - 12ms/step\n",
            "Epoch 118/500\n",
            "3/3 - 0s - loss: 0.6204 - accuracy: 0.6739 - val_loss: 0.6084 - val_accuracy: 0.6750 - 34ms/epoch - 11ms/step\n",
            "Epoch 119/500\n",
            "3/3 - 0s - loss: 0.6200 - accuracy: 0.6848 - val_loss: 0.6080 - val_accuracy: 0.6750 - 32ms/epoch - 11ms/step\n",
            "Epoch 120/500\n",
            "3/3 - 0s - loss: 0.6197 - accuracy: 0.6957 - val_loss: 0.6077 - val_accuracy: 0.6750 - 34ms/epoch - 11ms/step\n",
            "Epoch 121/500\n",
            "3/3 - 0s - loss: 0.6193 - accuracy: 0.6848 - val_loss: 0.6073 - val_accuracy: 0.6750 - 27ms/epoch - 9ms/step\n",
            "Epoch 122/500\n",
            "3/3 - 0s - loss: 0.6192 - accuracy: 0.6739 - val_loss: 0.6068 - val_accuracy: 0.6750 - 32ms/epoch - 11ms/step\n",
            "Epoch 123/500\n",
            "3/3 - 0s - loss: 0.6190 - accuracy: 0.6957 - val_loss: 0.6064 - val_accuracy: 0.6750 - 29ms/epoch - 10ms/step\n",
            "Epoch 124/500\n",
            "3/3 - 0s - loss: 0.6185 - accuracy: 0.7174 - val_loss: 0.6062 - val_accuracy: 0.6750 - 27ms/epoch - 9ms/step\n",
            "Epoch 125/500\n",
            "3/3 - 0s - loss: 0.6181 - accuracy: 0.7174 - val_loss: 0.6058 - val_accuracy: 0.6750 - 28ms/epoch - 9ms/step\n",
            "Epoch 126/500\n",
            "3/3 - 0s - loss: 0.6176 - accuracy: 0.7065 - val_loss: 0.6054 - val_accuracy: 0.6750 - 30ms/epoch - 10ms/step\n",
            "Epoch 127/500\n",
            "3/3 - 0s - loss: 0.6173 - accuracy: 0.7174 - val_loss: 0.6050 - val_accuracy: 0.6750 - 33ms/epoch - 11ms/step\n",
            "Epoch 128/500\n",
            "3/3 - 0s - loss: 0.6172 - accuracy: 0.7065 - val_loss: 0.6046 - val_accuracy: 0.6750 - 35ms/epoch - 12ms/step\n",
            "Epoch 129/500\n",
            "3/3 - 0s - loss: 0.6167 - accuracy: 0.7174 - val_loss: 0.6042 - val_accuracy: 0.6750 - 29ms/epoch - 10ms/step\n",
            "Epoch 130/500\n",
            "3/3 - 0s - loss: 0.6162 - accuracy: 0.7283 - val_loss: 0.6040 - val_accuracy: 0.6750 - 30ms/epoch - 10ms/step\n",
            "Epoch 131/500\n",
            "3/3 - 0s - loss: 0.6160 - accuracy: 0.7283 - val_loss: 0.6036 - val_accuracy: 0.6750 - 32ms/epoch - 11ms/step\n",
            "Epoch 132/500\n",
            "3/3 - 0s - loss: 0.6157 - accuracy: 0.7174 - val_loss: 0.6032 - val_accuracy: 0.6750 - 35ms/epoch - 12ms/step\n",
            "Epoch 133/500\n",
            "3/3 - 0s - loss: 0.6151 - accuracy: 0.7283 - val_loss: 0.6030 - val_accuracy: 0.6750 - 29ms/epoch - 10ms/step\n",
            "Epoch 134/500\n",
            "3/3 - 0s - loss: 0.6153 - accuracy: 0.6957 - val_loss: 0.6025 - val_accuracy: 0.6750 - 42ms/epoch - 14ms/step\n",
            "Epoch 135/500\n",
            "3/3 - 0s - loss: 0.6144 - accuracy: 0.7283 - val_loss: 0.6022 - val_accuracy: 0.6750 - 27ms/epoch - 9ms/step\n",
            "Epoch 136/500\n",
            "3/3 - 0s - loss: 0.6147 - accuracy: 0.7283 - val_loss: 0.6018 - val_accuracy: 0.6750 - 29ms/epoch - 10ms/step\n",
            "Epoch 137/500\n",
            "3/3 - 0s - loss: 0.6139 - accuracy: 0.7283 - val_loss: 0.6016 - val_accuracy: 0.6750 - 29ms/epoch - 10ms/step\n",
            "Epoch 138/500\n",
            "3/3 - 0s - loss: 0.6136 - accuracy: 0.7283 - val_loss: 0.6012 - val_accuracy: 0.6750 - 28ms/epoch - 9ms/step\n",
            "Epoch 139/500\n",
            "3/3 - 0s - loss: 0.6131 - accuracy: 0.7283 - val_loss: 0.6008 - val_accuracy: 0.6750 - 29ms/epoch - 10ms/step\n",
            "Epoch 140/500\n",
            "3/3 - 0s - loss: 0.6130 - accuracy: 0.7283 - val_loss: 0.6006 - val_accuracy: 0.6750 - 25ms/epoch - 8ms/step\n",
            "Epoch 141/500\n",
            "3/3 - 0s - loss: 0.6124 - accuracy: 0.7283 - val_loss: 0.6001 - val_accuracy: 0.6750 - 31ms/epoch - 10ms/step\n",
            "Epoch 142/500\n",
            "3/3 - 0s - loss: 0.6120 - accuracy: 0.7283 - val_loss: 0.5997 - val_accuracy: 0.6750 - 28ms/epoch - 9ms/step\n",
            "Epoch 143/500\n",
            "3/3 - 0s - loss: 0.6117 - accuracy: 0.7283 - val_loss: 0.5995 - val_accuracy: 0.6750 - 25ms/epoch - 8ms/step\n",
            "Epoch 144/500\n",
            "3/3 - 0s - loss: 0.6114 - accuracy: 0.7283 - val_loss: 0.5990 - val_accuracy: 0.7000 - 30ms/epoch - 10ms/step\n",
            "Epoch 145/500\n",
            "3/3 - 0s - loss: 0.6110 - accuracy: 0.7283 - val_loss: 0.5986 - val_accuracy: 0.7000 - 34ms/epoch - 11ms/step\n",
            "Epoch 146/500\n",
            "3/3 - 0s - loss: 0.6108 - accuracy: 0.7283 - val_loss: 0.5983 - val_accuracy: 0.7000 - 34ms/epoch - 11ms/step\n",
            "Epoch 147/500\n",
            "3/3 - 0s - loss: 0.6105 - accuracy: 0.7283 - val_loss: 0.5979 - val_accuracy: 0.7250 - 31ms/epoch - 10ms/step\n",
            "Epoch 148/500\n",
            "3/3 - 0s - loss: 0.6101 - accuracy: 0.7283 - val_loss: 0.5974 - val_accuracy: 0.7250 - 47ms/epoch - 16ms/step\n",
            "Epoch 149/500\n",
            "3/3 - 0s - loss: 0.6096 - accuracy: 0.7283 - val_loss: 0.5971 - val_accuracy: 0.7250 - 28ms/epoch - 9ms/step\n",
            "Epoch 150/500\n",
            "3/3 - 0s - loss: 0.6094 - accuracy: 0.7283 - val_loss: 0.5967 - val_accuracy: 0.7250 - 28ms/epoch - 9ms/step\n",
            "Epoch 151/500\n",
            "3/3 - 0s - loss: 0.6091 - accuracy: 0.7283 - val_loss: 0.5964 - val_accuracy: 0.7250 - 29ms/epoch - 10ms/step\n",
            "Epoch 152/500\n",
            "3/3 - 0s - loss: 0.6088 - accuracy: 0.7283 - val_loss: 0.5963 - val_accuracy: 0.7250 - 31ms/epoch - 10ms/step\n",
            "Epoch 153/500\n",
            "3/3 - 0s - loss: 0.6081 - accuracy: 0.7391 - val_loss: 0.5959 - val_accuracy: 0.7250 - 29ms/epoch - 10ms/step\n",
            "Epoch 154/500\n",
            "3/3 - 0s - loss: 0.6080 - accuracy: 0.7391 - val_loss: 0.5954 - val_accuracy: 0.7250 - 25ms/epoch - 8ms/step\n",
            "Epoch 155/500\n",
            "3/3 - 0s - loss: 0.6074 - accuracy: 0.7391 - val_loss: 0.5951 - val_accuracy: 0.7250 - 28ms/epoch - 9ms/step\n",
            "Epoch 156/500\n",
            "3/3 - 0s - loss: 0.6072 - accuracy: 0.7391 - val_loss: 0.5948 - val_accuracy: 0.7250 - 28ms/epoch - 9ms/step\n",
            "Epoch 157/500\n",
            "3/3 - 0s - loss: 0.6067 - accuracy: 0.7391 - val_loss: 0.5944 - val_accuracy: 0.7250 - 32ms/epoch - 11ms/step\n",
            "Epoch 158/500\n",
            "3/3 - 0s - loss: 0.6065 - accuracy: 0.7391 - val_loss: 0.5940 - val_accuracy: 0.7250 - 25ms/epoch - 8ms/step\n",
            "Epoch 159/500\n",
            "3/3 - 0s - loss: 0.6060 - accuracy: 0.7391 - val_loss: 0.5937 - val_accuracy: 0.7250 - 42ms/epoch - 14ms/step\n",
            "Epoch 160/500\n",
            "3/3 - 0s - loss: 0.6057 - accuracy: 0.7391 - val_loss: 0.5933 - val_accuracy: 0.7250 - 33ms/epoch - 11ms/step\n",
            "Epoch 161/500\n",
            "3/3 - 0s - loss: 0.6055 - accuracy: 0.7391 - val_loss: 0.5929 - val_accuracy: 0.7250 - 28ms/epoch - 9ms/step\n",
            "Epoch 162/500\n",
            "3/3 - 0s - loss: 0.6050 - accuracy: 0.7391 - val_loss: 0.5926 - val_accuracy: 0.7250 - 28ms/epoch - 9ms/step\n",
            "Epoch 163/500\n",
            "3/3 - 0s - loss: 0.6051 - accuracy: 0.7391 - val_loss: 0.5923 - val_accuracy: 0.7250 - 41ms/epoch - 14ms/step\n",
            "Epoch 164/500\n",
            "3/3 - 0s - loss: 0.6043 - accuracy: 0.7391 - val_loss: 0.5920 - val_accuracy: 0.7250 - 28ms/epoch - 9ms/step\n",
            "Epoch 165/500\n",
            "3/3 - 0s - loss: 0.6040 - accuracy: 0.7391 - val_loss: 0.5915 - val_accuracy: 0.7250 - 30ms/epoch - 10ms/step\n",
            "Epoch 166/500\n",
            "3/3 - 0s - loss: 0.6037 - accuracy: 0.7391 - val_loss: 0.5913 - val_accuracy: 0.7250 - 28ms/epoch - 9ms/step\n",
            "Epoch 167/500\n",
            "3/3 - 0s - loss: 0.6032 - accuracy: 0.7391 - val_loss: 0.5911 - val_accuracy: 0.7250 - 31ms/epoch - 10ms/step\n",
            "Epoch 168/500\n",
            "3/3 - 0s - loss: 0.6028 - accuracy: 0.7391 - val_loss: 0.5907 - val_accuracy: 0.7250 - 31ms/epoch - 10ms/step\n",
            "Epoch 169/500\n",
            "3/3 - 0s - loss: 0.6030 - accuracy: 0.7283 - val_loss: 0.5906 - val_accuracy: 0.7250 - 25ms/epoch - 8ms/step\n",
            "Epoch 170/500\n",
            "3/3 - 0s - loss: 0.6029 - accuracy: 0.7391 - val_loss: 0.5899 - val_accuracy: 0.7250 - 31ms/epoch - 10ms/step\n",
            "Epoch 171/500\n",
            "3/3 - 0s - loss: 0.6018 - accuracy: 0.7283 - val_loss: 0.5895 - val_accuracy: 0.7250 - 25ms/epoch - 8ms/step\n",
            "Epoch 172/500\n",
            "3/3 - 0s - loss: 0.6017 - accuracy: 0.7391 - val_loss: 0.5892 - val_accuracy: 0.7250 - 32ms/epoch - 11ms/step\n",
            "Epoch 173/500\n",
            "3/3 - 0s - loss: 0.6011 - accuracy: 0.7500 - val_loss: 0.5889 - val_accuracy: 0.7250 - 33ms/epoch - 11ms/step\n",
            "Epoch 174/500\n",
            "3/3 - 0s - loss: 0.6010 - accuracy: 0.7500 - val_loss: 0.5885 - val_accuracy: 0.7250 - 28ms/epoch - 9ms/step\n",
            "Epoch 175/500\n",
            "3/3 - 0s - loss: 0.6005 - accuracy: 0.7391 - val_loss: 0.5883 - val_accuracy: 0.7250 - 28ms/epoch - 9ms/step\n",
            "Epoch 176/500\n",
            "3/3 - 0s - loss: 0.6000 - accuracy: 0.7500 - val_loss: 0.5878 - val_accuracy: 0.7250 - 34ms/epoch - 11ms/step\n",
            "Epoch 177/500\n",
            "3/3 - 0s - loss: 0.5999 - accuracy: 0.7391 - val_loss: 0.5876 - val_accuracy: 0.7250 - 31ms/epoch - 10ms/step\n",
            "Epoch 178/500\n",
            "3/3 - 0s - loss: 0.5995 - accuracy: 0.7500 - val_loss: 0.5871 - val_accuracy: 0.7500 - 33ms/epoch - 11ms/step\n",
            "Epoch 179/500\n",
            "3/3 - 0s - loss: 0.5990 - accuracy: 0.7391 - val_loss: 0.5867 - val_accuracy: 0.7500 - 32ms/epoch - 11ms/step\n",
            "Epoch 180/500\n",
            "3/3 - 0s - loss: 0.5986 - accuracy: 0.7391 - val_loss: 0.5865 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 181/500\n",
            "3/3 - 0s - loss: 0.5983 - accuracy: 0.7391 - val_loss: 0.5861 - val_accuracy: 0.7500 - 48ms/epoch - 16ms/step\n",
            "Epoch 182/500\n",
            "3/3 - 0s - loss: 0.5981 - accuracy: 0.7391 - val_loss: 0.5858 - val_accuracy: 0.7500 - 31ms/epoch - 10ms/step\n",
            "Epoch 183/500\n",
            "3/3 - 0s - loss: 0.5975 - accuracy: 0.7500 - val_loss: 0.5854 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 184/500\n",
            "3/3 - 0s - loss: 0.5973 - accuracy: 0.7500 - val_loss: 0.5852 - val_accuracy: 0.7500 - 34ms/epoch - 11ms/step\n",
            "Epoch 185/500\n",
            "3/3 - 0s - loss: 0.5971 - accuracy: 0.7500 - val_loss: 0.5848 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 186/500\n",
            "3/3 - 0s - loss: 0.5973 - accuracy: 0.7391 - val_loss: 0.5841 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 187/500\n",
            "3/3 - 0s - loss: 0.5964 - accuracy: 0.7500 - val_loss: 0.5838 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 188/500\n",
            "3/3 - 0s - loss: 0.5960 - accuracy: 0.7500 - val_loss: 0.5834 - val_accuracy: 0.7750 - 29ms/epoch - 10ms/step\n",
            "Epoch 189/500\n",
            "3/3 - 0s - loss: 0.5954 - accuracy: 0.7609 - val_loss: 0.5832 - val_accuracy: 0.7500 - 28ms/epoch - 9ms/step\n",
            "Epoch 190/500\n",
            "3/3 - 0s - loss: 0.5953 - accuracy: 0.7609 - val_loss: 0.5827 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 191/500\n",
            "3/3 - 0s - loss: 0.5948 - accuracy: 0.7500 - val_loss: 0.5824 - val_accuracy: 0.7750 - 39ms/epoch - 13ms/step\n",
            "Epoch 192/500\n",
            "3/3 - 0s - loss: 0.5943 - accuracy: 0.7609 - val_loss: 0.5821 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 193/500\n",
            "3/3 - 0s - loss: 0.5941 - accuracy: 0.7717 - val_loss: 0.5819 - val_accuracy: 0.7500 - 33ms/epoch - 11ms/step\n",
            "Epoch 194/500\n",
            "3/3 - 0s - loss: 0.5939 - accuracy: 0.7609 - val_loss: 0.5817 - val_accuracy: 0.7500 - 27ms/epoch - 9ms/step\n",
            "Epoch 195/500\n",
            "3/3 - 0s - loss: 0.5932 - accuracy: 0.7609 - val_loss: 0.5813 - val_accuracy: 0.7500 - 27ms/epoch - 9ms/step\n",
            "Epoch 196/500\n",
            "3/3 - 0s - loss: 0.5930 - accuracy: 0.7717 - val_loss: 0.5811 - val_accuracy: 0.7500 - 31ms/epoch - 10ms/step\n",
            "Epoch 197/500\n",
            "3/3 - 0s - loss: 0.5928 - accuracy: 0.7717 - val_loss: 0.5808 - val_accuracy: 0.7500 - 50ms/epoch - 17ms/step\n",
            "Epoch 198/500\n",
            "3/3 - 0s - loss: 0.5922 - accuracy: 0.7717 - val_loss: 0.5803 - val_accuracy: 0.7500 - 34ms/epoch - 11ms/step\n",
            "Epoch 199/500\n",
            "3/3 - 0s - loss: 0.5929 - accuracy: 0.7717 - val_loss: 0.5802 - val_accuracy: 0.7500 - 33ms/epoch - 11ms/step\n",
            "Epoch 200/500\n",
            "3/3 - 0s - loss: 0.5916 - accuracy: 0.7717 - val_loss: 0.5798 - val_accuracy: 0.7500 - 33ms/epoch - 11ms/step\n",
            "Epoch 201/500\n",
            "3/3 - 0s - loss: 0.5911 - accuracy: 0.7609 - val_loss: 0.5795 - val_accuracy: 0.7500 - 31ms/epoch - 10ms/step\n",
            "Epoch 202/500\n",
            "3/3 - 0s - loss: 0.5909 - accuracy: 0.7717 - val_loss: 0.5791 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 203/500\n",
            "3/3 - 0s - loss: 0.5906 - accuracy: 0.7609 - val_loss: 0.5788 - val_accuracy: 0.7500 - 34ms/epoch - 11ms/step\n",
            "Epoch 204/500\n",
            "3/3 - 0s - loss: 0.5906 - accuracy: 0.7609 - val_loss: 0.5786 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 205/500\n",
            "3/3 - 0s - loss: 0.5898 - accuracy: 0.7609 - val_loss: 0.5783 - val_accuracy: 0.7500 - 31ms/epoch - 10ms/step\n",
            "Epoch 206/500\n",
            "3/3 - 0s - loss: 0.5893 - accuracy: 0.7500 - val_loss: 0.5778 - val_accuracy: 0.7250 - 31ms/epoch - 10ms/step\n",
            "Epoch 207/500\n",
            "3/3 - 0s - loss: 0.5890 - accuracy: 0.7500 - val_loss: 0.5774 - val_accuracy: 0.7250 - 31ms/epoch - 10ms/step\n",
            "Epoch 208/500\n",
            "3/3 - 0s - loss: 0.5890 - accuracy: 0.7609 - val_loss: 0.5771 - val_accuracy: 0.7250 - 31ms/epoch - 10ms/step\n",
            "Epoch 209/500\n",
            "3/3 - 0s - loss: 0.5890 - accuracy: 0.7500 - val_loss: 0.5766 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 210/500\n",
            "3/3 - 0s - loss: 0.5889 - accuracy: 0.7717 - val_loss: 0.5765 - val_accuracy: 0.7250 - 30ms/epoch - 10ms/step\n",
            "Epoch 211/500\n",
            "3/3 - 0s - loss: 0.5878 - accuracy: 0.7609 - val_loss: 0.5761 - val_accuracy: 0.7250 - 28ms/epoch - 9ms/step\n",
            "Epoch 212/500\n",
            "3/3 - 0s - loss: 0.5873 - accuracy: 0.7609 - val_loss: 0.5758 - val_accuracy: 0.7500 - 28ms/epoch - 9ms/step\n",
            "Epoch 213/500\n",
            "3/3 - 0s - loss: 0.5875 - accuracy: 0.7500 - val_loss: 0.5754 - val_accuracy: 0.7500 - 34ms/epoch - 11ms/step\n",
            "Epoch 214/500\n",
            "3/3 - 0s - loss: 0.5869 - accuracy: 0.7609 - val_loss: 0.5752 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 215/500\n",
            "3/3 - 0s - loss: 0.5862 - accuracy: 0.7609 - val_loss: 0.5748 - val_accuracy: 0.7500 - 34ms/epoch - 11ms/step\n",
            "Epoch 216/500\n",
            "3/3 - 0s - loss: 0.5859 - accuracy: 0.7609 - val_loss: 0.5745 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 217/500\n",
            "3/3 - 0s - loss: 0.5854 - accuracy: 0.7717 - val_loss: 0.5741 - val_accuracy: 0.7500 - 28ms/epoch - 9ms/step\n",
            "Epoch 218/500\n",
            "3/3 - 0s - loss: 0.5851 - accuracy: 0.7717 - val_loss: 0.5738 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 219/500\n",
            "3/3 - 0s - loss: 0.5847 - accuracy: 0.7609 - val_loss: 0.5735 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 220/500\n",
            "3/3 - 0s - loss: 0.5846 - accuracy: 0.7717 - val_loss: 0.5729 - val_accuracy: 0.7500 - 38ms/epoch - 13ms/step\n",
            "Epoch 221/500\n",
            "3/3 - 0s - loss: 0.5844 - accuracy: 0.7717 - val_loss: 0.5727 - val_accuracy: 0.7500 - 31ms/epoch - 10ms/step\n",
            "Epoch 222/500\n",
            "3/3 - 0s - loss: 0.5838 - accuracy: 0.7717 - val_loss: 0.5724 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 223/500\n",
            "3/3 - 0s - loss: 0.5834 - accuracy: 0.7717 - val_loss: 0.5721 - val_accuracy: 0.7500 - 35ms/epoch - 12ms/step\n",
            "Epoch 224/500\n",
            "3/3 - 0s - loss: 0.5836 - accuracy: 0.7717 - val_loss: 0.5719 - val_accuracy: 0.7500 - 33ms/epoch - 11ms/step\n",
            "Epoch 225/500\n",
            "3/3 - 0s - loss: 0.5828 - accuracy: 0.7826 - val_loss: 0.5713 - val_accuracy: 0.7500 - 32ms/epoch - 11ms/step\n",
            "Epoch 226/500\n",
            "3/3 - 0s - loss: 0.5823 - accuracy: 0.7717 - val_loss: 0.5710 - val_accuracy: 0.7500 - 28ms/epoch - 9ms/step\n",
            "Epoch 227/500\n",
            "3/3 - 0s - loss: 0.5820 - accuracy: 0.7717 - val_loss: 0.5707 - val_accuracy: 0.7500 - 34ms/epoch - 11ms/step\n",
            "Epoch 228/500\n",
            "3/3 - 0s - loss: 0.5815 - accuracy: 0.7717 - val_loss: 0.5703 - val_accuracy: 0.7500 - 36ms/epoch - 12ms/step\n",
            "Epoch 229/500\n",
            "3/3 - 0s - loss: 0.5812 - accuracy: 0.7717 - val_loss: 0.5700 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 230/500\n",
            "3/3 - 0s - loss: 0.5811 - accuracy: 0.7717 - val_loss: 0.5698 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 231/500\n",
            "3/3 - 0s - loss: 0.5806 - accuracy: 0.7717 - val_loss: 0.5695 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 232/500\n",
            "3/3 - 0s - loss: 0.5801 - accuracy: 0.7717 - val_loss: 0.5690 - val_accuracy: 0.7500 - 33ms/epoch - 11ms/step\n",
            "Epoch 233/500\n",
            "3/3 - 0s - loss: 0.5798 - accuracy: 0.7826 - val_loss: 0.5685 - val_accuracy: 0.7500 - 34ms/epoch - 11ms/step\n",
            "Epoch 234/500\n",
            "3/3 - 0s - loss: 0.5794 - accuracy: 0.7717 - val_loss: 0.5683 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 235/500\n",
            "3/3 - 0s - loss: 0.5791 - accuracy: 0.7717 - val_loss: 0.5679 - val_accuracy: 0.7500 - 31ms/epoch - 10ms/step\n",
            "Epoch 236/500\n",
            "3/3 - 0s - loss: 0.5787 - accuracy: 0.7717 - val_loss: 0.5676 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 237/500\n",
            "3/3 - 0s - loss: 0.5786 - accuracy: 0.7717 - val_loss: 0.5672 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 238/500\n",
            "3/3 - 0s - loss: 0.5778 - accuracy: 0.7717 - val_loss: 0.5669 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 239/500\n",
            "3/3 - 0s - loss: 0.5778 - accuracy: 0.7717 - val_loss: 0.5664 - val_accuracy: 0.7500 - 28ms/epoch - 9ms/step\n",
            "Epoch 240/500\n",
            "3/3 - 0s - loss: 0.5773 - accuracy: 0.7717 - val_loss: 0.5662 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 241/500\n",
            "3/3 - 0s - loss: 0.5768 - accuracy: 0.7717 - val_loss: 0.5659 - val_accuracy: 0.7500 - 31ms/epoch - 10ms/step\n",
            "Epoch 242/500\n",
            "3/3 - 0s - loss: 0.5773 - accuracy: 0.7826 - val_loss: 0.5655 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 243/500\n",
            "3/3 - 0s - loss: 0.5761 - accuracy: 0.7717 - val_loss: 0.5652 - val_accuracy: 0.7500 - 39ms/epoch - 13ms/step\n",
            "Epoch 244/500\n",
            "3/3 - 0s - loss: 0.5765 - accuracy: 0.7717 - val_loss: 0.5648 - val_accuracy: 0.7500 - 32ms/epoch - 11ms/step\n",
            "Epoch 245/500\n",
            "3/3 - 0s - loss: 0.5754 - accuracy: 0.7717 - val_loss: 0.5646 - val_accuracy: 0.7500 - 32ms/epoch - 11ms/step\n",
            "Epoch 246/500\n",
            "3/3 - 0s - loss: 0.5752 - accuracy: 0.7717 - val_loss: 0.5643 - val_accuracy: 0.7500 - 32ms/epoch - 11ms/step\n",
            "Epoch 247/500\n",
            "3/3 - 0s - loss: 0.5747 - accuracy: 0.7717 - val_loss: 0.5640 - val_accuracy: 0.7500 - 28ms/epoch - 9ms/step\n",
            "Epoch 248/500\n",
            "3/3 - 0s - loss: 0.5745 - accuracy: 0.7717 - val_loss: 0.5638 - val_accuracy: 0.7500 - 43ms/epoch - 14ms/step\n",
            "Epoch 249/500\n",
            "3/3 - 0s - loss: 0.5740 - accuracy: 0.7717 - val_loss: 0.5636 - val_accuracy: 0.7500 - 33ms/epoch - 11ms/step\n",
            "Epoch 250/500\n",
            "3/3 - 0s - loss: 0.5736 - accuracy: 0.7717 - val_loss: 0.5633 - val_accuracy: 0.7500 - 32ms/epoch - 11ms/step\n",
            "Epoch 251/500\n",
            "3/3 - 0s - loss: 0.5733 - accuracy: 0.7717 - val_loss: 0.5630 - val_accuracy: 0.7500 - 33ms/epoch - 11ms/step\n",
            "Epoch 252/500\n",
            "3/3 - 0s - loss: 0.5733 - accuracy: 0.7717 - val_loss: 0.5626 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 253/500\n",
            "3/3 - 0s - loss: 0.5726 - accuracy: 0.7826 - val_loss: 0.5624 - val_accuracy: 0.7500 - 28ms/epoch - 9ms/step\n",
            "Epoch 254/500\n",
            "3/3 - 0s - loss: 0.5723 - accuracy: 0.7717 - val_loss: 0.5620 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 255/500\n",
            "3/3 - 0s - loss: 0.5718 - accuracy: 0.7717 - val_loss: 0.5617 - val_accuracy: 0.7500 - 34ms/epoch - 11ms/step\n",
            "Epoch 256/500\n",
            "3/3 - 0s - loss: 0.5718 - accuracy: 0.7717 - val_loss: 0.5615 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 257/500\n",
            "3/3 - 0s - loss: 0.5717 - accuracy: 0.7717 - val_loss: 0.5611 - val_accuracy: 0.7750 - 27ms/epoch - 9ms/step\n",
            "Epoch 258/500\n",
            "3/3 - 0s - loss: 0.5710 - accuracy: 0.7826 - val_loss: 0.5609 - val_accuracy: 0.7500 - 31ms/epoch - 10ms/step\n",
            "Epoch 259/500\n",
            "3/3 - 0s - loss: 0.5707 - accuracy: 0.7826 - val_loss: 0.5607 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 260/500\n",
            "3/3 - 0s - loss: 0.5703 - accuracy: 0.7826 - val_loss: 0.5605 - val_accuracy: 0.7500 - 37ms/epoch - 12ms/step\n",
            "Epoch 261/500\n",
            "3/3 - 0s - loss: 0.5701 - accuracy: 0.7826 - val_loss: 0.5601 - val_accuracy: 0.7500 - 46ms/epoch - 15ms/step\n",
            "Epoch 262/500\n",
            "3/3 - 0s - loss: 0.5694 - accuracy: 0.7826 - val_loss: 0.5598 - val_accuracy: 0.7500 - 28ms/epoch - 9ms/step\n",
            "Epoch 263/500\n",
            "3/3 - 0s - loss: 0.5691 - accuracy: 0.7826 - val_loss: 0.5595 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 264/500\n",
            "3/3 - 0s - loss: 0.5688 - accuracy: 0.7826 - val_loss: 0.5593 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 265/500\n",
            "3/3 - 0s - loss: 0.5683 - accuracy: 0.7717 - val_loss: 0.5589 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 266/500\n",
            "3/3 - 0s - loss: 0.5681 - accuracy: 0.7717 - val_loss: 0.5587 - val_accuracy: 0.7500 - 29ms/epoch - 10ms/step\n",
            "Epoch 267/500\n",
            "3/3 - 0s - loss: 0.5682 - accuracy: 0.7717 - val_loss: 0.5583 - val_accuracy: 0.7750 - 25ms/epoch - 8ms/step\n",
            "Epoch 268/500\n",
            "3/3 - 0s - loss: 0.5676 - accuracy: 0.7826 - val_loss: 0.5581 - val_accuracy: 0.7500 - 40ms/epoch - 13ms/step\n",
            "Epoch 269/500\n",
            "3/3 - 0s - loss: 0.5670 - accuracy: 0.7935 - val_loss: 0.5577 - val_accuracy: 0.7750 - 30ms/epoch - 10ms/step\n",
            "Epoch 270/500\n",
            "3/3 - 0s - loss: 0.5667 - accuracy: 0.7826 - val_loss: 0.5575 - val_accuracy: 0.7500 - 33ms/epoch - 11ms/step\n",
            "Epoch 271/500\n",
            "3/3 - 0s - loss: 0.5662 - accuracy: 0.7826 - val_loss: 0.5572 - val_accuracy: 0.7500 - 30ms/epoch - 10ms/step\n",
            "Epoch 272/500\n",
            "3/3 - 0s - loss: 0.5660 - accuracy: 0.7826 - val_loss: 0.5569 - val_accuracy: 0.7750 - 50ms/epoch - 17ms/step\n",
            "Epoch 273/500\n",
            "3/3 - 0s - loss: 0.5659 - accuracy: 0.7826 - val_loss: 0.5566 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 274/500\n",
            "3/3 - 0s - loss: 0.5652 - accuracy: 0.7826 - val_loss: 0.5562 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 275/500\n",
            "3/3 - 0s - loss: 0.5652 - accuracy: 0.7826 - val_loss: 0.5560 - val_accuracy: 0.7750 - 41ms/epoch - 14ms/step\n",
            "Epoch 276/500\n",
            "3/3 - 0s - loss: 0.5646 - accuracy: 0.7826 - val_loss: 0.5556 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 277/500\n",
            "3/3 - 0s - loss: 0.5645 - accuracy: 0.7717 - val_loss: 0.5552 - val_accuracy: 0.7750 - 37ms/epoch - 12ms/step\n",
            "Epoch 278/500\n",
            "3/3 - 0s - loss: 0.5638 - accuracy: 0.7826 - val_loss: 0.5549 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 279/500\n",
            "3/3 - 0s - loss: 0.5638 - accuracy: 0.7826 - val_loss: 0.5548 - val_accuracy: 0.7750 - 36ms/epoch - 12ms/step\n",
            "Epoch 280/500\n",
            "3/3 - 0s - loss: 0.5634 - accuracy: 0.7826 - val_loss: 0.5543 - val_accuracy: 0.7750 - 26ms/epoch - 9ms/step\n",
            "Epoch 281/500\n",
            "3/3 - 0s - loss: 0.5627 - accuracy: 0.7826 - val_loss: 0.5540 - val_accuracy: 0.7750 - 33ms/epoch - 11ms/step\n",
            "Epoch 282/500\n",
            "3/3 - 0s - loss: 0.5625 - accuracy: 0.7826 - val_loss: 0.5537 - val_accuracy: 0.7750 - 36ms/epoch - 12ms/step\n",
            "Epoch 283/500\n",
            "3/3 - 0s - loss: 0.5624 - accuracy: 0.7826 - val_loss: 0.5535 - val_accuracy: 0.7750 - 31ms/epoch - 10ms/step\n",
            "Epoch 284/500\n",
            "3/3 - 0s - loss: 0.5619 - accuracy: 0.7826 - val_loss: 0.5531 - val_accuracy: 0.7750 - 32ms/epoch - 11ms/step\n",
            "Epoch 285/500\n",
            "3/3 - 0s - loss: 0.5619 - accuracy: 0.7826 - val_loss: 0.5529 - val_accuracy: 0.7750 - 35ms/epoch - 12ms/step\n",
            "Epoch 286/500\n",
            "3/3 - 0s - loss: 0.5611 - accuracy: 0.7826 - val_loss: 0.5525 - val_accuracy: 0.7750 - 32ms/epoch - 11ms/step\n",
            "Epoch 287/500\n",
            "3/3 - 0s - loss: 0.5607 - accuracy: 0.7826 - val_loss: 0.5522 - val_accuracy: 0.7750 - 35ms/epoch - 12ms/step\n",
            "Epoch 288/500\n",
            "3/3 - 0s - loss: 0.5606 - accuracy: 0.7826 - val_loss: 0.5517 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 289/500\n",
            "3/3 - 0s - loss: 0.5601 - accuracy: 0.7826 - val_loss: 0.5514 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 290/500\n",
            "3/3 - 0s - loss: 0.5596 - accuracy: 0.7826 - val_loss: 0.5511 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 291/500\n",
            "3/3 - 0s - loss: 0.5592 - accuracy: 0.7826 - val_loss: 0.5508 - val_accuracy: 0.7750 - 31ms/epoch - 10ms/step\n",
            "Epoch 292/500\n",
            "3/3 - 0s - loss: 0.5589 - accuracy: 0.7826 - val_loss: 0.5505 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 293/500\n",
            "3/3 - 0s - loss: 0.5588 - accuracy: 0.7826 - val_loss: 0.5502 - val_accuracy: 0.7750 - 32ms/epoch - 11ms/step\n",
            "Epoch 294/500\n",
            "3/3 - 0s - loss: 0.5586 - accuracy: 0.7826 - val_loss: 0.5499 - val_accuracy: 0.7750 - 30ms/epoch - 10ms/step\n",
            "Epoch 295/500\n",
            "3/3 - 0s - loss: 0.5579 - accuracy: 0.7826 - val_loss: 0.5496 - val_accuracy: 0.7750 - 30ms/epoch - 10ms/step\n",
            "Epoch 296/500\n",
            "3/3 - 0s - loss: 0.5575 - accuracy: 0.7826 - val_loss: 0.5493 - val_accuracy: 0.7750 - 51ms/epoch - 17ms/step\n",
            "Epoch 297/500\n",
            "3/3 - 0s - loss: 0.5572 - accuracy: 0.7826 - val_loss: 0.5490 - val_accuracy: 0.7750 - 31ms/epoch - 10ms/step\n",
            "Epoch 298/500\n",
            "3/3 - 0s - loss: 0.5568 - accuracy: 0.7826 - val_loss: 0.5488 - val_accuracy: 0.7750 - 31ms/epoch - 10ms/step\n",
            "Epoch 299/500\n",
            "3/3 - 0s - loss: 0.5566 - accuracy: 0.7826 - val_loss: 0.5486 - val_accuracy: 0.7750 - 37ms/epoch - 12ms/step\n",
            "Epoch 300/500\n",
            "3/3 - 0s - loss: 0.5563 - accuracy: 0.7826 - val_loss: 0.5482 - val_accuracy: 0.7750 - 31ms/epoch - 10ms/step\n",
            "Epoch 301/500\n",
            "3/3 - 0s - loss: 0.5558 - accuracy: 0.7826 - val_loss: 0.5479 - val_accuracy: 0.7750 - 29ms/epoch - 10ms/step\n",
            "Epoch 302/500\n",
            "3/3 - 0s - loss: 0.5557 - accuracy: 0.7826 - val_loss: 0.5475 - val_accuracy: 0.7750 - 42ms/epoch - 14ms/step\n",
            "Epoch 303/500\n",
            "3/3 - 0s - loss: 0.5554 - accuracy: 0.7826 - val_loss: 0.5473 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 304/500\n",
            "3/3 - 0s - loss: 0.5550 - accuracy: 0.7826 - val_loss: 0.5469 - val_accuracy: 0.7750 - 31ms/epoch - 10ms/step\n",
            "Epoch 305/500\n",
            "3/3 - 0s - loss: 0.5544 - accuracy: 0.7826 - val_loss: 0.5467 - val_accuracy: 0.7750 - 35ms/epoch - 12ms/step\n",
            "Epoch 306/500\n",
            "3/3 - 0s - loss: 0.5549 - accuracy: 0.7935 - val_loss: 0.5465 - val_accuracy: 0.7750 - 32ms/epoch - 11ms/step\n",
            "Epoch 307/500\n",
            "3/3 - 0s - loss: 0.5542 - accuracy: 0.7826 - val_loss: 0.5461 - val_accuracy: 0.7750 - 36ms/epoch - 12ms/step\n",
            "Epoch 308/500\n",
            "3/3 - 0s - loss: 0.5538 - accuracy: 0.7935 - val_loss: 0.5460 - val_accuracy: 0.7750 - 32ms/epoch - 11ms/step\n",
            "Epoch 309/500\n",
            "3/3 - 0s - loss: 0.5534 - accuracy: 0.7826 - val_loss: 0.5455 - val_accuracy: 0.7750 - 38ms/epoch - 13ms/step\n",
            "Epoch 310/500\n",
            "3/3 - 0s - loss: 0.5529 - accuracy: 0.7826 - val_loss: 0.5454 - val_accuracy: 0.7750 - 46ms/epoch - 15ms/step\n",
            "Epoch 311/500\n",
            "3/3 - 0s - loss: 0.5531 - accuracy: 0.8043 - val_loss: 0.5454 - val_accuracy: 0.7750 - 39ms/epoch - 13ms/step\n",
            "Epoch 312/500\n",
            "3/3 - 0s - loss: 0.5520 - accuracy: 0.7826 - val_loss: 0.5451 - val_accuracy: 0.7750 - 35ms/epoch - 12ms/step\n",
            "Epoch 313/500\n",
            "3/3 - 0s - loss: 0.5520 - accuracy: 0.7826 - val_loss: 0.5448 - val_accuracy: 0.7750 - 37ms/epoch - 12ms/step\n",
            "Epoch 314/500\n",
            "3/3 - 0s - loss: 0.5515 - accuracy: 0.7826 - val_loss: 0.5444 - val_accuracy: 0.7750 - 36ms/epoch - 12ms/step\n",
            "Epoch 315/500\n",
            "3/3 - 0s - loss: 0.5511 - accuracy: 0.7826 - val_loss: 0.5443 - val_accuracy: 0.7750 - 27ms/epoch - 9ms/step\n",
            "Epoch 316/500\n",
            "3/3 - 0s - loss: 0.5509 - accuracy: 0.7826 - val_loss: 0.5441 - val_accuracy: 0.7750 - 44ms/epoch - 15ms/step\n",
            "Epoch 317/500\n",
            "3/3 - 0s - loss: 0.5504 - accuracy: 0.7826 - val_loss: 0.5437 - val_accuracy: 0.7750 - 40ms/epoch - 13ms/step\n",
            "Epoch 318/500\n",
            "3/3 - 0s - loss: 0.5501 - accuracy: 0.7935 - val_loss: 0.5436 - val_accuracy: 0.7750 - 49ms/epoch - 16ms/step\n",
            "Epoch 319/500\n",
            "3/3 - 0s - loss: 0.5497 - accuracy: 0.7935 - val_loss: 0.5432 - val_accuracy: 0.7750 - 33ms/epoch - 11ms/step\n",
            "Epoch 320/500\n",
            "3/3 - 0s - loss: 0.5500 - accuracy: 0.7826 - val_loss: 0.5431 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 321/500\n",
            "3/3 - 0s - loss: 0.5492 - accuracy: 0.7826 - val_loss: 0.5428 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 322/500\n",
            "3/3 - 0s - loss: 0.5486 - accuracy: 0.7826 - val_loss: 0.5425 - val_accuracy: 0.7750 - 32ms/epoch - 11ms/step\n",
            "Epoch 323/500\n",
            "3/3 - 0s - loss: 0.5484 - accuracy: 0.7826 - val_loss: 0.5422 - val_accuracy: 0.7750 - 37ms/epoch - 12ms/step\n",
            "Epoch 324/500\n",
            "3/3 - 0s - loss: 0.5481 - accuracy: 0.7826 - val_loss: 0.5419 - val_accuracy: 0.7750 - 36ms/epoch - 12ms/step\n",
            "Epoch 325/500\n",
            "3/3 - 0s - loss: 0.5481 - accuracy: 0.7826 - val_loss: 0.5417 - val_accuracy: 0.7750 - 31ms/epoch - 10ms/step\n",
            "Epoch 326/500\n",
            "3/3 - 0s - loss: 0.5476 - accuracy: 0.7935 - val_loss: 0.5414 - val_accuracy: 0.7750 - 32ms/epoch - 11ms/step\n",
            "Epoch 327/500\n",
            "3/3 - 0s - loss: 0.5472 - accuracy: 0.7935 - val_loss: 0.5412 - val_accuracy: 0.7750 - 36ms/epoch - 12ms/step\n",
            "Epoch 328/500\n",
            "3/3 - 0s - loss: 0.5467 - accuracy: 0.7935 - val_loss: 0.5408 - val_accuracy: 0.7750 - 33ms/epoch - 11ms/step\n",
            "Epoch 329/500\n",
            "3/3 - 0s - loss: 0.5464 - accuracy: 0.7826 - val_loss: 0.5403 - val_accuracy: 0.7750 - 31ms/epoch - 10ms/step\n",
            "Epoch 330/500\n",
            "3/3 - 0s - loss: 0.5459 - accuracy: 0.8043 - val_loss: 0.5401 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 331/500\n",
            "3/3 - 0s - loss: 0.5461 - accuracy: 0.7935 - val_loss: 0.5400 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 332/500\n",
            "3/3 - 0s - loss: 0.5452 - accuracy: 0.7935 - val_loss: 0.5398 - val_accuracy: 0.7750 - 32ms/epoch - 11ms/step\n",
            "Epoch 333/500\n",
            "3/3 - 0s - loss: 0.5450 - accuracy: 0.8043 - val_loss: 0.5394 - val_accuracy: 0.7750 - 35ms/epoch - 12ms/step\n",
            "Epoch 334/500\n",
            "3/3 - 0s - loss: 0.5447 - accuracy: 0.7935 - val_loss: 0.5390 - val_accuracy: 0.7750 - 29ms/epoch - 10ms/step\n",
            "Epoch 335/500\n",
            "3/3 - 0s - loss: 0.5443 - accuracy: 0.8043 - val_loss: 0.5387 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 336/500\n",
            "3/3 - 0s - loss: 0.5441 - accuracy: 0.7935 - val_loss: 0.5385 - val_accuracy: 0.7750 - 30ms/epoch - 10ms/step\n",
            "Epoch 337/500\n",
            "3/3 - 0s - loss: 0.5438 - accuracy: 0.7935 - val_loss: 0.5380 - val_accuracy: 0.7750 - 30ms/epoch - 10ms/step\n",
            "Epoch 338/500\n",
            "3/3 - 0s - loss: 0.5434 - accuracy: 0.7935 - val_loss: 0.5378 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 339/500\n",
            "3/3 - 0s - loss: 0.5429 - accuracy: 0.8043 - val_loss: 0.5376 - val_accuracy: 0.7750 - 31ms/epoch - 10ms/step\n",
            "Epoch 340/500\n",
            "3/3 - 0s - loss: 0.5430 - accuracy: 0.7935 - val_loss: 0.5372 - val_accuracy: 0.7750 - 34ms/epoch - 11ms/step\n",
            "Epoch 341/500\n",
            "3/3 - 0s - loss: 0.5426 - accuracy: 0.7935 - val_loss: 0.5369 - val_accuracy: 0.7750 - 32ms/epoch - 11ms/step\n",
            "Epoch 342/500\n",
            "3/3 - 0s - loss: 0.5421 - accuracy: 0.8043 - val_loss: 0.5366 - val_accuracy: 0.7750 - 39ms/epoch - 13ms/step\n",
            "Epoch 343/500\n",
            "3/3 - 0s - loss: 0.5417 - accuracy: 0.8043 - val_loss: 0.5364 - val_accuracy: 0.7750 - 31ms/epoch - 10ms/step\n",
            "Epoch 344/500\n",
            "3/3 - 0s - loss: 0.5421 - accuracy: 0.8043 - val_loss: 0.5363 - val_accuracy: 0.7750 - 29ms/epoch - 10ms/step\n",
            "Epoch 345/500\n",
            "3/3 - 0s - loss: 0.5412 - accuracy: 0.8043 - val_loss: 0.5362 - val_accuracy: 0.7750 - 30ms/epoch - 10ms/step\n",
            "Epoch 346/500\n",
            "3/3 - 0s - loss: 0.5406 - accuracy: 0.8043 - val_loss: 0.5359 - val_accuracy: 0.7750 - 30ms/epoch - 10ms/step\n",
            "Epoch 347/500\n",
            "3/3 - 0s - loss: 0.5405 - accuracy: 0.8043 - val_loss: 0.5355 - val_accuracy: 0.7750 - 32ms/epoch - 11ms/step\n",
            "Epoch 348/500\n",
            "3/3 - 0s - loss: 0.5402 - accuracy: 0.8152 - val_loss: 0.5354 - val_accuracy: 0.7750 - 38ms/epoch - 13ms/step\n",
            "Epoch 349/500\n",
            "3/3 - 0s - loss: 0.5402 - accuracy: 0.7826 - val_loss: 0.5349 - val_accuracy: 0.7750 - 53ms/epoch - 18ms/step\n",
            "Epoch 350/500\n",
            "3/3 - 0s - loss: 0.5394 - accuracy: 0.8043 - val_loss: 0.5346 - val_accuracy: 0.7750 - 36ms/epoch - 12ms/step\n",
            "Epoch 351/500\n",
            "3/3 - 0s - loss: 0.5391 - accuracy: 0.8043 - val_loss: 0.5345 - val_accuracy: 0.7750 - 31ms/epoch - 10ms/step\n",
            "Epoch 352/500\n",
            "3/3 - 0s - loss: 0.5388 - accuracy: 0.8043 - val_loss: 0.5343 - val_accuracy: 0.7750 - 37ms/epoch - 12ms/step\n",
            "Epoch 353/500\n",
            "3/3 - 0s - loss: 0.5385 - accuracy: 0.7935 - val_loss: 0.5339 - val_accuracy: 0.7750 - 41ms/epoch - 14ms/step\n",
            "Epoch 354/500\n",
            "3/3 - 0s - loss: 0.5381 - accuracy: 0.8043 - val_loss: 0.5335 - val_accuracy: 0.7750 - 41ms/epoch - 14ms/step\n",
            "Epoch 355/500\n",
            "3/3 - 0s - loss: 0.5378 - accuracy: 0.8043 - val_loss: 0.5333 - val_accuracy: 0.7750 - 28ms/epoch - 9ms/step\n",
            "Epoch 356/500\n",
            "3/3 - 0s - loss: 0.5374 - accuracy: 0.8043 - val_loss: 0.5330 - val_accuracy: 0.8000 - 33ms/epoch - 11ms/step\n",
            "Epoch 357/500\n",
            "3/3 - 0s - loss: 0.5371 - accuracy: 0.8043 - val_loss: 0.5328 - val_accuracy: 0.8000 - 30ms/epoch - 10ms/step\n",
            "Epoch 358/500\n",
            "3/3 - 0s - loss: 0.5368 - accuracy: 0.8043 - val_loss: 0.5325 - val_accuracy: 0.8000 - 34ms/epoch - 11ms/step\n",
            "Epoch 359/500\n",
            "3/3 - 0s - loss: 0.5365 - accuracy: 0.8043 - val_loss: 0.5322 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 360/500\n",
            "3/3 - 0s - loss: 0.5361 - accuracy: 0.8043 - val_loss: 0.5320 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 361/500\n",
            "3/3 - 0s - loss: 0.5359 - accuracy: 0.8043 - val_loss: 0.5317 - val_accuracy: 0.8250 - 35ms/epoch - 12ms/step\n",
            "Epoch 362/500\n",
            "3/3 - 0s - loss: 0.5353 - accuracy: 0.8152 - val_loss: 0.5314 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 363/500\n",
            "3/3 - 0s - loss: 0.5355 - accuracy: 0.8152 - val_loss: 0.5311 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 364/500\n",
            "3/3 - 0s - loss: 0.5348 - accuracy: 0.8043 - val_loss: 0.5308 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 365/500\n",
            "3/3 - 0s - loss: 0.5343 - accuracy: 0.8152 - val_loss: 0.5306 - val_accuracy: 0.8250 - 36ms/epoch - 12ms/step\n",
            "Epoch 366/500\n",
            "3/3 - 0s - loss: 0.5340 - accuracy: 0.8152 - val_loss: 0.5304 - val_accuracy: 0.8250 - 37ms/epoch - 12ms/step\n",
            "Epoch 367/500\n",
            "3/3 - 0s - loss: 0.5337 - accuracy: 0.8152 - val_loss: 0.5301 - val_accuracy: 0.8250 - 34ms/epoch - 11ms/step\n",
            "Epoch 368/500\n",
            "3/3 - 0s - loss: 0.5343 - accuracy: 0.7935 - val_loss: 0.5301 - val_accuracy: 0.8250 - 28ms/epoch - 9ms/step\n",
            "Epoch 369/500\n",
            "3/3 - 0s - loss: 0.5331 - accuracy: 0.8152 - val_loss: 0.5299 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 370/500\n",
            "3/3 - 0s - loss: 0.5328 - accuracy: 0.8043 - val_loss: 0.5295 - val_accuracy: 0.8250 - 29ms/epoch - 10ms/step\n",
            "Epoch 371/500\n",
            "3/3 - 0s - loss: 0.5326 - accuracy: 0.8152 - val_loss: 0.5292 - val_accuracy: 0.8250 - 29ms/epoch - 10ms/step\n",
            "Epoch 372/500\n",
            "3/3 - 0s - loss: 0.5322 - accuracy: 0.8261 - val_loss: 0.5291 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 373/500\n",
            "3/3 - 0s - loss: 0.5321 - accuracy: 0.8043 - val_loss: 0.5290 - val_accuracy: 0.8250 - 37ms/epoch - 12ms/step\n",
            "Epoch 374/500\n",
            "3/3 - 0s - loss: 0.5317 - accuracy: 0.8152 - val_loss: 0.5286 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 375/500\n",
            "3/3 - 0s - loss: 0.5311 - accuracy: 0.8152 - val_loss: 0.5283 - val_accuracy: 0.8250 - 34ms/epoch - 11ms/step\n",
            "Epoch 376/500\n",
            "3/3 - 0s - loss: 0.5310 - accuracy: 0.8043 - val_loss: 0.5281 - val_accuracy: 0.8250 - 35ms/epoch - 12ms/step\n",
            "Epoch 377/500\n",
            "3/3 - 0s - loss: 0.5311 - accuracy: 0.8043 - val_loss: 0.5278 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 378/500\n",
            "3/3 - 0s - loss: 0.5302 - accuracy: 0.8152 - val_loss: 0.5275 - val_accuracy: 0.8250 - 54ms/epoch - 18ms/step\n",
            "Epoch 379/500\n",
            "3/3 - 0s - loss: 0.5302 - accuracy: 0.8043 - val_loss: 0.5274 - val_accuracy: 0.8250 - 27ms/epoch - 9ms/step\n",
            "Epoch 380/500\n",
            "3/3 - 0s - loss: 0.5305 - accuracy: 0.8043 - val_loss: 0.5273 - val_accuracy: 0.8250 - 44ms/epoch - 15ms/step\n",
            "Epoch 381/500\n",
            "3/3 - 0s - loss: 0.5295 - accuracy: 0.8043 - val_loss: 0.5271 - val_accuracy: 0.8250 - 59ms/epoch - 20ms/step\n",
            "Epoch 382/500\n",
            "3/3 - 0s - loss: 0.5292 - accuracy: 0.7935 - val_loss: 0.5269 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 383/500\n",
            "3/3 - 0s - loss: 0.5285 - accuracy: 0.8152 - val_loss: 0.5266 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 384/500\n",
            "3/3 - 0s - loss: 0.5287 - accuracy: 0.8152 - val_loss: 0.5265 - val_accuracy: 0.8000 - 37ms/epoch - 12ms/step\n",
            "Epoch 385/500\n",
            "3/3 - 0s - loss: 0.5282 - accuracy: 0.8152 - val_loss: 0.5262 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 386/500\n",
            "3/3 - 0s - loss: 0.5278 - accuracy: 0.8152 - val_loss: 0.5259 - val_accuracy: 0.8250 - 27ms/epoch - 9ms/step\n",
            "Epoch 387/500\n",
            "3/3 - 0s - loss: 0.5272 - accuracy: 0.8152 - val_loss: 0.5256 - val_accuracy: 0.8250 - 34ms/epoch - 11ms/step\n",
            "Epoch 388/500\n",
            "3/3 - 0s - loss: 0.5270 - accuracy: 0.8152 - val_loss: 0.5254 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 389/500\n",
            "3/3 - 0s - loss: 0.5266 - accuracy: 0.8152 - val_loss: 0.5251 - val_accuracy: 0.8250 - 34ms/epoch - 11ms/step\n",
            "Epoch 390/500\n",
            "3/3 - 0s - loss: 0.5269 - accuracy: 0.8152 - val_loss: 0.5246 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 391/500\n",
            "3/3 - 0s - loss: 0.5263 - accuracy: 0.8043 - val_loss: 0.5244 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 392/500\n",
            "3/3 - 0s - loss: 0.5256 - accuracy: 0.8043 - val_loss: 0.5241 - val_accuracy: 0.8250 - 37ms/epoch - 12ms/step\n",
            "Epoch 393/500\n",
            "3/3 - 0s - loss: 0.5253 - accuracy: 0.8152 - val_loss: 0.5238 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 394/500\n",
            "3/3 - 0s - loss: 0.5253 - accuracy: 0.8043 - val_loss: 0.5238 - val_accuracy: 0.8250 - 34ms/epoch - 11ms/step\n",
            "Epoch 395/500\n",
            "3/3 - 0s - loss: 0.5251 - accuracy: 0.8152 - val_loss: 0.5234 - val_accuracy: 0.8250 - 29ms/epoch - 10ms/step\n",
            "Epoch 396/500\n",
            "3/3 - 0s - loss: 0.5244 - accuracy: 0.7935 - val_loss: 0.5231 - val_accuracy: 0.8250 - 34ms/epoch - 11ms/step\n",
            "Epoch 397/500\n",
            "3/3 - 0s - loss: 0.5242 - accuracy: 0.8152 - val_loss: 0.5228 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 398/500\n",
            "3/3 - 0s - loss: 0.5238 - accuracy: 0.8043 - val_loss: 0.5225 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 399/500\n",
            "3/3 - 0s - loss: 0.5238 - accuracy: 0.8043 - val_loss: 0.5221 - val_accuracy: 0.8250 - 29ms/epoch - 10ms/step\n",
            "Epoch 400/500\n",
            "3/3 - 0s - loss: 0.5236 - accuracy: 0.7935 - val_loss: 0.5218 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 401/500\n",
            "3/3 - 0s - loss: 0.5229 - accuracy: 0.7935 - val_loss: 0.5217 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 402/500\n",
            "3/3 - 0s - loss: 0.5227 - accuracy: 0.7935 - val_loss: 0.5215 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 403/500\n",
            "3/3 - 0s - loss: 0.5223 - accuracy: 0.7935 - val_loss: 0.5212 - val_accuracy: 0.8250 - 29ms/epoch - 10ms/step\n",
            "Epoch 404/500\n",
            "3/3 - 0s - loss: 0.5220 - accuracy: 0.7935 - val_loss: 0.5211 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 405/500\n",
            "3/3 - 0s - loss: 0.5216 - accuracy: 0.7935 - val_loss: 0.5210 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 406/500\n",
            "3/3 - 0s - loss: 0.5212 - accuracy: 0.7935 - val_loss: 0.5208 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 407/500\n",
            "3/3 - 0s - loss: 0.5212 - accuracy: 0.7935 - val_loss: 0.5203 - val_accuracy: 0.8250 - 37ms/epoch - 12ms/step\n",
            "Epoch 408/500\n",
            "3/3 - 0s - loss: 0.5206 - accuracy: 0.7935 - val_loss: 0.5200 - val_accuracy: 0.8250 - 44ms/epoch - 15ms/step\n",
            "Epoch 409/500\n",
            "3/3 - 0s - loss: 0.5203 - accuracy: 0.7935 - val_loss: 0.5199 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 410/500\n",
            "3/3 - 0s - loss: 0.5200 - accuracy: 0.7935 - val_loss: 0.5197 - val_accuracy: 0.8250 - 29ms/epoch - 10ms/step\n",
            "Epoch 411/500\n",
            "3/3 - 0s - loss: 0.5197 - accuracy: 0.7935 - val_loss: 0.5195 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 412/500\n",
            "3/3 - 0s - loss: 0.5197 - accuracy: 0.7935 - val_loss: 0.5191 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 413/500\n",
            "3/3 - 0s - loss: 0.5194 - accuracy: 0.8043 - val_loss: 0.5191 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 414/500\n",
            "3/3 - 0s - loss: 0.5189 - accuracy: 0.7935 - val_loss: 0.5191 - val_accuracy: 0.8250 - 28ms/epoch - 9ms/step\n",
            "Epoch 415/500\n",
            "3/3 - 0s - loss: 0.5193 - accuracy: 0.8043 - val_loss: 0.5191 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 416/500\n",
            "3/3 - 0s - loss: 0.5182 - accuracy: 0.7935 - val_loss: 0.5188 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 417/500\n",
            "3/3 - 0s - loss: 0.5188 - accuracy: 0.7935 - val_loss: 0.5186 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 418/500\n",
            "3/3 - 0s - loss: 0.5175 - accuracy: 0.7935 - val_loss: 0.5183 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 419/500\n",
            "3/3 - 0s - loss: 0.5178 - accuracy: 0.8043 - val_loss: 0.5183 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 420/500\n",
            "3/3 - 0s - loss: 0.5169 - accuracy: 0.7935 - val_loss: 0.5181 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 421/500\n",
            "3/3 - 0s - loss: 0.5168 - accuracy: 0.7935 - val_loss: 0.5179 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 422/500\n",
            "3/3 - 0s - loss: 0.5164 - accuracy: 0.7935 - val_loss: 0.5175 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 423/500\n",
            "3/3 - 0s - loss: 0.5160 - accuracy: 0.7935 - val_loss: 0.5174 - val_accuracy: 0.8250 - 29ms/epoch - 10ms/step\n",
            "Epoch 424/500\n",
            "3/3 - 0s - loss: 0.5161 - accuracy: 0.8043 - val_loss: 0.5172 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 425/500\n",
            "3/3 - 0s - loss: 0.5155 - accuracy: 0.7935 - val_loss: 0.5171 - val_accuracy: 0.8250 - 34ms/epoch - 11ms/step\n",
            "Epoch 426/500\n",
            "3/3 - 0s - loss: 0.5154 - accuracy: 0.8043 - val_loss: 0.5168 - val_accuracy: 0.8250 - 29ms/epoch - 10ms/step\n",
            "Epoch 427/500\n",
            "3/3 - 0s - loss: 0.5149 - accuracy: 0.7935 - val_loss: 0.5165 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 428/500\n",
            "3/3 - 0s - loss: 0.5145 - accuracy: 0.7935 - val_loss: 0.5162 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 429/500\n",
            "3/3 - 0s - loss: 0.5142 - accuracy: 0.7935 - val_loss: 0.5159 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 430/500\n",
            "3/3 - 0s - loss: 0.5140 - accuracy: 0.7935 - val_loss: 0.5156 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 431/500\n",
            "3/3 - 0s - loss: 0.5139 - accuracy: 0.7935 - val_loss: 0.5156 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 432/500\n",
            "3/3 - 0s - loss: 0.5134 - accuracy: 0.7935 - val_loss: 0.5153 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 433/500\n",
            "3/3 - 0s - loss: 0.5142 - accuracy: 0.7826 - val_loss: 0.5154 - val_accuracy: 0.8250 - 47ms/epoch - 16ms/step\n",
            "Epoch 434/500\n",
            "3/3 - 0s - loss: 0.5127 - accuracy: 0.7935 - val_loss: 0.5152 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 435/500\n",
            "3/3 - 0s - loss: 0.5125 - accuracy: 0.7935 - val_loss: 0.5150 - val_accuracy: 0.8250 - 35ms/epoch - 12ms/step\n",
            "Epoch 436/500\n",
            "3/3 - 0s - loss: 0.5123 - accuracy: 0.7935 - val_loss: 0.5149 - val_accuracy: 0.8250 - 42ms/epoch - 14ms/step\n",
            "Epoch 437/500\n",
            "3/3 - 0s - loss: 0.5129 - accuracy: 0.7935 - val_loss: 0.5148 - val_accuracy: 0.8250 - 29ms/epoch - 10ms/step\n",
            "Epoch 438/500\n",
            "3/3 - 0s - loss: 0.5115 - accuracy: 0.7935 - val_loss: 0.5146 - val_accuracy: 0.8250 - 27ms/epoch - 9ms/step\n",
            "Epoch 439/500\n",
            "3/3 - 0s - loss: 0.5114 - accuracy: 0.7935 - val_loss: 0.5141 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 440/500\n",
            "3/3 - 0s - loss: 0.5113 - accuracy: 0.8043 - val_loss: 0.5136 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 441/500\n",
            "3/3 - 0s - loss: 0.5107 - accuracy: 0.7935 - val_loss: 0.5134 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 442/500\n",
            "3/3 - 0s - loss: 0.5104 - accuracy: 0.7935 - val_loss: 0.5131 - val_accuracy: 0.8250 - 26ms/epoch - 9ms/step\n",
            "Epoch 443/500\n",
            "3/3 - 0s - loss: 0.5101 - accuracy: 0.7935 - val_loss: 0.5128 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 444/500\n",
            "3/3 - 0s - loss: 0.5101 - accuracy: 0.7935 - val_loss: 0.5124 - val_accuracy: 0.8250 - 27ms/epoch - 9ms/step\n",
            "Epoch 445/500\n",
            "3/3 - 0s - loss: 0.5098 - accuracy: 0.7935 - val_loss: 0.5120 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 446/500\n",
            "3/3 - 0s - loss: 0.5091 - accuracy: 0.7935 - val_loss: 0.5118 - val_accuracy: 0.8250 - 36ms/epoch - 12ms/step\n",
            "Epoch 447/500\n",
            "3/3 - 0s - loss: 0.5090 - accuracy: 0.7935 - val_loss: 0.5114 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 448/500\n",
            "3/3 - 0s - loss: 0.5089 - accuracy: 0.7935 - val_loss: 0.5111 - val_accuracy: 0.8250 - 36ms/epoch - 12ms/step\n",
            "Epoch 449/500\n",
            "3/3 - 0s - loss: 0.5089 - accuracy: 0.7717 - val_loss: 0.5111 - val_accuracy: 0.8250 - 30ms/epoch - 10ms/step\n",
            "Epoch 450/500\n",
            "3/3 - 0s - loss: 0.5081 - accuracy: 0.7826 - val_loss: 0.5108 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 451/500\n",
            "3/3 - 0s - loss: 0.5077 - accuracy: 0.7935 - val_loss: 0.5106 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 452/500\n",
            "3/3 - 0s - loss: 0.5078 - accuracy: 0.7826 - val_loss: 0.5102 - val_accuracy: 0.8250 - 35ms/epoch - 12ms/step\n",
            "Epoch 453/500\n",
            "3/3 - 0s - loss: 0.5074 - accuracy: 0.7935 - val_loss: 0.5102 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 454/500\n",
            "3/3 - 0s - loss: 0.5068 - accuracy: 0.7826 - val_loss: 0.5101 - val_accuracy: 0.8250 - 28ms/epoch - 9ms/step\n",
            "Epoch 455/500\n",
            "3/3 - 0s - loss: 0.5065 - accuracy: 0.7826 - val_loss: 0.5098 - val_accuracy: 0.8250 - 28ms/epoch - 9ms/step\n",
            "Epoch 456/500\n",
            "3/3 - 0s - loss: 0.5063 - accuracy: 0.7826 - val_loss: 0.5095 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 457/500\n",
            "3/3 - 0s - loss: 0.5060 - accuracy: 0.7826 - val_loss: 0.5093 - val_accuracy: 0.8250 - 41ms/epoch - 14ms/step\n",
            "Epoch 458/500\n",
            "3/3 - 0s - loss: 0.5064 - accuracy: 0.7826 - val_loss: 0.5088 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 459/500\n",
            "3/3 - 0s - loss: 0.5054 - accuracy: 0.7826 - val_loss: 0.5086 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 460/500\n",
            "3/3 - 0s - loss: 0.5051 - accuracy: 0.7935 - val_loss: 0.5084 - val_accuracy: 0.8250 - 27ms/epoch - 9ms/step\n",
            "Epoch 461/500\n",
            "3/3 - 0s - loss: 0.5049 - accuracy: 0.8043 - val_loss: 0.5083 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 462/500\n",
            "3/3 - 0s - loss: 0.5045 - accuracy: 0.8043 - val_loss: 0.5081 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 463/500\n",
            "3/3 - 0s - loss: 0.5054 - accuracy: 0.7935 - val_loss: 0.5076 - val_accuracy: 0.8250 - 35ms/epoch - 12ms/step\n",
            "Epoch 464/500\n",
            "3/3 - 0s - loss: 0.5041 - accuracy: 0.7935 - val_loss: 0.5076 - val_accuracy: 0.8250 - 43ms/epoch - 14ms/step\n",
            "Epoch 465/500\n",
            "3/3 - 0s - loss: 0.5041 - accuracy: 0.7826 - val_loss: 0.5072 - val_accuracy: 0.8250 - 34ms/epoch - 11ms/step\n",
            "Epoch 466/500\n",
            "3/3 - 0s - loss: 0.5036 - accuracy: 0.7826 - val_loss: 0.5069 - val_accuracy: 0.8250 - 34ms/epoch - 11ms/step\n",
            "Epoch 467/500\n",
            "3/3 - 0s - loss: 0.5033 - accuracy: 0.8043 - val_loss: 0.5068 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 468/500\n",
            "3/3 - 0s - loss: 0.5030 - accuracy: 0.8043 - val_loss: 0.5065 - val_accuracy: 0.8250 - 26ms/epoch - 9ms/step\n",
            "Epoch 469/500\n",
            "3/3 - 0s - loss: 0.5025 - accuracy: 0.7935 - val_loss: 0.5064 - val_accuracy: 0.8250 - 38ms/epoch - 13ms/step\n",
            "Epoch 470/500\n",
            "3/3 - 0s - loss: 0.5026 - accuracy: 0.7935 - val_loss: 0.5062 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 471/500\n",
            "3/3 - 0s - loss: 0.5022 - accuracy: 0.8043 - val_loss: 0.5062 - val_accuracy: 0.8250 - 49ms/epoch - 16ms/step\n",
            "Epoch 472/500\n",
            "3/3 - 0s - loss: 0.5020 - accuracy: 0.7935 - val_loss: 0.5061 - val_accuracy: 0.8250 - 29ms/epoch - 10ms/step\n",
            "Epoch 473/500\n",
            "3/3 - 0s - loss: 0.5014 - accuracy: 0.7935 - val_loss: 0.5060 - val_accuracy: 0.8250 - 29ms/epoch - 10ms/step\n",
            "Epoch 474/500\n",
            "3/3 - 0s - loss: 0.5011 - accuracy: 0.7826 - val_loss: 0.5057 - val_accuracy: 0.8250 - 28ms/epoch - 9ms/step\n",
            "Epoch 475/500\n",
            "3/3 - 0s - loss: 0.5014 - accuracy: 0.7826 - val_loss: 0.5057 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 476/500\n",
            "3/3 - 0s - loss: 0.5006 - accuracy: 0.7935 - val_loss: 0.5055 - val_accuracy: 0.8250 - 37ms/epoch - 12ms/step\n",
            "Epoch 477/500\n",
            "3/3 - 0s - loss: 0.5002 - accuracy: 0.7826 - val_loss: 0.5053 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 478/500\n",
            "3/3 - 0s - loss: 0.4999 - accuracy: 0.7935 - val_loss: 0.5051 - val_accuracy: 0.8250 - 34ms/epoch - 11ms/step\n",
            "Epoch 479/500\n",
            "3/3 - 0s - loss: 0.5003 - accuracy: 0.7935 - val_loss: 0.5050 - val_accuracy: 0.8250 - 38ms/epoch - 13ms/step\n",
            "Epoch 480/500\n",
            "3/3 - 0s - loss: 0.4996 - accuracy: 0.7935 - val_loss: 0.5049 - val_accuracy: 0.8250 - 36ms/epoch - 12ms/step\n",
            "Epoch 481/500\n",
            "3/3 - 0s - loss: 0.4998 - accuracy: 0.7717 - val_loss: 0.5045 - val_accuracy: 0.8250 - 37ms/epoch - 12ms/step\n",
            "Epoch 482/500\n",
            "3/3 - 0s - loss: 0.4989 - accuracy: 0.8043 - val_loss: 0.5044 - val_accuracy: 0.8250 - 36ms/epoch - 12ms/step\n",
            "Epoch 483/500\n",
            "3/3 - 0s - loss: 0.4986 - accuracy: 0.7826 - val_loss: 0.5041 - val_accuracy: 0.8250 - 35ms/epoch - 12ms/step\n",
            "Epoch 484/500\n",
            "3/3 - 0s - loss: 0.4982 - accuracy: 0.7935 - val_loss: 0.5038 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 485/500\n",
            "3/3 - 0s - loss: 0.4988 - accuracy: 0.8043 - val_loss: 0.5033 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 486/500\n",
            "3/3 - 0s - loss: 0.4980 - accuracy: 0.8043 - val_loss: 0.5031 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 487/500\n",
            "3/3 - 0s - loss: 0.4982 - accuracy: 0.7826 - val_loss: 0.5027 - val_accuracy: 0.8250 - 34ms/epoch - 11ms/step\n",
            "Epoch 488/500\n",
            "3/3 - 0s - loss: 0.4974 - accuracy: 0.8152 - val_loss: 0.5027 - val_accuracy: 0.8250 - 39ms/epoch - 13ms/step\n",
            "Epoch 489/500\n",
            "3/3 - 0s - loss: 0.4972 - accuracy: 0.8152 - val_loss: 0.5025 - val_accuracy: 0.8250 - 35ms/epoch - 12ms/step\n",
            "Epoch 490/500\n",
            "3/3 - 0s - loss: 0.4971 - accuracy: 0.8152 - val_loss: 0.5025 - val_accuracy: 0.8250 - 42ms/epoch - 14ms/step\n",
            "Epoch 491/500\n",
            "3/3 - 0s - loss: 0.4963 - accuracy: 0.8043 - val_loss: 0.5022 - val_accuracy: 0.8250 - 43ms/epoch - 14ms/step\n",
            "Epoch 492/500\n",
            "3/3 - 0s - loss: 0.4965 - accuracy: 0.7935 - val_loss: 0.5020 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 493/500\n",
            "3/3 - 0s - loss: 0.4958 - accuracy: 0.8043 - val_loss: 0.5019 - val_accuracy: 0.8250 - 45ms/epoch - 15ms/step\n",
            "Epoch 494/500\n",
            "3/3 - 0s - loss: 0.4957 - accuracy: 0.8152 - val_loss: 0.5019 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 495/500\n",
            "3/3 - 0s - loss: 0.4953 - accuracy: 0.8043 - val_loss: 0.5016 - val_accuracy: 0.8250 - 37ms/epoch - 12ms/step\n",
            "Epoch 496/500\n",
            "3/3 - 0s - loss: 0.4951 - accuracy: 0.8043 - val_loss: 0.5013 - val_accuracy: 0.8250 - 33ms/epoch - 11ms/step\n",
            "Epoch 497/500\n",
            "3/3 - 0s - loss: 0.4947 - accuracy: 0.8043 - val_loss: 0.5010 - val_accuracy: 0.8250 - 35ms/epoch - 12ms/step\n",
            "Epoch 498/500\n",
            "3/3 - 0s - loss: 0.4944 - accuracy: 0.8152 - val_loss: 0.5010 - val_accuracy: 0.8250 - 32ms/epoch - 11ms/step\n",
            "Epoch 499/500\n",
            "3/3 - 0s - loss: 0.4941 - accuracy: 0.8152 - val_loss: 0.5010 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n",
            "Epoch 500/500\n",
            "3/3 - 0s - loss: 0.4938 - accuracy: 0.8043 - val_loss: 0.5007 - val_accuracy: 0.8250 - 31ms/epoch - 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTAHH0itjdge",
        "outputId": "b426c581-aa89-4734-e312-92274fd09a13"
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.33486426, -0.00460496,  0.13587916, -0.07003993],\n",
              "        [-0.13433142,  0.16585825, -0.44167703, -0.24456531],\n",
              "        [-0.3724018 , -0.05249836,  0.24716502,  0.29377836],\n",
              "        [-0.1448647 ,  0.17519447,  0.03873882,  0.27581936],\n",
              "        [-0.3217867 ,  0.45924124, -0.12802416,  0.24038684],\n",
              "        [-0.3818035 , -0.24456634, -0.43976   , -0.42288655],\n",
              "        [-0.32775614,  0.08491308, -0.37005356,  0.18720293],\n",
              "        [-0.3458829 , -0.14222392, -0.3245712 , -0.27869993],\n",
              "        [-0.09751844, -0.18230063,  0.39573193, -0.2890197 ],\n",
              "        [ 0.08522726,  0.5470415 , -0.3708643 ,  0.01806441],\n",
              "        [ 0.19085248, -0.07525028, -0.44461268,  0.27636743],\n",
              "        [-0.11253668, -0.32970244, -0.09619015, -0.20942259],\n",
              "        [ 0.06614646, -0.33559546, -0.42879713, -0.05849329],\n",
              "        [ 0.06484749,  0.05297977,  0.25364447,  0.07343835],\n",
              "        [ 0.08815283, -0.04547486, -0.25887692, -0.3569521 ],\n",
              "        [ 0.3317852 ,  0.26765412,  0.4035254 , -0.00343007],\n",
              "        [ 0.395556  ,  0.02802218,  0.16953814, -0.22230564],\n",
              "        [ 0.06466333,  0.46979618, -0.05747116, -0.253285  ],\n",
              "        [ 0.14625598,  0.56632364, -0.08410558,  0.4235546 ],\n",
              "        [ 0.33743787, -0.02115632, -0.45227888,  0.15202063],\n",
              "        [-0.31128472, -0.13788103, -0.35514417,  0.27853465],\n",
              "        [ 0.50776625,  0.86165696, -0.42284143,  0.2828018 ],\n",
              "        [ 0.18203205, -0.1784667 , -0.32974744, -0.34403747],\n",
              "        [-0.1197935 ,  0.17095838,  0.35433984,  0.29475558],\n",
              "        [-0.18598202,  0.387252  , -0.0477308 , -0.17359903]],\n",
              "       dtype=float32),\n",
              " array([-0.04566934, -0.3909596 ,  0.        ,  0.        ], dtype=float32),\n",
              " array([[ 0.6730899 ],\n",
              "        [ 1.7577596 ],\n",
              "        [ 0.15678167],\n",
              "        [-0.12659544]], dtype=float32),\n",
              " array([-0.7227318], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-OYyiHSjdge"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XIu4OuHdjdgf",
        "outputId": "e9cbfa06-68ab-4089-846d-e2ce8f3a7db4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7WDfelMjdgf",
        "outputId": "6259ab9c-f6ca-42c1-abe9-cde9e58a3c3d"
      },
      "source": [
        "from sklearn.metrics import log_loss\n",
        "y_pred_prob = model.predict(X_test)\n",
        "log_loss(y_true=y_test,y_pred=y_pred_prob)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:2442: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:2442: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2BSdIdLjdgf",
        "outputId": "be495baa-100d-499f-844a-215185623738"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "predict_probs= model.predict(X_test)\n",
        "predict_probs[:5]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.42811814],\n",
              "       [0.6829158 ],\n",
              "       [0.46297607],\n",
              "       [0.3267917 ],\n",
              "       [0.79117537]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ4gWVKZkqEt",
        "outputId": "22aa76ea-02f5-4142-c23c-cf992c8e2686"
      },
      "source": [
        "predict_classes = np.where(predict_probs>=0.5,1,0)\n",
        "predict_classes[:5]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpeU5c0RkjUC",
        "outputId": "1763ab7c-dd19-47c5-ecb7-9e248ef5cd66"
      },
      "source": [
        "acc = accuracy_score(y_test,predict_classes)\n",
        "print(f\"Accuracy: {acc}\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.825\n"
          ]
        }
      ]
    }
  ]
}