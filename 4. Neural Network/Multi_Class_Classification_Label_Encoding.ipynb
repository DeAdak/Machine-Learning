{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88ZueHajDBTr"
   },
   "source": [
    "# Keras for Multi-Class Classification\n",
    "\n",
    "This notebook demonstrates the use of keras functions for multi-class classification problem, Satellite Imaging Dataset, from *source*, UCI repository, a  database was generated\n",
    "from data purchased from NASA by the Australian Centre\n",
    "for Remote Sensing, and used for research at: The Centre for Remote Sensing,NSW 2033,Australia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWSmrnYfDPZI",
    "outputId": "30c7a9d2-966b-4adf-9391-5f8e1ff7774e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGiVMbqsDBTu"
   },
   "source": [
    "Necessary Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qxRRz2XDBTw"
   },
   "source": [
    "Importing the file into **pandas** dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "JreyR9wmDBTx",
    "outputId": "da6bb1c7-aa7b-4e72-ac59-dd7a6e29a660"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x.1</th>\n",
       "      <th>x.2</th>\n",
       "      <th>x.3</th>\n",
       "      <th>x.4</th>\n",
       "      <th>x.5</th>\n",
       "      <th>x.6</th>\n",
       "      <th>x.7</th>\n",
       "      <th>x.8</th>\n",
       "      <th>x.9</th>\n",
       "      <th>x.10</th>\n",
       "      <th>...</th>\n",
       "      <th>x.28</th>\n",
       "      <th>x.29</th>\n",
       "      <th>x.30</th>\n",
       "      <th>x.31</th>\n",
       "      <th>x.32</th>\n",
       "      <th>x.33</th>\n",
       "      <th>x.34</th>\n",
       "      <th>x.35</th>\n",
       "      <th>x.36</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>115</td>\n",
       "      <td>120</td>\n",
       "      <td>94</td>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>106</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>88</td>\n",
       "      <td>121</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "      <td>87</td>\n",
       "      <td>grey soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>106</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>grey soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>grey soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>grey soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "      <td>98</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>107</td>\n",
       "      <td>109</td>\n",
       "      <td>87</td>\n",
       "      <td>grey soil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x.1  x.2  x.3  x.4  x.5  x.6  x.7  x.8  x.9  x.10  ...  x.28  x.29  x.30  \\\n",
       "0   92  115  120   94   84  102  106   79   84   102  ...   104    88   121   \n",
       "1   84  102  106   79   84  102  102   83   80   102  ...   100    84   107   \n",
       "2   84  102  102   83   80  102  102   79   84    94  ...    87    84    99   \n",
       "3   80  102  102   79   84   94  102   79   80    94  ...    79    84    99   \n",
       "4   84   94  102   79   80   94   98   76   80   102  ...    79    84   103   \n",
       "\n",
       "   x.31  x.32  x.33  x.34  x.35  x.36    classes  \n",
       "0   128   100    84   107   113    87  grey soil  \n",
       "1   113    87    84    99   104    79  grey soil  \n",
       "2   104    79    84    99   104    79  grey soil  \n",
       "3   104    79    84   103   104    79  grey soil  \n",
       "4   104    79    79   107   109    87  grey soil  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"G:\\Ddrive\\PG DBDA\\12 Practical Machine Learning_/Cases/Satellite Imaging/Satellite.csv\",sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVWK7YrcDBTx",
    "outputId": "044cfc74-c1ad-44ed-9139-bd3202b785fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grey soil' 'damp grey soil' 'vegetation stubble' 'very damp grey soil'\n",
      " 'cotton crop' 'red soil']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"classes\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_vEmlnYDBTy",
    "outputId": "405b0556-3d51-48d2-f70a-f61b005c8956"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6435, 37)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m13mL60mDBTz"
   },
   "source": [
    "For the column **classes** which is a response variable, the hot encoding / dummying needs to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "enXllxtbDBTz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    grey soil\n",
       "1    grey soil\n",
       "2    grey soil\n",
       "3    grey soil\n",
       "4    grey soil\n",
       "Name: classes, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:,-1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbcode = LabelEncoder()\n",
    "y = lbcode.fit_transform(y)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Lq731-PDBT0"
   },
   "source": [
    "We now create two separate objects for feature variables X  and output variable   y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l8H4POBDDBT0"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "0tlT3nkMDBT0",
    "outputId": "944fc198-12a1-4860-c254-424e26611322"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x.1</th>\n",
       "      <th>x.2</th>\n",
       "      <th>x.3</th>\n",
       "      <th>x.4</th>\n",
       "      <th>x.5</th>\n",
       "      <th>x.6</th>\n",
       "      <th>x.7</th>\n",
       "      <th>x.8</th>\n",
       "      <th>x.9</th>\n",
       "      <th>x.10</th>\n",
       "      <th>...</th>\n",
       "      <th>x.27</th>\n",
       "      <th>x.28</th>\n",
       "      <th>x.29</th>\n",
       "      <th>x.30</th>\n",
       "      <th>x.31</th>\n",
       "      <th>x.32</th>\n",
       "      <th>x.33</th>\n",
       "      <th>x.34</th>\n",
       "      <th>x.35</th>\n",
       "      <th>x.36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>115</td>\n",
       "      <td>120</td>\n",
       "      <td>94</td>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>106</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>104</td>\n",
       "      <td>88</td>\n",
       "      <td>121</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>106</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "      <td>98</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>107</td>\n",
       "      <td>109</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x.1  x.2  x.3  x.4  x.5  x.6  x.7  x.8  x.9  x.10  ...  x.27  x.28  x.29  \\\n",
       "0   92  115  120   94   84  102  106   79   84   102  ...   134   104    88   \n",
       "1   84  102  106   79   84  102  102   83   80   102  ...   128   100    84   \n",
       "2   84  102  102   83   80  102  102   79   84    94  ...   113    87    84   \n",
       "3   80  102  102   79   84   94  102   79   80    94  ...   104    79    84   \n",
       "4   84   94  102   79   80   94   98   76   80   102  ...   104    79    84   \n",
       "\n",
       "   x.30  x.31  x.32  x.33  x.34  x.35  x.36  \n",
       "0   121   128   100    84   107   113    87  \n",
       "1   107   113    87    84    99   104    79  \n",
       "2    99   104    79    84    99   104    79  \n",
       "3    99   104    79    84   103   104    79  \n",
       "4   103   104    79    79   107   109    87  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBwAezqQDBT1"
   },
   "source": [
    "Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDvS3ckwDBT1"
   },
   "source": [
    "We now, split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-gKaP2nLDBT2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, \n",
    "                                                    random_state=2024,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fEPAOZOkDBT1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7eGpunSDBT2",
    "outputId": "d4455d20-2244-4d71-b5ec-59be00b110b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5791, 36), (5791,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gatFnBKaDBT2"
   },
   "source": [
    "Let us now define the neural network through which we plan to build the MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4O9R21lDBT2"
   },
   "source": [
    "Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "H8Zpk3wrDBT2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcRxrLjGDBT3"
   },
   "source": [
    "**Model Definition:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TyAXdvF0DBT3"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(2021)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(7, activation='relu',input_shape=(X_train.shape[1], )), \n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')  \n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVpAUF3GDBT3"
   },
   "source": [
    "**Model Fitting:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RpYs9QiDBT3",
    "outputId": "26c67872-18ca-4b9b-e64e-58fb8742483c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "181/181 - 6s - loss: 1.6867 - accuracy: 0.4571 - val_loss: 1.5365 - val_accuracy: 0.3665 - 6s/epoch - 31ms/step\n",
      "Epoch 2/1000\n",
      "181/181 - 1s - loss: 1.3350 - accuracy: 0.5115 - val_loss: 1.1725 - val_accuracy: 0.5481 - 873ms/epoch - 5ms/step\n",
      "Epoch 3/1000\n",
      "181/181 - 1s - loss: 1.0755 - accuracy: 0.5607 - val_loss: 1.0174 - val_accuracy: 0.5901 - 833ms/epoch - 5ms/step\n",
      "Epoch 4/1000\n",
      "181/181 - 1s - loss: 0.9567 - accuracy: 0.6234 - val_loss: 0.9343 - val_accuracy: 0.6615 - 839ms/epoch - 5ms/step\n",
      "Epoch 5/1000\n",
      "181/181 - 1s - loss: 0.8898 - accuracy: 0.6795 - val_loss: 0.8915 - val_accuracy: 0.6941 - 841ms/epoch - 5ms/step\n",
      "Epoch 6/1000\n",
      "181/181 - 1s - loss: 0.8484 - accuracy: 0.7013 - val_loss: 0.8689 - val_accuracy: 0.6910 - 836ms/epoch - 5ms/step\n",
      "Epoch 7/1000\n",
      "181/181 - 1s - loss: 0.8153 - accuracy: 0.7130 - val_loss: 0.8308 - val_accuracy: 0.7143 - 901ms/epoch - 5ms/step\n",
      "Epoch 8/1000\n",
      "181/181 - 1s - loss: 0.7933 - accuracy: 0.7116 - val_loss: 0.8152 - val_accuracy: 0.7096 - 1s/epoch - 6ms/step\n",
      "Epoch 9/1000\n",
      "181/181 - 1s - loss: 0.7735 - accuracy: 0.7175 - val_loss: 0.8017 - val_accuracy: 0.7143 - 1s/epoch - 6ms/step\n",
      "Epoch 10/1000\n",
      "181/181 - 1s - loss: 0.7596 - accuracy: 0.7168 - val_loss: 0.7945 - val_accuracy: 0.7034 - 1s/epoch - 6ms/step\n",
      "Epoch 11/1000\n",
      "181/181 - 1s - loss: 0.7475 - accuracy: 0.7180 - val_loss: 0.7833 - val_accuracy: 0.7143 - 1s/epoch - 6ms/step\n",
      "Epoch 12/1000\n",
      "181/181 - 1s - loss: 0.7366 - accuracy: 0.7182 - val_loss: 0.7719 - val_accuracy: 0.7205 - 1s/epoch - 6ms/step\n",
      "Epoch 13/1000\n",
      "181/181 - 1s - loss: 0.7278 - accuracy: 0.7220 - val_loss: 0.7654 - val_accuracy: 0.7174 - 950ms/epoch - 5ms/step\n",
      "Epoch 14/1000\n",
      "181/181 - 1s - loss: 0.7186 - accuracy: 0.7239 - val_loss: 0.7581 - val_accuracy: 0.7174 - 988ms/epoch - 5ms/step\n",
      "Epoch 15/1000\n",
      "181/181 - 1s - loss: 0.7123 - accuracy: 0.7246 - val_loss: 0.7534 - val_accuracy: 0.7236 - 999ms/epoch - 6ms/step\n",
      "Epoch 16/1000\n",
      "181/181 - 1s - loss: 0.7048 - accuracy: 0.7249 - val_loss: 0.7430 - val_accuracy: 0.7252 - 887ms/epoch - 5ms/step\n",
      "Epoch 17/1000\n",
      "181/181 - 1s - loss: 0.6974 - accuracy: 0.7273 - val_loss: 0.7471 - val_accuracy: 0.7220 - 843ms/epoch - 5ms/step\n",
      "Epoch 18/1000\n",
      "181/181 - 1s - loss: 0.6934 - accuracy: 0.7273 - val_loss: 0.7312 - val_accuracy: 0.7298 - 839ms/epoch - 5ms/step\n",
      "Epoch 19/1000\n",
      "181/181 - 1s - loss: 0.6855 - accuracy: 0.7301 - val_loss: 0.7288 - val_accuracy: 0.7205 - 933ms/epoch - 5ms/step\n",
      "Epoch 20/1000\n",
      "181/181 - 1s - loss: 0.6824 - accuracy: 0.7277 - val_loss: 0.7202 - val_accuracy: 0.7298 - 836ms/epoch - 5ms/step\n",
      "Epoch 21/1000\n",
      "181/181 - 1s - loss: 0.6784 - accuracy: 0.7296 - val_loss: 0.7164 - val_accuracy: 0.7314 - 870ms/epoch - 5ms/step\n",
      "Epoch 22/1000\n",
      "181/181 - 1s - loss: 0.6695 - accuracy: 0.7311 - val_loss: 0.7096 - val_accuracy: 0.7345 - 847ms/epoch - 5ms/step\n",
      "Epoch 23/1000\n",
      "181/181 - 1s - loss: 0.6665 - accuracy: 0.7332 - val_loss: 0.7076 - val_accuracy: 0.7267 - 842ms/epoch - 5ms/step\n",
      "Epoch 24/1000\n",
      "181/181 - 1s - loss: 0.6614 - accuracy: 0.7339 - val_loss: 0.7016 - val_accuracy: 0.7345 - 834ms/epoch - 5ms/step\n",
      "Epoch 25/1000\n",
      "181/181 - 1s - loss: 0.6558 - accuracy: 0.7365 - val_loss: 0.6953 - val_accuracy: 0.7453 - 841ms/epoch - 5ms/step\n",
      "Epoch 26/1000\n",
      "181/181 - 1s - loss: 0.6507 - accuracy: 0.7405 - val_loss: 0.6912 - val_accuracy: 0.7453 - 836ms/epoch - 5ms/step\n",
      "Epoch 27/1000\n",
      "181/181 - 1s - loss: 0.6432 - accuracy: 0.7472 - val_loss: 0.6849 - val_accuracy: 0.7453 - 836ms/epoch - 5ms/step\n",
      "Epoch 28/1000\n",
      "181/181 - 1s - loss: 0.6420 - accuracy: 0.7470 - val_loss: 0.6913 - val_accuracy: 0.7360 - 845ms/epoch - 5ms/step\n",
      "Epoch 29/1000\n",
      "181/181 - 1s - loss: 0.6356 - accuracy: 0.7481 - val_loss: 0.6797 - val_accuracy: 0.7500 - 833ms/epoch - 5ms/step\n",
      "Epoch 30/1000\n",
      "181/181 - 1s - loss: 0.6296 - accuracy: 0.7539 - val_loss: 0.6791 - val_accuracy: 0.7547 - 837ms/epoch - 5ms/step\n",
      "Epoch 31/1000\n",
      "181/181 - 1s - loss: 0.6251 - accuracy: 0.7626 - val_loss: 0.6667 - val_accuracy: 0.7748 - 839ms/epoch - 5ms/step\n",
      "Epoch 32/1000\n",
      "181/181 - 1s - loss: 0.6219 - accuracy: 0.7688 - val_loss: 0.6858 - val_accuracy: 0.7484 - 979ms/epoch - 5ms/step\n",
      "Epoch 33/1000\n",
      "181/181 - 1s - loss: 0.6158 - accuracy: 0.7693 - val_loss: 0.6595 - val_accuracy: 0.7811 - 852ms/epoch - 5ms/step\n",
      "Epoch 34/1000\n",
      "181/181 - 1s - loss: 0.6158 - accuracy: 0.7669 - val_loss: 0.6542 - val_accuracy: 0.7780 - 834ms/epoch - 5ms/step\n",
      "Epoch 35/1000\n",
      "181/181 - 1s - loss: 0.6091 - accuracy: 0.7734 - val_loss: 0.6496 - val_accuracy: 0.7857 - 838ms/epoch - 5ms/step\n",
      "Epoch 36/1000\n",
      "181/181 - 1s - loss: 0.6050 - accuracy: 0.7778 - val_loss: 0.6432 - val_accuracy: 0.7919 - 832ms/epoch - 5ms/step\n",
      "Epoch 37/1000\n",
      "181/181 - 1s - loss: 0.6003 - accuracy: 0.7781 - val_loss: 0.6520 - val_accuracy: 0.7811 - 835ms/epoch - 5ms/step\n",
      "Epoch 38/1000\n",
      "181/181 - 1s - loss: 0.5966 - accuracy: 0.7812 - val_loss: 0.6436 - val_accuracy: 0.7795 - 878ms/epoch - 5ms/step\n",
      "Epoch 39/1000\n",
      "181/181 - 1s - loss: 0.5903 - accuracy: 0.7821 - val_loss: 0.6373 - val_accuracy: 0.7904 - 841ms/epoch - 5ms/step\n",
      "Epoch 40/1000\n",
      "181/181 - 1s - loss: 0.5890 - accuracy: 0.7828 - val_loss: 0.6486 - val_accuracy: 0.7764 - 843ms/epoch - 5ms/step\n",
      "Epoch 41/1000\n",
      "181/181 - 1s - loss: 0.5835 - accuracy: 0.7864 - val_loss: 0.6254 - val_accuracy: 0.7981 - 832ms/epoch - 5ms/step\n",
      "Epoch 42/1000\n",
      "181/181 - 1s - loss: 0.5776 - accuracy: 0.7867 - val_loss: 0.6225 - val_accuracy: 0.7981 - 954ms/epoch - 5ms/step\n",
      "Epoch 43/1000\n",
      "181/181 - 1s - loss: 0.5763 - accuracy: 0.7841 - val_loss: 0.6207 - val_accuracy: 0.8012 - 966ms/epoch - 5ms/step\n",
      "Epoch 44/1000\n",
      "181/181 - 1s - loss: 0.5721 - accuracy: 0.7874 - val_loss: 0.6203 - val_accuracy: 0.7966 - 1s/epoch - 6ms/step\n",
      "Epoch 45/1000\n",
      "181/181 - 1s - loss: 0.5652 - accuracy: 0.7893 - val_loss: 0.6271 - val_accuracy: 0.7966 - 942ms/epoch - 5ms/step\n",
      "Epoch 46/1000\n",
      "181/181 - 1s - loss: 0.5647 - accuracy: 0.7898 - val_loss: 0.6171 - val_accuracy: 0.7981 - 931ms/epoch - 5ms/step\n",
      "Epoch 47/1000\n",
      "181/181 - 1s - loss: 0.5588 - accuracy: 0.7909 - val_loss: 0.6068 - val_accuracy: 0.8012 - 878ms/epoch - 5ms/step\n",
      "Epoch 48/1000\n",
      "181/181 - 1s - loss: 0.5560 - accuracy: 0.7912 - val_loss: 0.6011 - val_accuracy: 0.8043 - 860ms/epoch - 5ms/step\n",
      "Epoch 49/1000\n",
      "181/181 - 1s - loss: 0.5556 - accuracy: 0.7955 - val_loss: 0.6143 - val_accuracy: 0.8043 - 904ms/epoch - 5ms/step\n",
      "Epoch 50/1000\n",
      "181/181 - 1s - loss: 0.5487 - accuracy: 0.7917 - val_loss: 0.5973 - val_accuracy: 0.8043 - 980ms/epoch - 5ms/step\n",
      "Epoch 51/1000\n",
      "181/181 - 1s - loss: 0.5451 - accuracy: 0.7933 - val_loss: 0.5948 - val_accuracy: 0.8090 - 986ms/epoch - 5ms/step\n",
      "Epoch 52/1000\n",
      "181/181 - 1s - loss: 0.5448 - accuracy: 0.7917 - val_loss: 0.5913 - val_accuracy: 0.8059 - 931ms/epoch - 5ms/step\n",
      "Epoch 53/1000\n",
      "181/181 - 1s - loss: 0.5385 - accuracy: 0.7971 - val_loss: 0.5981 - val_accuracy: 0.8043 - 917ms/epoch - 5ms/step\n",
      "Epoch 54/1000\n",
      "181/181 - 1s - loss: 0.5401 - accuracy: 0.7968 - val_loss: 0.5879 - val_accuracy: 0.8043 - 853ms/epoch - 5ms/step\n",
      "Epoch 55/1000\n",
      "181/181 - 1s - loss: 0.5355 - accuracy: 0.7987 - val_loss: 0.5900 - val_accuracy: 0.7997 - 1s/epoch - 6ms/step\n",
      "Epoch 56/1000\n",
      "181/181 - 1s - loss: 0.5320 - accuracy: 0.7976 - val_loss: 0.5895 - val_accuracy: 0.8168 - 950ms/epoch - 5ms/step\n",
      "Epoch 57/1000\n",
      "181/181 - 1s - loss: 0.5277 - accuracy: 0.8019 - val_loss: 0.5968 - val_accuracy: 0.8168 - 1s/epoch - 6ms/step\n",
      "Epoch 58/1000\n",
      "181/181 - 1s - loss: 0.5254 - accuracy: 0.7999 - val_loss: 0.5814 - val_accuracy: 0.8137 - 969ms/epoch - 5ms/step\n",
      "Epoch 59/1000\n",
      "181/181 - 1s - loss: 0.5254 - accuracy: 0.8012 - val_loss: 0.5850 - val_accuracy: 0.8106 - 952ms/epoch - 5ms/step\n",
      "Epoch 60/1000\n",
      "181/181 - 1s - loss: 0.5203 - accuracy: 0.8025 - val_loss: 0.5780 - val_accuracy: 0.8075 - 940ms/epoch - 5ms/step\n",
      "Epoch 61/1000\n",
      "181/181 - 1s - loss: 0.5201 - accuracy: 0.8018 - val_loss: 0.5712 - val_accuracy: 0.8168 - 921ms/epoch - 5ms/step\n",
      "Epoch 62/1000\n",
      "181/181 - 1s - loss: 0.5187 - accuracy: 0.8011 - val_loss: 0.5685 - val_accuracy: 0.8152 - 913ms/epoch - 5ms/step\n",
      "Epoch 63/1000\n",
      "181/181 - 1s - loss: 0.5163 - accuracy: 0.8069 - val_loss: 0.5677 - val_accuracy: 0.8137 - 920ms/epoch - 5ms/step\n",
      "Epoch 64/1000\n",
      "181/181 - 1s - loss: 0.5127 - accuracy: 0.8033 - val_loss: 0.5752 - val_accuracy: 0.8183 - 911ms/epoch - 5ms/step\n",
      "Epoch 65/1000\n",
      "181/181 - 1s - loss: 0.5108 - accuracy: 0.8068 - val_loss: 0.5752 - val_accuracy: 0.8106 - 1s/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000\n",
      "181/181 - 1s - loss: 0.5107 - accuracy: 0.8023 - val_loss: 0.5775 - val_accuracy: 0.8230 - 1s/epoch - 6ms/step\n",
      "Epoch 67/1000\n",
      "181/181 - 1s - loss: 0.5059 - accuracy: 0.8068 - val_loss: 0.5600 - val_accuracy: 0.8214 - 937ms/epoch - 5ms/step\n",
      "Epoch 68/1000\n",
      "181/181 - 1s - loss: 0.5055 - accuracy: 0.8101 - val_loss: 0.5756 - val_accuracy: 0.8261 - 912ms/epoch - 5ms/step\n",
      "Epoch 69/1000\n",
      "181/181 - 1s - loss: 0.5050 - accuracy: 0.8090 - val_loss: 0.5597 - val_accuracy: 0.8183 - 908ms/epoch - 5ms/step\n",
      "Epoch 70/1000\n",
      "181/181 - 1s - loss: 0.5042 - accuracy: 0.8088 - val_loss: 0.5677 - val_accuracy: 0.8261 - 845ms/epoch - 5ms/step\n",
      "Epoch 71/1000\n",
      "181/181 - 1s - loss: 0.5031 - accuracy: 0.8092 - val_loss: 0.5534 - val_accuracy: 0.8276 - 827ms/epoch - 5ms/step\n",
      "Epoch 72/1000\n",
      "181/181 - 1s - loss: 0.5010 - accuracy: 0.8080 - val_loss: 0.5670 - val_accuracy: 0.8152 - 840ms/epoch - 5ms/step\n",
      "Epoch 73/1000\n",
      "181/181 - 1s - loss: 0.5016 - accuracy: 0.8068 - val_loss: 0.5531 - val_accuracy: 0.8261 - 838ms/epoch - 5ms/step\n",
      "Epoch 74/1000\n",
      "181/181 - 1s - loss: 0.4996 - accuracy: 0.8145 - val_loss: 0.5600 - val_accuracy: 0.8168 - 973ms/epoch - 5ms/step\n",
      "Epoch 75/1000\n",
      "181/181 - 1s - loss: 0.4966 - accuracy: 0.8119 - val_loss: 0.5560 - val_accuracy: 0.8199 - 945ms/epoch - 5ms/step\n",
      "Epoch 76/1000\n",
      "181/181 - 1s - loss: 0.4974 - accuracy: 0.8106 - val_loss: 0.5513 - val_accuracy: 0.8261 - 956ms/epoch - 5ms/step\n",
      "Epoch 77/1000\n",
      "181/181 - 1s - loss: 0.4921 - accuracy: 0.8138 - val_loss: 0.5593 - val_accuracy: 0.8199 - 1s/epoch - 6ms/step\n",
      "Epoch 78/1000\n",
      "181/181 - 1s - loss: 0.4938 - accuracy: 0.8152 - val_loss: 0.5512 - val_accuracy: 0.8245 - 975ms/epoch - 5ms/step\n",
      "Epoch 79/1000\n",
      "181/181 - 1s - loss: 0.4900 - accuracy: 0.8137 - val_loss: 0.5469 - val_accuracy: 0.8214 - 1s/epoch - 6ms/step\n",
      "Epoch 80/1000\n",
      "181/181 - 1s - loss: 0.4926 - accuracy: 0.8121 - val_loss: 0.5452 - val_accuracy: 0.8307 - 1s/epoch - 6ms/step\n",
      "Epoch 81/1000\n",
      "181/181 - 1s - loss: 0.4900 - accuracy: 0.8176 - val_loss: 0.5505 - val_accuracy: 0.8261 - 1s/epoch - 6ms/step\n",
      "Epoch 82/1000\n",
      "181/181 - 1s - loss: 0.4893 - accuracy: 0.8164 - val_loss: 0.5439 - val_accuracy: 0.8292 - 852ms/epoch - 5ms/step\n",
      "Epoch 83/1000\n",
      "181/181 - 1s - loss: 0.4905 - accuracy: 0.8149 - val_loss: 0.5453 - val_accuracy: 0.8230 - 846ms/epoch - 5ms/step\n",
      "Epoch 84/1000\n",
      "181/181 - 1s - loss: 0.4884 - accuracy: 0.8133 - val_loss: 0.5510 - val_accuracy: 0.8183 - 841ms/epoch - 5ms/step\n",
      "Epoch 85/1000\n",
      "181/181 - 1s - loss: 0.4878 - accuracy: 0.8137 - val_loss: 0.5397 - val_accuracy: 0.8276 - 848ms/epoch - 5ms/step\n",
      "Epoch 86/1000\n",
      "181/181 - 1s - loss: 0.4879 - accuracy: 0.8147 - val_loss: 0.5450 - val_accuracy: 0.8307 - 878ms/epoch - 5ms/step\n",
      "Epoch 87/1000\n",
      "181/181 - 1s - loss: 0.4820 - accuracy: 0.8166 - val_loss: 0.5356 - val_accuracy: 0.8307 - 922ms/epoch - 5ms/step\n",
      "Epoch 88/1000\n",
      "181/181 - 1s - loss: 0.4824 - accuracy: 0.8159 - val_loss: 0.5512 - val_accuracy: 0.8199 - 847ms/epoch - 5ms/step\n",
      "Epoch 89/1000\n",
      "181/181 - 1s - loss: 0.4812 - accuracy: 0.8164 - val_loss: 0.5362 - val_accuracy: 0.8385 - 880ms/epoch - 5ms/step\n",
      "Epoch 90/1000\n",
      "181/181 - 1s - loss: 0.4797 - accuracy: 0.8192 - val_loss: 0.5419 - val_accuracy: 0.8214 - 991ms/epoch - 5ms/step\n",
      "Epoch 91/1000\n",
      "181/181 - 1s - loss: 0.4793 - accuracy: 0.8190 - val_loss: 0.5332 - val_accuracy: 0.8354 - 961ms/epoch - 5ms/step\n",
      "Epoch 92/1000\n",
      "181/181 - 1s - loss: 0.4789 - accuracy: 0.8187 - val_loss: 0.5477 - val_accuracy: 0.8261 - 877ms/epoch - 5ms/step\n",
      "Epoch 93/1000\n",
      "181/181 - 1s - loss: 0.4778 - accuracy: 0.8232 - val_loss: 0.5322 - val_accuracy: 0.8385 - 861ms/epoch - 5ms/step\n",
      "Epoch 94/1000\n",
      "181/181 - 1s - loss: 0.4790 - accuracy: 0.8213 - val_loss: 0.5358 - val_accuracy: 0.8292 - 836ms/epoch - 5ms/step\n",
      "Epoch 95/1000\n",
      "181/181 - 1s - loss: 0.4795 - accuracy: 0.8197 - val_loss: 0.5313 - val_accuracy: 0.8339 - 831ms/epoch - 5ms/step\n",
      "Epoch 96/1000\n",
      "181/181 - 1s - loss: 0.4741 - accuracy: 0.8214 - val_loss: 0.5352 - val_accuracy: 0.8292 - 828ms/epoch - 5ms/step\n",
      "Epoch 97/1000\n",
      "181/181 - 1s - loss: 0.4744 - accuracy: 0.8258 - val_loss: 0.5273 - val_accuracy: 0.8416 - 942ms/epoch - 5ms/step\n",
      "Epoch 98/1000\n",
      "181/181 - 1s - loss: 0.4762 - accuracy: 0.8173 - val_loss: 0.5266 - val_accuracy: 0.8401 - 916ms/epoch - 5ms/step\n",
      "Epoch 99/1000\n",
      "181/181 - 1s - loss: 0.4765 - accuracy: 0.8225 - val_loss: 0.5287 - val_accuracy: 0.8385 - 828ms/epoch - 5ms/step\n",
      "Epoch 100/1000\n",
      "181/181 - 1s - loss: 0.4738 - accuracy: 0.8230 - val_loss: 0.5273 - val_accuracy: 0.8401 - 826ms/epoch - 5ms/step\n",
      "Epoch 101/1000\n",
      "181/181 - 1s - loss: 0.4679 - accuracy: 0.8254 - val_loss: 0.5296 - val_accuracy: 0.8339 - 844ms/epoch - 5ms/step\n",
      "Epoch 102/1000\n",
      "181/181 - 1s - loss: 0.4724 - accuracy: 0.8265 - val_loss: 0.5248 - val_accuracy: 0.8432 - 1s/epoch - 6ms/step\n",
      "Epoch 103/1000\n",
      "181/181 - 1s - loss: 0.4739 - accuracy: 0.8230 - val_loss: 0.5261 - val_accuracy: 0.8385 - 918ms/epoch - 5ms/step\n",
      "Epoch 104/1000\n",
      "181/181 - 1s - loss: 0.4669 - accuracy: 0.8256 - val_loss: 0.5249 - val_accuracy: 0.8416 - 959ms/epoch - 5ms/step\n",
      "Epoch 105/1000\n",
      "181/181 - 1s - loss: 0.4666 - accuracy: 0.8278 - val_loss: 0.5413 - val_accuracy: 0.8323 - 1s/epoch - 6ms/step\n",
      "Epoch 106/1000\n",
      "181/181 - 1s - loss: 0.4680 - accuracy: 0.8247 - val_loss: 0.5272 - val_accuracy: 0.8432 - 863ms/epoch - 5ms/step\n",
      "Epoch 107/1000\n",
      "181/181 - 1s - loss: 0.4671 - accuracy: 0.8251 - val_loss: 0.5238 - val_accuracy: 0.8292 - 1s/epoch - 6ms/step\n",
      "Epoch 108/1000\n",
      "181/181 - 1s - loss: 0.4670 - accuracy: 0.8227 - val_loss: 0.5187 - val_accuracy: 0.8447 - 828ms/epoch - 5ms/step\n",
      "Epoch 109/1000\n",
      "181/181 - 1s - loss: 0.4617 - accuracy: 0.8251 - val_loss: 0.5310 - val_accuracy: 0.8401 - 885ms/epoch - 5ms/step\n",
      "Epoch 110/1000\n",
      "181/181 - 1s - loss: 0.4626 - accuracy: 0.8284 - val_loss: 0.5205 - val_accuracy: 0.8416 - 964ms/epoch - 5ms/step\n",
      "Epoch 111/1000\n",
      "181/181 - 1s - loss: 0.4621 - accuracy: 0.8270 - val_loss: 0.5333 - val_accuracy: 0.8323 - 979ms/epoch - 5ms/step\n",
      "Epoch 112/1000\n",
      "181/181 - 1s - loss: 0.4615 - accuracy: 0.8266 - val_loss: 0.5221 - val_accuracy: 0.8401 - 921ms/epoch - 5ms/step\n",
      "Epoch 113/1000\n",
      "181/181 - 1s - loss: 0.4620 - accuracy: 0.8277 - val_loss: 0.5173 - val_accuracy: 0.8478 - 1s/epoch - 6ms/step\n",
      "Epoch 114/1000\n",
      "181/181 - 1s - loss: 0.4559 - accuracy: 0.8296 - val_loss: 0.5294 - val_accuracy: 0.8339 - 1s/epoch - 6ms/step\n",
      "Epoch 115/1000\n",
      "181/181 - 1s - loss: 0.4530 - accuracy: 0.8290 - val_loss: 0.5209 - val_accuracy: 0.8494 - 1s/epoch - 6ms/step\n",
      "Epoch 116/1000\n",
      "181/181 - 1s - loss: 0.4474 - accuracy: 0.8358 - val_loss: 0.5057 - val_accuracy: 0.8494 - 1s/epoch - 6ms/step\n",
      "Epoch 117/1000\n",
      "181/181 - 1s - loss: 0.4472 - accuracy: 0.8327 - val_loss: 0.5109 - val_accuracy: 0.8385 - 1s/epoch - 6ms/step\n",
      "Epoch 118/1000\n",
      "181/181 - 1s - loss: 0.4457 - accuracy: 0.8341 - val_loss: 0.5064 - val_accuracy: 0.8463 - 924ms/epoch - 5ms/step\n",
      "Epoch 119/1000\n",
      "181/181 - 1s - loss: 0.4452 - accuracy: 0.8349 - val_loss: 0.5094 - val_accuracy: 0.8447 - 875ms/epoch - 5ms/step\n",
      "Epoch 120/1000\n",
      "181/181 - 1s - loss: 0.4452 - accuracy: 0.8384 - val_loss: 0.4996 - val_accuracy: 0.8494 - 993ms/epoch - 5ms/step\n",
      "Epoch 121/1000\n",
      "181/181 - 1s - loss: 0.4424 - accuracy: 0.8346 - val_loss: 0.5071 - val_accuracy: 0.8432 - 930ms/epoch - 5ms/step\n",
      "Epoch 122/1000\n",
      "181/181 - 1s - loss: 0.4390 - accuracy: 0.8351 - val_loss: 0.5130 - val_accuracy: 0.8354 - 882ms/epoch - 5ms/step\n",
      "Epoch 123/1000\n",
      "181/181 - 1s - loss: 0.4377 - accuracy: 0.8363 - val_loss: 0.4987 - val_accuracy: 0.8416 - 938ms/epoch - 5ms/step\n",
      "Epoch 124/1000\n",
      "181/181 - 1s - loss: 0.4408 - accuracy: 0.8380 - val_loss: 0.4949 - val_accuracy: 0.8463 - 925ms/epoch - 5ms/step\n",
      "Epoch 125/1000\n",
      "181/181 - 1s - loss: 0.4339 - accuracy: 0.8372 - val_loss: 0.5045 - val_accuracy: 0.8432 - 835ms/epoch - 5ms/step\n",
      "Epoch 126/1000\n",
      "181/181 - 1s - loss: 0.4351 - accuracy: 0.8415 - val_loss: 0.5089 - val_accuracy: 0.8494 - 834ms/epoch - 5ms/step\n",
      "Epoch 127/1000\n",
      "181/181 - 1s - loss: 0.4393 - accuracy: 0.8339 - val_loss: 0.4907 - val_accuracy: 0.8494 - 834ms/epoch - 5ms/step\n",
      "Epoch 128/1000\n",
      "181/181 - 1s - loss: 0.4330 - accuracy: 0.8413 - val_loss: 0.4895 - val_accuracy: 0.8494 - 829ms/epoch - 5ms/step\n",
      "Epoch 129/1000\n",
      "181/181 - 1s - loss: 0.4318 - accuracy: 0.8396 - val_loss: 0.4905 - val_accuracy: 0.8463 - 847ms/epoch - 5ms/step\n",
      "Epoch 130/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 - 1s - loss: 0.4315 - accuracy: 0.8403 - val_loss: 0.4846 - val_accuracy: 0.8525 - 834ms/epoch - 5ms/step\n",
      "Epoch 131/1000\n",
      "181/181 - 1s - loss: 0.4319 - accuracy: 0.8365 - val_loss: 0.4848 - val_accuracy: 0.8478 - 830ms/epoch - 5ms/step\n",
      "Epoch 132/1000\n",
      "181/181 - 1s - loss: 0.4284 - accuracy: 0.8387 - val_loss: 0.4827 - val_accuracy: 0.8494 - 837ms/epoch - 5ms/step\n",
      "Epoch 133/1000\n",
      "181/181 - 1s - loss: 0.4262 - accuracy: 0.8406 - val_loss: 0.4946 - val_accuracy: 0.8478 - 839ms/epoch - 5ms/step\n",
      "Epoch 134/1000\n",
      "181/181 - 1s - loss: 0.4277 - accuracy: 0.8368 - val_loss: 0.4957 - val_accuracy: 0.8370 - 890ms/epoch - 5ms/step\n",
      "Epoch 135/1000\n",
      "181/181 - 1s - loss: 0.4261 - accuracy: 0.8413 - val_loss: 0.4790 - val_accuracy: 0.8478 - 872ms/epoch - 5ms/step\n",
      "Epoch 136/1000\n",
      "181/181 - 1s - loss: 0.4250 - accuracy: 0.8427 - val_loss: 0.4838 - val_accuracy: 0.8509 - 1s/epoch - 6ms/step\n",
      "Epoch 137/1000\n",
      "181/181 - 1s - loss: 0.4258 - accuracy: 0.8403 - val_loss: 0.4770 - val_accuracy: 0.8463 - 920ms/epoch - 5ms/step\n",
      "Epoch 138/1000\n",
      "181/181 - 1s - loss: 0.4273 - accuracy: 0.8417 - val_loss: 0.4801 - val_accuracy: 0.8525 - 1s/epoch - 6ms/step\n",
      "Epoch 139/1000\n",
      "181/181 - 1s - loss: 0.4218 - accuracy: 0.8411 - val_loss: 0.4918 - val_accuracy: 0.8385 - 1s/epoch - 6ms/step\n",
      "Epoch 140/1000\n",
      "181/181 - 1s - loss: 0.4261 - accuracy: 0.8377 - val_loss: 0.4814 - val_accuracy: 0.8494 - 957ms/epoch - 5ms/step\n",
      "Epoch 141/1000\n",
      "181/181 - 1s - loss: 0.4209 - accuracy: 0.8408 - val_loss: 0.4875 - val_accuracy: 0.8447 - 967ms/epoch - 5ms/step\n",
      "Epoch 142/1000\n",
      "181/181 - 1s - loss: 0.4190 - accuracy: 0.8427 - val_loss: 0.4775 - val_accuracy: 0.8509 - 942ms/epoch - 5ms/step\n",
      "Epoch 143/1000\n",
      "181/181 - 1s - loss: 0.4190 - accuracy: 0.8396 - val_loss: 0.4924 - val_accuracy: 0.8370 - 935ms/epoch - 5ms/step\n",
      "Epoch 144/1000\n",
      "181/181 - 1s - loss: 0.4162 - accuracy: 0.8458 - val_loss: 0.4795 - val_accuracy: 0.8416 - 962ms/epoch - 5ms/step\n",
      "Epoch 145/1000\n",
      "181/181 - 1s - loss: 0.4182 - accuracy: 0.8399 - val_loss: 0.4669 - val_accuracy: 0.8494 - 987ms/epoch - 5ms/step\n",
      "Epoch 146/1000\n",
      "181/181 - 1s - loss: 0.4172 - accuracy: 0.8430 - val_loss: 0.4732 - val_accuracy: 0.8447 - 832ms/epoch - 5ms/step\n",
      "Epoch 147/1000\n",
      "181/181 - 1s - loss: 0.4152 - accuracy: 0.8417 - val_loss: 0.4645 - val_accuracy: 0.8525 - 827ms/epoch - 5ms/step\n",
      "Epoch 148/1000\n",
      "181/181 - 1s - loss: 0.4141 - accuracy: 0.8442 - val_loss: 0.4632 - val_accuracy: 0.8463 - 828ms/epoch - 5ms/step\n",
      "Epoch 149/1000\n",
      "181/181 - 1s - loss: 0.4107 - accuracy: 0.8453 - val_loss: 0.4678 - val_accuracy: 0.8525 - 827ms/epoch - 5ms/step\n",
      "Epoch 150/1000\n",
      "181/181 - 1s - loss: 0.4126 - accuracy: 0.8403 - val_loss: 0.4619 - val_accuracy: 0.8463 - 828ms/epoch - 5ms/step\n",
      "Epoch 151/1000\n",
      "181/181 - 1s - loss: 0.4116 - accuracy: 0.8454 - val_loss: 0.4630 - val_accuracy: 0.8509 - 884ms/epoch - 5ms/step\n",
      "Epoch 152/1000\n",
      "181/181 - 1s - loss: 0.4127 - accuracy: 0.8410 - val_loss: 0.4649 - val_accuracy: 0.8509 - 918ms/epoch - 5ms/step\n",
      "Epoch 153/1000\n",
      "181/181 - 1s - loss: 0.4080 - accuracy: 0.8436 - val_loss: 0.4582 - val_accuracy: 0.8494 - 837ms/epoch - 5ms/step\n",
      "Epoch 154/1000\n",
      "181/181 - 1s - loss: 0.4082 - accuracy: 0.8439 - val_loss: 0.4563 - val_accuracy: 0.8478 - 834ms/epoch - 5ms/step\n",
      "Epoch 155/1000\n",
      "181/181 - 1s - loss: 0.4077 - accuracy: 0.8460 - val_loss: 0.4558 - val_accuracy: 0.8525 - 831ms/epoch - 5ms/step\n",
      "Epoch 156/1000\n",
      "181/181 - 1s - loss: 0.4080 - accuracy: 0.8463 - val_loss: 0.4564 - val_accuracy: 0.8494 - 830ms/epoch - 5ms/step\n",
      "Epoch 157/1000\n",
      "181/181 - 1s - loss: 0.4082 - accuracy: 0.8446 - val_loss: 0.4545 - val_accuracy: 0.8478 - 829ms/epoch - 5ms/step\n",
      "Epoch 158/1000\n",
      "181/181 - 1s - loss: 0.4056 - accuracy: 0.8446 - val_loss: 0.4534 - val_accuracy: 0.8540 - 841ms/epoch - 5ms/step\n",
      "Epoch 159/1000\n",
      "181/181 - 1s - loss: 0.4095 - accuracy: 0.8427 - val_loss: 0.4556 - val_accuracy: 0.8525 - 829ms/epoch - 5ms/step\n",
      "Epoch 160/1000\n",
      "181/181 - 1s - loss: 0.4067 - accuracy: 0.8448 - val_loss: 0.4700 - val_accuracy: 0.8385 - 829ms/epoch - 5ms/step\n",
      "Epoch 161/1000\n",
      "181/181 - 1s - loss: 0.4059 - accuracy: 0.8460 - val_loss: 0.4518 - val_accuracy: 0.8478 - 832ms/epoch - 5ms/step\n",
      "Epoch 162/1000\n",
      "181/181 - 1s - loss: 0.4040 - accuracy: 0.8432 - val_loss: 0.4529 - val_accuracy: 0.8478 - 914ms/epoch - 5ms/step\n",
      "Epoch 163/1000\n",
      "181/181 - 1s - loss: 0.4013 - accuracy: 0.8453 - val_loss: 0.4488 - val_accuracy: 0.8494 - 834ms/epoch - 5ms/step\n",
      "Epoch 164/1000\n",
      "181/181 - 1s - loss: 0.3994 - accuracy: 0.8442 - val_loss: 0.4487 - val_accuracy: 0.8556 - 1s/epoch - 6ms/step\n",
      "Epoch 165/1000\n",
      "181/181 - 1s - loss: 0.4007 - accuracy: 0.8494 - val_loss: 0.4510 - val_accuracy: 0.8494 - 955ms/epoch - 5ms/step\n",
      "Epoch 166/1000\n",
      "181/181 - 1s - loss: 0.3983 - accuracy: 0.8442 - val_loss: 0.4485 - val_accuracy: 0.8494 - 989ms/epoch - 5ms/step\n",
      "Epoch 167/1000\n",
      "181/181 - 1s - loss: 0.3981 - accuracy: 0.8480 - val_loss: 0.4466 - val_accuracy: 0.8525 - 989ms/epoch - 5ms/step\n",
      "Epoch 168/1000\n",
      "181/181 - 1s - loss: 0.3994 - accuracy: 0.8458 - val_loss: 0.4432 - val_accuracy: 0.8447 - 1s/epoch - 6ms/step\n",
      "Epoch 169/1000\n",
      "181/181 - 1s - loss: 0.3962 - accuracy: 0.8460 - val_loss: 0.4426 - val_accuracy: 0.8525 - 973ms/epoch - 5ms/step\n",
      "Epoch 170/1000\n",
      "181/181 - 1s - loss: 0.3954 - accuracy: 0.8482 - val_loss: 0.4431 - val_accuracy: 0.8571 - 849ms/epoch - 5ms/step\n",
      "Epoch 171/1000\n",
      "181/181 - 1s - loss: 0.3919 - accuracy: 0.8511 - val_loss: 0.4412 - val_accuracy: 0.8478 - 857ms/epoch - 5ms/step\n",
      "Epoch 172/1000\n",
      "181/181 - 1s - loss: 0.3959 - accuracy: 0.8467 - val_loss: 0.4637 - val_accuracy: 0.8370 - 1s/epoch - 6ms/step\n",
      "Epoch 173/1000\n",
      "181/181 - 1s - loss: 0.3953 - accuracy: 0.8468 - val_loss: 0.4465 - val_accuracy: 0.8525 - 891ms/epoch - 5ms/step\n",
      "Epoch 174/1000\n",
      "181/181 - 1s - loss: 0.3921 - accuracy: 0.8482 - val_loss: 0.4576 - val_accuracy: 0.8432 - 865ms/epoch - 5ms/step\n",
      "Epoch 175/1000\n",
      "181/181 - 1s - loss: 0.3941 - accuracy: 0.8487 - val_loss: 0.4455 - val_accuracy: 0.8556 - 830ms/epoch - 5ms/step\n",
      "Epoch 176/1000\n",
      "181/181 - 1s - loss: 0.3898 - accuracy: 0.8498 - val_loss: 0.4478 - val_accuracy: 0.8602 - 839ms/epoch - 5ms/step\n",
      "Epoch 177/1000\n",
      "181/181 - 1s - loss: 0.3961 - accuracy: 0.8486 - val_loss: 0.4422 - val_accuracy: 0.8478 - 831ms/epoch - 5ms/step\n",
      "Epoch 178/1000\n",
      "181/181 - 1s - loss: 0.3945 - accuracy: 0.8453 - val_loss: 0.4390 - val_accuracy: 0.8540 - 866ms/epoch - 5ms/step\n",
      "Epoch 179/1000\n",
      "181/181 - 1s - loss: 0.3889 - accuracy: 0.8463 - val_loss: 0.4396 - val_accuracy: 0.8447 - 845ms/epoch - 5ms/step\n",
      "Epoch 180/1000\n",
      "181/181 - 1s - loss: 0.3896 - accuracy: 0.8480 - val_loss: 0.4381 - val_accuracy: 0.8463 - 830ms/epoch - 5ms/step\n",
      "Epoch 181/1000\n",
      "181/181 - 1s - loss: 0.3863 - accuracy: 0.8511 - val_loss: 0.4325 - val_accuracy: 0.8494 - 827ms/epoch - 5ms/step\n",
      "Epoch 182/1000\n",
      "181/181 - 1s - loss: 0.3893 - accuracy: 0.8477 - val_loss: 0.4511 - val_accuracy: 0.8323 - 834ms/epoch - 5ms/step\n",
      "Epoch 183/1000\n",
      "181/181 - 1s - loss: 0.3875 - accuracy: 0.8467 - val_loss: 0.4267 - val_accuracy: 0.8540 - 830ms/epoch - 5ms/step\n",
      "Epoch 184/1000\n",
      "181/181 - 1s - loss: 0.3834 - accuracy: 0.8496 - val_loss: 0.4286 - val_accuracy: 0.8525 - 829ms/epoch - 5ms/step\n",
      "Epoch 185/1000\n",
      "181/181 - 1s - loss: 0.3831 - accuracy: 0.8492 - val_loss: 0.4313 - val_accuracy: 0.8509 - 933ms/epoch - 5ms/step\n",
      "Epoch 186/1000\n",
      "181/181 - 1s - loss: 0.3860 - accuracy: 0.8499 - val_loss: 0.4349 - val_accuracy: 0.8494 - 972ms/epoch - 5ms/step\n",
      "Epoch 187/1000\n",
      "181/181 - 1s - loss: 0.3822 - accuracy: 0.8506 - val_loss: 0.4334 - val_accuracy: 0.8478 - 1s/epoch - 6ms/step\n",
      "Epoch 188/1000\n",
      "181/181 - 1s - loss: 0.3863 - accuracy: 0.8518 - val_loss: 0.4295 - val_accuracy: 0.8556 - 977ms/epoch - 5ms/step\n",
      "Epoch 189/1000\n",
      "181/181 - 1s - loss: 0.3799 - accuracy: 0.8539 - val_loss: 0.4262 - val_accuracy: 0.8525 - 978ms/epoch - 5ms/step\n",
      "Epoch 190/1000\n",
      "181/181 - 1s - loss: 0.3796 - accuracy: 0.8517 - val_loss: 0.4291 - val_accuracy: 0.8509 - 883ms/epoch - 5ms/step\n",
      "Epoch 191/1000\n",
      "181/181 - 1s - loss: 0.3795 - accuracy: 0.8534 - val_loss: 0.4202 - val_accuracy: 0.8587 - 885ms/epoch - 5ms/step\n",
      "Epoch 192/1000\n",
      "181/181 - 1s - loss: 0.3799 - accuracy: 0.8525 - val_loss: 0.4284 - val_accuracy: 0.8432 - 870ms/epoch - 5ms/step\n",
      "Epoch 193/1000\n",
      "181/181 - 1s - loss: 0.3785 - accuracy: 0.8505 - val_loss: 0.4263 - val_accuracy: 0.8540 - 846ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/1000\n",
      "181/181 - 1s - loss: 0.3793 - accuracy: 0.8511 - val_loss: 0.4192 - val_accuracy: 0.8634 - 835ms/epoch - 5ms/step\n",
      "Epoch 195/1000\n",
      "181/181 - 1s - loss: 0.3778 - accuracy: 0.8536 - val_loss: 0.4181 - val_accuracy: 0.8509 - 840ms/epoch - 5ms/step\n",
      "Epoch 196/1000\n",
      "181/181 - 1s - loss: 0.3753 - accuracy: 0.8536 - val_loss: 0.4189 - val_accuracy: 0.8587 - 922ms/epoch - 5ms/step\n",
      "Epoch 197/1000\n",
      "181/181 - 1s - loss: 0.3744 - accuracy: 0.8534 - val_loss: 0.4154 - val_accuracy: 0.8571 - 1s/epoch - 6ms/step\n",
      "Epoch 198/1000\n",
      "181/181 - 1s - loss: 0.3730 - accuracy: 0.8515 - val_loss: 0.4111 - val_accuracy: 0.8509 - 905ms/epoch - 5ms/step\n",
      "Epoch 199/1000\n",
      "181/181 - 1s - loss: 0.3737 - accuracy: 0.8520 - val_loss: 0.4115 - val_accuracy: 0.8540 - 836ms/epoch - 5ms/step\n",
      "Epoch 200/1000\n",
      "181/181 - 1s - loss: 0.3737 - accuracy: 0.8539 - val_loss: 0.4113 - val_accuracy: 0.8602 - 831ms/epoch - 5ms/step\n",
      "Epoch 201/1000\n",
      "181/181 - 1s - loss: 0.3826 - accuracy: 0.8511 - val_loss: 0.4174 - val_accuracy: 0.8540 - 830ms/epoch - 5ms/step\n",
      "Epoch 202/1000\n",
      "181/181 - 1s - loss: 0.3717 - accuracy: 0.8511 - val_loss: 0.4151 - val_accuracy: 0.8571 - 833ms/epoch - 5ms/step\n",
      "Epoch 203/1000\n",
      "181/181 - 1s - loss: 0.3683 - accuracy: 0.8560 - val_loss: 0.4521 - val_accuracy: 0.8478 - 832ms/epoch - 5ms/step\n",
      "Epoch 204/1000\n",
      "181/181 - 1s - loss: 0.3739 - accuracy: 0.8565 - val_loss: 0.4103 - val_accuracy: 0.8571 - 829ms/epoch - 5ms/step\n",
      "Epoch 205/1000\n",
      "181/181 - 1s - loss: 0.3681 - accuracy: 0.8551 - val_loss: 0.4073 - val_accuracy: 0.8556 - 1s/epoch - 6ms/step\n",
      "Epoch 206/1000\n",
      "181/181 - 1s - loss: 0.3688 - accuracy: 0.8562 - val_loss: 0.4138 - val_accuracy: 0.8634 - 1s/epoch - 6ms/step\n",
      "Epoch 207/1000\n",
      "181/181 - 1s - loss: 0.3700 - accuracy: 0.8553 - val_loss: 0.4109 - val_accuracy: 0.8602 - 1s/epoch - 8ms/step\n",
      "Epoch 208/1000\n",
      "181/181 - 2s - loss: 0.3712 - accuracy: 0.8581 - val_loss: 0.4151 - val_accuracy: 0.8494 - 2s/epoch - 11ms/step\n",
      "Epoch 209/1000\n",
      "181/181 - 2s - loss: 0.3693 - accuracy: 0.8539 - val_loss: 0.4062 - val_accuracy: 0.8634 - 2s/epoch - 13ms/step\n",
      "Epoch 210/1000\n",
      "181/181 - 2s - loss: 0.3674 - accuracy: 0.8574 - val_loss: 0.4148 - val_accuracy: 0.8602 - 2s/epoch - 11ms/step\n",
      "Epoch 211/1000\n",
      "181/181 - 2s - loss: 0.3676 - accuracy: 0.8539 - val_loss: 0.4016 - val_accuracy: 0.8587 - 2s/epoch - 9ms/step\n",
      "Epoch 212/1000\n",
      "181/181 - 2s - loss: 0.3660 - accuracy: 0.8563 - val_loss: 0.4043 - val_accuracy: 0.8618 - 2s/epoch - 10ms/step\n",
      "Epoch 213/1000\n",
      "181/181 - 1s - loss: 0.3656 - accuracy: 0.8577 - val_loss: 0.4036 - val_accuracy: 0.8587 - 1s/epoch - 8ms/step\n",
      "Epoch 214/1000\n",
      "181/181 - 1s - loss: 0.3685 - accuracy: 0.8541 - val_loss: 0.4084 - val_accuracy: 0.8525 - 1s/epoch - 8ms/step\n",
      "Epoch 215/1000\n",
      "181/181 - 1s - loss: 0.3643 - accuracy: 0.8570 - val_loss: 0.4048 - val_accuracy: 0.8587 - 1s/epoch - 7ms/step\n",
      "Epoch 216/1000\n",
      "181/181 - 1s - loss: 0.3617 - accuracy: 0.8556 - val_loss: 0.3998 - val_accuracy: 0.8634 - 1s/epoch - 6ms/step\n",
      "Epoch 217/1000\n",
      "181/181 - 2s - loss: 0.3631 - accuracy: 0.8603 - val_loss: 0.3995 - val_accuracy: 0.8649 - 2s/epoch - 9ms/step\n",
      "Epoch 218/1000\n",
      "181/181 - 1s - loss: 0.3658 - accuracy: 0.8565 - val_loss: 0.3931 - val_accuracy: 0.8587 - 1s/epoch - 7ms/step\n",
      "Epoch 219/1000\n",
      "181/181 - 1s - loss: 0.3607 - accuracy: 0.8596 - val_loss: 0.3932 - val_accuracy: 0.8618 - 1s/epoch - 7ms/step\n",
      "Epoch 220/1000\n",
      "181/181 - 1s - loss: 0.3608 - accuracy: 0.8587 - val_loss: 0.3912 - val_accuracy: 0.8680 - 1s/epoch - 7ms/step\n",
      "Epoch 221/1000\n",
      "181/181 - 2s - loss: 0.3650 - accuracy: 0.8586 - val_loss: 0.4214 - val_accuracy: 0.8494 - 2s/epoch - 10ms/step\n",
      "Epoch 222/1000\n",
      "181/181 - 2s - loss: 0.3633 - accuracy: 0.8605 - val_loss: 0.3994 - val_accuracy: 0.8618 - 2s/epoch - 9ms/step\n",
      "Epoch 223/1000\n",
      "181/181 - 2s - loss: 0.3637 - accuracy: 0.8598 - val_loss: 0.4004 - val_accuracy: 0.8618 - 2s/epoch - 9ms/step\n",
      "Epoch 224/1000\n",
      "181/181 - 2s - loss: 0.3607 - accuracy: 0.8598 - val_loss: 0.3891 - val_accuracy: 0.8602 - 2s/epoch - 9ms/step\n",
      "Epoch 225/1000\n",
      "181/181 - 2s - loss: 0.3609 - accuracy: 0.8594 - val_loss: 0.3985 - val_accuracy: 0.8634 - 2s/epoch - 10ms/step\n",
      "Epoch 226/1000\n",
      "181/181 - 2s - loss: 0.3602 - accuracy: 0.8612 - val_loss: 0.3947 - val_accuracy: 0.8602 - 2s/epoch - 10ms/step\n",
      "Epoch 227/1000\n",
      "181/181 - 2s - loss: 0.3622 - accuracy: 0.8572 - val_loss: 0.3878 - val_accuracy: 0.8618 - 2s/epoch - 10ms/step\n",
      "Epoch 228/1000\n",
      "181/181 - 2s - loss: 0.3583 - accuracy: 0.8608 - val_loss: 0.3848 - val_accuracy: 0.8571 - 2s/epoch - 9ms/step\n",
      "Epoch 229/1000\n",
      "181/181 - 1s - loss: 0.3599 - accuracy: 0.8601 - val_loss: 0.3862 - val_accuracy: 0.8618 - 1s/epoch - 7ms/step\n",
      "Epoch 230/1000\n",
      "181/181 - 1s - loss: 0.3591 - accuracy: 0.8600 - val_loss: 0.3908 - val_accuracy: 0.8649 - 1s/epoch - 7ms/step\n",
      "Epoch 231/1000\n",
      "181/181 - 1s - loss: 0.3599 - accuracy: 0.8608 - val_loss: 0.3840 - val_accuracy: 0.8649 - 1s/epoch - 7ms/step\n",
      "Epoch 232/1000\n",
      "181/181 - 1s - loss: 0.3603 - accuracy: 0.8589 - val_loss: 0.3856 - val_accuracy: 0.8618 - 1s/epoch - 7ms/step\n",
      "Epoch 233/1000\n",
      "181/181 - 1s - loss: 0.3593 - accuracy: 0.8608 - val_loss: 0.3804 - val_accuracy: 0.8634 - 1s/epoch - 7ms/step\n",
      "Epoch 234/1000\n",
      "181/181 - 1s - loss: 0.3610 - accuracy: 0.8596 - val_loss: 0.3875 - val_accuracy: 0.8618 - 1s/epoch - 7ms/step\n",
      "Epoch 235/1000\n",
      "181/181 - 1s - loss: 0.3568 - accuracy: 0.8627 - val_loss: 0.3830 - val_accuracy: 0.8649 - 1s/epoch - 8ms/step\n",
      "Epoch 236/1000\n",
      "181/181 - 1s - loss: 0.3564 - accuracy: 0.8617 - val_loss: 0.3847 - val_accuracy: 0.8665 - 1s/epoch - 6ms/step\n",
      "Epoch 237/1000\n",
      "181/181 - 1s - loss: 0.3538 - accuracy: 0.8625 - val_loss: 0.3832 - val_accuracy: 0.8602 - 1s/epoch - 6ms/step\n",
      "Epoch 238/1000\n",
      "181/181 - 1s - loss: 0.3570 - accuracy: 0.8617 - val_loss: 0.3769 - val_accuracy: 0.8680 - 1s/epoch - 6ms/step\n",
      "Epoch 239/1000\n",
      "181/181 - 1s - loss: 0.3538 - accuracy: 0.8622 - val_loss: 0.3873 - val_accuracy: 0.8540 - 1s/epoch - 7ms/step\n",
      "Epoch 240/1000\n",
      "181/181 - 1s - loss: 0.3552 - accuracy: 0.8612 - val_loss: 0.3755 - val_accuracy: 0.8696 - 1s/epoch - 7ms/step\n",
      "Epoch 241/1000\n",
      "181/181 - 1s - loss: 0.3506 - accuracy: 0.8632 - val_loss: 0.3799 - val_accuracy: 0.8602 - 1s/epoch - 7ms/step\n",
      "Epoch 242/1000\n",
      "181/181 - 1s - loss: 0.3542 - accuracy: 0.8612 - val_loss: 0.3782 - val_accuracy: 0.8618 - 1s/epoch - 6ms/step\n",
      "Epoch 243/1000\n",
      "181/181 - 1s - loss: 0.3544 - accuracy: 0.8600 - val_loss: 0.3734 - val_accuracy: 0.8696 - 1s/epoch - 6ms/step\n",
      "Epoch 244/1000\n",
      "181/181 - 1s - loss: 0.3510 - accuracy: 0.8639 - val_loss: 0.3776 - val_accuracy: 0.8602 - 901ms/epoch - 5ms/step\n",
      "Epoch 245/1000\n",
      "181/181 - 1s - loss: 0.3522 - accuracy: 0.8639 - val_loss: 0.3821 - val_accuracy: 0.8649 - 860ms/epoch - 5ms/step\n",
      "Epoch 246/1000\n",
      "181/181 - 1s - loss: 0.3527 - accuracy: 0.8605 - val_loss: 0.3735 - val_accuracy: 0.8680 - 1s/epoch - 6ms/step\n",
      "Epoch 247/1000\n",
      "181/181 - 1s - loss: 0.3525 - accuracy: 0.8610 - val_loss: 0.3726 - val_accuracy: 0.8634 - 1s/epoch - 7ms/step\n",
      "Epoch 248/1000\n",
      "181/181 - 1s - loss: 0.3526 - accuracy: 0.8600 - val_loss: 0.3740 - val_accuracy: 0.8680 - 1s/epoch - 8ms/step\n",
      "Epoch 249/1000\n",
      "181/181 - 1s - loss: 0.3486 - accuracy: 0.8620 - val_loss: 0.3759 - val_accuracy: 0.8665 - 1s/epoch - 6ms/step\n",
      "Epoch 250/1000\n",
      "181/181 - 1s - loss: 0.3526 - accuracy: 0.8596 - val_loss: 0.3720 - val_accuracy: 0.8665 - 1s/epoch - 6ms/step\n",
      "Epoch 251/1000\n",
      "181/181 - 1s - loss: 0.3489 - accuracy: 0.8613 - val_loss: 0.3708 - val_accuracy: 0.8711 - 1s/epoch - 7ms/step\n",
      "Epoch 252/1000\n",
      "181/181 - 1s - loss: 0.3539 - accuracy: 0.8622 - val_loss: 0.3803 - val_accuracy: 0.8618 - 1s/epoch - 6ms/step\n",
      "Epoch 253/1000\n",
      "181/181 - 1s - loss: 0.3528 - accuracy: 0.8598 - val_loss: 0.3676 - val_accuracy: 0.8665 - 1s/epoch - 6ms/step\n",
      "Epoch 254/1000\n",
      "181/181 - 1s - loss: 0.3483 - accuracy: 0.8620 - val_loss: 0.3737 - val_accuracy: 0.8711 - 1s/epoch - 6ms/step\n",
      "Epoch 255/1000\n",
      "181/181 - 1s - loss: 0.3480 - accuracy: 0.8610 - val_loss: 0.3728 - val_accuracy: 0.8665 - 1s/epoch - 6ms/step\n",
      "Epoch 256/1000\n",
      "181/181 - 1s - loss: 0.3502 - accuracy: 0.8622 - val_loss: 0.3753 - val_accuracy: 0.8665 - 944ms/epoch - 5ms/step\n",
      "Epoch 257/1000\n",
      "181/181 - 1s - loss: 0.3486 - accuracy: 0.8629 - val_loss: 0.3825 - val_accuracy: 0.8602 - 957ms/epoch - 5ms/step\n",
      "Epoch 258/1000\n",
      "181/181 - 1s - loss: 0.3494 - accuracy: 0.8596 - val_loss: 0.3703 - val_accuracy: 0.8649 - 991ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/1000\n",
      "181/181 - 1s - loss: 0.3500 - accuracy: 0.8605 - val_loss: 0.3876 - val_accuracy: 0.8478 - 1s/epoch - 6ms/step\n",
      "Epoch 260/1000\n",
      "181/181 - 1s - loss: 0.3498 - accuracy: 0.8627 - val_loss: 0.3724 - val_accuracy: 0.8680 - 1s/epoch - 6ms/step\n",
      "Epoch 261/1000\n",
      "181/181 - 1s - loss: 0.3473 - accuracy: 0.8625 - val_loss: 0.3767 - val_accuracy: 0.8680 - 1s/epoch - 6ms/step\n",
      "Epoch 262/1000\n",
      "181/181 - 1s - loss: 0.3495 - accuracy: 0.8610 - val_loss: 0.3702 - val_accuracy: 0.8680 - 1s/epoch - 7ms/step\n",
      "Epoch 263/1000\n",
      "181/181 - 1s - loss: 0.3501 - accuracy: 0.8608 - val_loss: 0.3669 - val_accuracy: 0.8665 - 1s/epoch - 6ms/step\n",
      "Epoch 264/1000\n",
      "181/181 - 1s - loss: 0.3488 - accuracy: 0.8613 - val_loss: 0.3699 - val_accuracy: 0.8634 - 964ms/epoch - 5ms/step\n",
      "Epoch 265/1000\n",
      "181/181 - 1s - loss: 0.3466 - accuracy: 0.8606 - val_loss: 0.3702 - val_accuracy: 0.8680 - 1s/epoch - 6ms/step\n",
      "Epoch 266/1000\n",
      "181/181 - 1s - loss: 0.3458 - accuracy: 0.8617 - val_loss: 0.3771 - val_accuracy: 0.8696 - 1s/epoch - 6ms/step\n",
      "Epoch 267/1000\n",
      "181/181 - 1s - loss: 0.3478 - accuracy: 0.8641 - val_loss: 0.3645 - val_accuracy: 0.8711 - 904ms/epoch - 5ms/step\n",
      "Epoch 268/1000\n",
      "181/181 - 1s - loss: 0.3455 - accuracy: 0.8625 - val_loss: 0.3665 - val_accuracy: 0.8696 - 942ms/epoch - 5ms/step\n",
      "Epoch 269/1000\n",
      "181/181 - 1s - loss: 0.3471 - accuracy: 0.8644 - val_loss: 0.3833 - val_accuracy: 0.8634 - 1s/epoch - 6ms/step\n",
      "Epoch 270/1000\n",
      "181/181 - 1s - loss: 0.3441 - accuracy: 0.8665 - val_loss: 0.3610 - val_accuracy: 0.8665 - 976ms/epoch - 5ms/step\n",
      "Epoch 271/1000\n",
      "181/181 - 1s - loss: 0.3454 - accuracy: 0.8629 - val_loss: 0.3623 - val_accuracy: 0.8711 - 941ms/epoch - 5ms/step\n",
      "Epoch 272/1000\n",
      "181/181 - 1s - loss: 0.3463 - accuracy: 0.8639 - val_loss: 0.3611 - val_accuracy: 0.8680 - 898ms/epoch - 5ms/step\n",
      "Epoch 273/1000\n",
      "181/181 - 1s - loss: 0.3458 - accuracy: 0.8612 - val_loss: 0.3646 - val_accuracy: 0.8727 - 949ms/epoch - 5ms/step\n",
      "Epoch 274/1000\n",
      "181/181 - 1s - loss: 0.3443 - accuracy: 0.8622 - val_loss: 0.3606 - val_accuracy: 0.8711 - 1s/epoch - 6ms/step\n",
      "Epoch 275/1000\n",
      "181/181 - 1s - loss: 0.3434 - accuracy: 0.8643 - val_loss: 0.3668 - val_accuracy: 0.8665 - 1s/epoch - 6ms/step\n",
      "Epoch 276/1000\n",
      "181/181 - 1s - loss: 0.3464 - accuracy: 0.8606 - val_loss: 0.3652 - val_accuracy: 0.8649 - 1s/epoch - 7ms/step\n",
      "Epoch 277/1000\n",
      "181/181 - 1s - loss: 0.3425 - accuracy: 0.8627 - val_loss: 0.3613 - val_accuracy: 0.8711 - 991ms/epoch - 5ms/step\n",
      "Epoch 278/1000\n",
      "181/181 - 1s - loss: 0.3428 - accuracy: 0.8613 - val_loss: 0.3632 - val_accuracy: 0.8665 - 951ms/epoch - 5ms/step\n",
      "Epoch 279/1000\n",
      "181/181 - 1s - loss: 0.3435 - accuracy: 0.8643 - val_loss: 0.3699 - val_accuracy: 0.8758 - 856ms/epoch - 5ms/step\n",
      "Epoch 280/1000\n",
      "181/181 - 1s - loss: 0.3422 - accuracy: 0.8596 - val_loss: 0.3611 - val_accuracy: 0.8649 - 877ms/epoch - 5ms/step\n",
      "Epoch 281/1000\n",
      "181/181 - 1s - loss: 0.3443 - accuracy: 0.8641 - val_loss: 0.3604 - val_accuracy: 0.8649 - 1s/epoch - 6ms/step\n",
      "Epoch 282/1000\n",
      "181/181 - 1s - loss: 0.3415 - accuracy: 0.8631 - val_loss: 0.3615 - val_accuracy: 0.8696 - 907ms/epoch - 5ms/step\n",
      "Epoch 283/1000\n",
      "181/181 - 1s - loss: 0.3413 - accuracy: 0.8636 - val_loss: 0.3606 - val_accuracy: 0.8696 - 1s/epoch - 6ms/step\n",
      "Epoch 284/1000\n",
      "181/181 - 1s - loss: 0.3407 - accuracy: 0.8631 - val_loss: 0.3577 - val_accuracy: 0.8696 - 1s/epoch - 6ms/step\n",
      "Epoch 285/1000\n",
      "181/181 - 1s - loss: 0.3412 - accuracy: 0.8625 - val_loss: 0.3610 - val_accuracy: 0.8665 - 878ms/epoch - 5ms/step\n",
      "Epoch 286/1000\n",
      "181/181 - 1s - loss: 0.3451 - accuracy: 0.8634 - val_loss: 0.3633 - val_accuracy: 0.8680 - 996ms/epoch - 6ms/step\n",
      "Epoch 287/1000\n",
      "181/181 - 1s - loss: 0.3424 - accuracy: 0.8624 - val_loss: 0.3646 - val_accuracy: 0.8680 - 1s/epoch - 6ms/step\n",
      "Epoch 288/1000\n",
      "181/181 - 1s - loss: 0.3422 - accuracy: 0.8644 - val_loss: 0.3686 - val_accuracy: 0.8571 - 918ms/epoch - 5ms/step\n",
      "Epoch 289/1000\n",
      "181/181 - 1s - loss: 0.3440 - accuracy: 0.8648 - val_loss: 0.3608 - val_accuracy: 0.8680 - 969ms/epoch - 5ms/step\n",
      "Epoch 290/1000\n",
      "181/181 - 1s - loss: 0.3405 - accuracy: 0.8608 - val_loss: 0.3597 - val_accuracy: 0.8618 - 961ms/epoch - 5ms/step\n",
      "Epoch 291/1000\n",
      "181/181 - 1s - loss: 0.3413 - accuracy: 0.8625 - val_loss: 0.3590 - val_accuracy: 0.8727 - 1s/epoch - 6ms/step\n",
      "Epoch 292/1000\n",
      "181/181 - 1s - loss: 0.3399 - accuracy: 0.8667 - val_loss: 0.3582 - val_accuracy: 0.8711 - 899ms/epoch - 5ms/step\n",
      "Epoch 293/1000\n",
      "181/181 - 1s - loss: 0.3388 - accuracy: 0.8646 - val_loss: 0.3585 - val_accuracy: 0.8711 - 904ms/epoch - 5ms/step\n",
      "Epoch 294/1000\n",
      "181/181 - 1s - loss: 0.3401 - accuracy: 0.8629 - val_loss: 0.3644 - val_accuracy: 0.8602 - 903ms/epoch - 5ms/step\n",
      "Epoch 295/1000\n",
      "181/181 - 1s - loss: 0.3392 - accuracy: 0.8638 - val_loss: 0.3552 - val_accuracy: 0.8773 - 851ms/epoch - 5ms/step\n",
      "Epoch 296/1000\n",
      "181/181 - 1s - loss: 0.3409 - accuracy: 0.8641 - val_loss: 0.3540 - val_accuracy: 0.8742 - 911ms/epoch - 5ms/step\n",
      "Epoch 297/1000\n",
      "181/181 - 1s - loss: 0.3402 - accuracy: 0.8606 - val_loss: 0.3619 - val_accuracy: 0.8696 - 838ms/epoch - 5ms/step\n",
      "Epoch 298/1000\n",
      "181/181 - 1s - loss: 0.3444 - accuracy: 0.8605 - val_loss: 0.3608 - val_accuracy: 0.8618 - 878ms/epoch - 5ms/step\n",
      "Epoch 299/1000\n",
      "181/181 - 1s - loss: 0.3406 - accuracy: 0.8610 - val_loss: 0.3697 - val_accuracy: 0.8758 - 1s/epoch - 6ms/step\n",
      "Epoch 300/1000\n",
      "181/181 - 1s - loss: 0.3369 - accuracy: 0.8638 - val_loss: 0.3525 - val_accuracy: 0.8696 - 1s/epoch - 7ms/step\n",
      "Epoch 301/1000\n",
      "181/181 - 1s - loss: 0.3403 - accuracy: 0.8639 - val_loss: 0.3508 - val_accuracy: 0.8711 - 1s/epoch - 7ms/step\n",
      "Epoch 302/1000\n",
      "181/181 - 1s - loss: 0.3394 - accuracy: 0.8625 - val_loss: 0.3533 - val_accuracy: 0.8711 - 1s/epoch - 7ms/step\n",
      "Epoch 303/1000\n",
      "181/181 - 1s - loss: 0.3410 - accuracy: 0.8617 - val_loss: 0.3575 - val_accuracy: 0.8711 - 969ms/epoch - 5ms/step\n",
      "Epoch 304/1000\n",
      "181/181 - 1s - loss: 0.3399 - accuracy: 0.8620 - val_loss: 0.3534 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 305/1000\n",
      "181/181 - 1s - loss: 0.3424 - accuracy: 0.8610 - val_loss: 0.3567 - val_accuracy: 0.8711 - 932ms/epoch - 5ms/step\n",
      "Epoch 306/1000\n",
      "181/181 - 1s - loss: 0.3384 - accuracy: 0.8634 - val_loss: 0.3619 - val_accuracy: 0.8587 - 970ms/epoch - 5ms/step\n",
      "Epoch 307/1000\n",
      "181/181 - 1s - loss: 0.3403 - accuracy: 0.8608 - val_loss: 0.3516 - val_accuracy: 0.8742 - 962ms/epoch - 5ms/step\n",
      "Epoch 308/1000\n",
      "181/181 - 1s - loss: 0.3406 - accuracy: 0.8636 - val_loss: 0.3696 - val_accuracy: 0.8602 - 991ms/epoch - 5ms/step\n",
      "Epoch 309/1000\n",
      "181/181 - 1s - loss: 0.3368 - accuracy: 0.8646 - val_loss: 0.3591 - val_accuracy: 0.8680 - 1s/epoch - 7ms/step\n",
      "Epoch 310/1000\n",
      "181/181 - 1s - loss: 0.3405 - accuracy: 0.8625 - val_loss: 0.3638 - val_accuracy: 0.8665 - 983ms/epoch - 5ms/step\n",
      "Epoch 311/1000\n",
      "181/181 - 1s - loss: 0.3383 - accuracy: 0.8636 - val_loss: 0.3588 - val_accuracy: 0.8711 - 938ms/epoch - 5ms/step\n",
      "Epoch 312/1000\n",
      "181/181 - 1s - loss: 0.3367 - accuracy: 0.8650 - val_loss: 0.3541 - val_accuracy: 0.8711 - 963ms/epoch - 5ms/step\n",
      "Epoch 313/1000\n",
      "181/181 - 1s - loss: 0.3380 - accuracy: 0.8653 - val_loss: 0.3539 - val_accuracy: 0.8649 - 995ms/epoch - 5ms/step\n",
      "Epoch 314/1000\n",
      "181/181 - 1s - loss: 0.3370 - accuracy: 0.8622 - val_loss: 0.3507 - val_accuracy: 0.8773 - 870ms/epoch - 5ms/step\n",
      "Epoch 315/1000\n",
      "181/181 - 1s - loss: 0.3395 - accuracy: 0.8653 - val_loss: 0.3564 - val_accuracy: 0.8680 - 850ms/epoch - 5ms/step\n",
      "Epoch 316/1000\n",
      "181/181 - 1s - loss: 0.3359 - accuracy: 0.8636 - val_loss: 0.3577 - val_accuracy: 0.8773 - 835ms/epoch - 5ms/step\n",
      "Epoch 317/1000\n",
      "181/181 - 1s - loss: 0.3374 - accuracy: 0.8651 - val_loss: 0.3549 - val_accuracy: 0.8758 - 835ms/epoch - 5ms/step\n",
      "Epoch 318/1000\n",
      "181/181 - 1s - loss: 0.3381 - accuracy: 0.8639 - val_loss: 0.3576 - val_accuracy: 0.8665 - 836ms/epoch - 5ms/step\n",
      "Epoch 319/1000\n",
      "181/181 - 1s - loss: 0.3364 - accuracy: 0.8631 - val_loss: 0.3557 - val_accuracy: 0.8696 - 859ms/epoch - 5ms/step\n",
      "Epoch 320/1000\n",
      "181/181 - 1s - loss: 0.3427 - accuracy: 0.8617 - val_loss: 0.3606 - val_accuracy: 0.8649 - 849ms/epoch - 5ms/step\n",
      "Epoch 321/1000\n",
      "181/181 - 1s - loss: 0.3395 - accuracy: 0.8615 - val_loss: 0.3559 - val_accuracy: 0.8634 - 905ms/epoch - 5ms/step\n",
      "Epoch 322/1000\n",
      "181/181 - 1s - loss: 0.3357 - accuracy: 0.8646 - val_loss: 0.3518 - val_accuracy: 0.8680 - 888ms/epoch - 5ms/step\n",
      "Epoch 323/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 - 1s - loss: 0.3366 - accuracy: 0.8679 - val_loss: 0.3522 - val_accuracy: 0.8696 - 911ms/epoch - 5ms/step\n",
      "Epoch 324/1000\n",
      "181/181 - 1s - loss: 0.3360 - accuracy: 0.8655 - val_loss: 0.3555 - val_accuracy: 0.8680 - 1s/epoch - 6ms/step\n",
      "Epoch 325/1000\n",
      "181/181 - 1s - loss: 0.3361 - accuracy: 0.8624 - val_loss: 0.3527 - val_accuracy: 0.8758 - 1s/epoch - 7ms/step\n",
      "Epoch 326/1000\n",
      "181/181 - 1s - loss: 0.3353 - accuracy: 0.8662 - val_loss: 0.3570 - val_accuracy: 0.8696 - 940ms/epoch - 5ms/step\n",
      "Epoch 327/1000\n",
      "181/181 - 1s - loss: 0.3373 - accuracy: 0.8650 - val_loss: 0.3522 - val_accuracy: 0.8711 - 855ms/epoch - 5ms/step\n",
      "Epoch 328/1000\n",
      "181/181 - 1s - loss: 0.3367 - accuracy: 0.8658 - val_loss: 0.3569 - val_accuracy: 0.8649 - 889ms/epoch - 5ms/step\n",
      "Epoch 329/1000\n",
      "181/181 - 1s - loss: 0.3360 - accuracy: 0.8650 - val_loss: 0.3583 - val_accuracy: 0.8665 - 856ms/epoch - 5ms/step\n",
      "Epoch 330/1000\n",
      "181/181 - 1s - loss: 0.3347 - accuracy: 0.8643 - val_loss: 0.3667 - val_accuracy: 0.8618 - 843ms/epoch - 5ms/step\n",
      "Epoch 331/1000\n",
      "181/181 - 1s - loss: 0.3369 - accuracy: 0.8646 - val_loss: 0.3471 - val_accuracy: 0.8696 - 833ms/epoch - 5ms/step\n",
      "Epoch 332/1000\n",
      "181/181 - 1s - loss: 0.3371 - accuracy: 0.8665 - val_loss: 0.3673 - val_accuracy: 0.8680 - 838ms/epoch - 5ms/step\n",
      "Epoch 333/1000\n",
      "181/181 - 1s - loss: 0.3362 - accuracy: 0.8648 - val_loss: 0.3484 - val_accuracy: 0.8680 - 834ms/epoch - 5ms/step\n",
      "Epoch 334/1000\n",
      "181/181 - 1s - loss: 0.3331 - accuracy: 0.8620 - val_loss: 0.3511 - val_accuracy: 0.8680 - 834ms/epoch - 5ms/step\n",
      "Epoch 335/1000\n",
      "181/181 - 1s - loss: 0.3372 - accuracy: 0.8632 - val_loss: 0.3553 - val_accuracy: 0.8665 - 865ms/epoch - 5ms/step\n",
      "Epoch 336/1000\n",
      "181/181 - 1s - loss: 0.3354 - accuracy: 0.8658 - val_loss: 0.3574 - val_accuracy: 0.8711 - 833ms/epoch - 5ms/step\n",
      "Epoch 337/1000\n",
      "181/181 - 1s - loss: 0.3341 - accuracy: 0.8670 - val_loss: 0.3589 - val_accuracy: 0.8665 - 834ms/epoch - 5ms/step\n",
      "Epoch 338/1000\n",
      "181/181 - 1s - loss: 0.3350 - accuracy: 0.8643 - val_loss: 0.3491 - val_accuracy: 0.8727 - 841ms/epoch - 5ms/step\n",
      "Epoch 339/1000\n",
      "181/181 - 1s - loss: 0.3346 - accuracy: 0.8667 - val_loss: 0.3496 - val_accuracy: 0.8758 - 834ms/epoch - 5ms/step\n",
      "Epoch 340/1000\n",
      "181/181 - 1s - loss: 0.3336 - accuracy: 0.8674 - val_loss: 0.3571 - val_accuracy: 0.8649 - 834ms/epoch - 5ms/step\n",
      "Epoch 341/1000\n",
      "181/181 - 1s - loss: 0.3317 - accuracy: 0.8650 - val_loss: 0.3688 - val_accuracy: 0.8696 - 833ms/epoch - 5ms/step\n",
      "Epoch 342/1000\n",
      "181/181 - 1s - loss: 0.3367 - accuracy: 0.8681 - val_loss: 0.3527 - val_accuracy: 0.8696 - 844ms/epoch - 5ms/step\n",
      "Epoch 343/1000\n",
      "181/181 - 1s - loss: 0.3365 - accuracy: 0.8620 - val_loss: 0.3473 - val_accuracy: 0.8680 - 829ms/epoch - 5ms/step\n",
      "Epoch 344/1000\n",
      "181/181 - 1s - loss: 0.3349 - accuracy: 0.8655 - val_loss: 0.3618 - val_accuracy: 0.8789 - 831ms/epoch - 5ms/step\n",
      "Epoch 345/1000\n",
      "181/181 - 1s - loss: 0.3317 - accuracy: 0.8682 - val_loss: 0.3608 - val_accuracy: 0.8680 - 832ms/epoch - 5ms/step\n",
      "Epoch 346/1000\n",
      "181/181 - 1s - loss: 0.3351 - accuracy: 0.8643 - val_loss: 0.3470 - val_accuracy: 0.8758 - 836ms/epoch - 5ms/step\n",
      "Epoch 347/1000\n",
      "181/181 - 1s - loss: 0.3333 - accuracy: 0.8643 - val_loss: 0.3474 - val_accuracy: 0.8696 - 844ms/epoch - 5ms/step\n",
      "Epoch 348/1000\n",
      "181/181 - 1s - loss: 0.3320 - accuracy: 0.8643 - val_loss: 0.3622 - val_accuracy: 0.8773 - 830ms/epoch - 5ms/step\n",
      "Epoch 349/1000\n",
      "181/181 - 1s - loss: 0.3330 - accuracy: 0.8651 - val_loss: 0.3452 - val_accuracy: 0.8742 - 846ms/epoch - 5ms/step\n",
      "Epoch 350/1000\n",
      "181/181 - 1s - loss: 0.3322 - accuracy: 0.8672 - val_loss: 0.3495 - val_accuracy: 0.8758 - 834ms/epoch - 5ms/step\n",
      "Epoch 351/1000\n",
      "181/181 - 1s - loss: 0.3329 - accuracy: 0.8646 - val_loss: 0.3455 - val_accuracy: 0.8742 - 835ms/epoch - 5ms/step\n",
      "Epoch 352/1000\n",
      "181/181 - 1s - loss: 0.3341 - accuracy: 0.8665 - val_loss: 0.3465 - val_accuracy: 0.8711 - 840ms/epoch - 5ms/step\n",
      "Epoch 353/1000\n",
      "181/181 - 1s - loss: 0.3317 - accuracy: 0.8650 - val_loss: 0.3606 - val_accuracy: 0.8727 - 832ms/epoch - 5ms/step\n",
      "Epoch 354/1000\n",
      "181/181 - 1s - loss: 0.3343 - accuracy: 0.8676 - val_loss: 0.3492 - val_accuracy: 0.8727 - 843ms/epoch - 5ms/step\n",
      "Epoch 355/1000\n",
      "181/181 - 1s - loss: 0.3316 - accuracy: 0.8674 - val_loss: 0.3478 - val_accuracy: 0.8758 - 879ms/epoch - 5ms/step\n",
      "Epoch 356/1000\n",
      "181/181 - 1s - loss: 0.3321 - accuracy: 0.8641 - val_loss: 0.3474 - val_accuracy: 0.8789 - 836ms/epoch - 5ms/step\n",
      "Epoch 357/1000\n",
      "181/181 - 1s - loss: 0.3308 - accuracy: 0.8644 - val_loss: 0.3467 - val_accuracy: 0.8789 - 839ms/epoch - 5ms/step\n",
      "Epoch 358/1000\n",
      "181/181 - 1s - loss: 0.3295 - accuracy: 0.8658 - val_loss: 0.3474 - val_accuracy: 0.8742 - 831ms/epoch - 5ms/step\n",
      "Epoch 359/1000\n",
      "181/181 - 1s - loss: 0.3317 - accuracy: 0.8674 - val_loss: 0.3560 - val_accuracy: 0.8696 - 871ms/epoch - 5ms/step\n",
      "Epoch 360/1000\n",
      "181/181 - 1s - loss: 0.3309 - accuracy: 0.8660 - val_loss: 0.3446 - val_accuracy: 0.8758 - 852ms/epoch - 5ms/step\n",
      "Epoch 361/1000\n",
      "181/181 - 1s - loss: 0.3331 - accuracy: 0.8667 - val_loss: 0.3447 - val_accuracy: 0.8727 - 843ms/epoch - 5ms/step\n",
      "Epoch 362/1000\n",
      "181/181 - 1s - loss: 0.3305 - accuracy: 0.8681 - val_loss: 0.3540 - val_accuracy: 0.8665 - 833ms/epoch - 5ms/step\n",
      "Epoch 363/1000\n",
      "181/181 - 1s - loss: 0.3316 - accuracy: 0.8631 - val_loss: 0.3539 - val_accuracy: 0.8804 - 832ms/epoch - 5ms/step\n",
      "Epoch 364/1000\n",
      "181/181 - 1s - loss: 0.3306 - accuracy: 0.8662 - val_loss: 0.3437 - val_accuracy: 0.8758 - 835ms/epoch - 5ms/step\n",
      "Epoch 365/1000\n",
      "181/181 - 1s - loss: 0.3331 - accuracy: 0.8674 - val_loss: 0.3431 - val_accuracy: 0.8758 - 837ms/epoch - 5ms/step\n",
      "Epoch 366/1000\n",
      "181/181 - 1s - loss: 0.3297 - accuracy: 0.8658 - val_loss: 0.3505 - val_accuracy: 0.8742 - 838ms/epoch - 5ms/step\n",
      "Epoch 367/1000\n",
      "181/181 - 1s - loss: 0.3301 - accuracy: 0.8643 - val_loss: 0.3492 - val_accuracy: 0.8758 - 848ms/epoch - 5ms/step\n",
      "Epoch 368/1000\n",
      "181/181 - 1s - loss: 0.3309 - accuracy: 0.8667 - val_loss: 0.3487 - val_accuracy: 0.8696 - 836ms/epoch - 5ms/step\n",
      "Epoch 369/1000\n",
      "181/181 - 1s - loss: 0.3314 - accuracy: 0.8639 - val_loss: 0.3458 - val_accuracy: 0.8773 - 982ms/epoch - 5ms/step\n",
      "Epoch 370/1000\n",
      "181/181 - 2s - loss: 0.3313 - accuracy: 0.8677 - val_loss: 0.3496 - val_accuracy: 0.8773 - 2s/epoch - 9ms/step\n",
      "Epoch 371/1000\n",
      "181/181 - 2s - loss: 0.3281 - accuracy: 0.8663 - val_loss: 0.3656 - val_accuracy: 0.8680 - 2s/epoch - 9ms/step\n",
      "Epoch 372/1000\n",
      "181/181 - 2s - loss: 0.3291 - accuracy: 0.8629 - val_loss: 0.3447 - val_accuracy: 0.8742 - 2s/epoch - 12ms/step\n",
      "Epoch 373/1000\n",
      "181/181 - 2s - loss: 0.3292 - accuracy: 0.8660 - val_loss: 0.3536 - val_accuracy: 0.8727 - 2s/epoch - 11ms/step\n",
      "Epoch 374/1000\n",
      "181/181 - 1s - loss: 0.3310 - accuracy: 0.8679 - val_loss: 0.3556 - val_accuracy: 0.8696 - 1s/epoch - 6ms/step\n",
      "Epoch 375/1000\n",
      "181/181 - 1s - loss: 0.3287 - accuracy: 0.8644 - val_loss: 0.3509 - val_accuracy: 0.8789 - 992ms/epoch - 5ms/step\n",
      "Epoch 376/1000\n",
      "181/181 - 1s - loss: 0.3310 - accuracy: 0.8641 - val_loss: 0.3401 - val_accuracy: 0.8727 - 956ms/epoch - 5ms/step\n",
      "Epoch 377/1000\n",
      "181/181 - 1s - loss: 0.3339 - accuracy: 0.8638 - val_loss: 0.3470 - val_accuracy: 0.8789 - 965ms/epoch - 5ms/step\n",
      "Epoch 378/1000\n",
      "181/181 - 1s - loss: 0.3314 - accuracy: 0.8672 - val_loss: 0.3402 - val_accuracy: 0.8696 - 1s/epoch - 6ms/step\n",
      "Epoch 379/1000\n",
      "181/181 - 1s - loss: 0.3317 - accuracy: 0.8667 - val_loss: 0.3486 - val_accuracy: 0.8758 - 932ms/epoch - 5ms/step\n",
      "Epoch 380/1000\n",
      "181/181 - 1s - loss: 0.3347 - accuracy: 0.8669 - val_loss: 0.3441 - val_accuracy: 0.8727 - 830ms/epoch - 5ms/step\n",
      "Epoch 381/1000\n",
      "181/181 - 1s - loss: 0.3316 - accuracy: 0.8667 - val_loss: 0.3561 - val_accuracy: 0.8618 - 842ms/epoch - 5ms/step\n",
      "Epoch 382/1000\n",
      "181/181 - 1s - loss: 0.3315 - accuracy: 0.8684 - val_loss: 0.3547 - val_accuracy: 0.8665 - 831ms/epoch - 5ms/step\n",
      "Epoch 383/1000\n",
      "181/181 - 1s - loss: 0.3304 - accuracy: 0.8674 - val_loss: 0.3452 - val_accuracy: 0.8696 - 846ms/epoch - 5ms/step\n",
      "Epoch 384/1000\n",
      "181/181 - 1s - loss: 0.3286 - accuracy: 0.8638 - val_loss: 0.3398 - val_accuracy: 0.8742 - 829ms/epoch - 5ms/step\n",
      "Epoch 385/1000\n",
      "181/181 - 1s - loss: 0.3296 - accuracy: 0.8667 - val_loss: 0.3440 - val_accuracy: 0.8711 - 830ms/epoch - 5ms/step\n",
      "Epoch 386/1000\n",
      "181/181 - 1s - loss: 0.3285 - accuracy: 0.8698 - val_loss: 0.3533 - val_accuracy: 0.8742 - 831ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000\n",
      "181/181 - 1s - loss: 0.3290 - accuracy: 0.8660 - val_loss: 0.3546 - val_accuracy: 0.8711 - 825ms/epoch - 5ms/step\n",
      "Epoch 388/1000\n",
      "181/181 - 1s - loss: 0.3324 - accuracy: 0.8672 - val_loss: 0.3500 - val_accuracy: 0.8758 - 831ms/epoch - 5ms/step\n",
      "Epoch 389/1000\n",
      "181/181 - 1s - loss: 0.3282 - accuracy: 0.8691 - val_loss: 0.3397 - val_accuracy: 0.8758 - 828ms/epoch - 5ms/step\n",
      "Epoch 390/1000\n",
      "181/181 - 1s - loss: 0.3271 - accuracy: 0.8670 - val_loss: 0.3420 - val_accuracy: 0.8696 - 832ms/epoch - 5ms/step\n",
      "Epoch 391/1000\n",
      "181/181 - 1s - loss: 0.3291 - accuracy: 0.8686 - val_loss: 0.3517 - val_accuracy: 0.8711 - 890ms/epoch - 5ms/step\n",
      "Epoch 392/1000\n",
      "181/181 - 1s - loss: 0.3307 - accuracy: 0.8663 - val_loss: 0.3496 - val_accuracy: 0.8665 - 938ms/epoch - 5ms/step\n",
      "Epoch 393/1000\n",
      "181/181 - 1s - loss: 0.3292 - accuracy: 0.8643 - val_loss: 0.3418 - val_accuracy: 0.8680 - 897ms/epoch - 5ms/step\n",
      "Epoch 394/1000\n",
      "181/181 - 1s - loss: 0.3289 - accuracy: 0.8679 - val_loss: 0.3414 - val_accuracy: 0.8711 - 931ms/epoch - 5ms/step\n",
      "Epoch 395/1000\n",
      "181/181 - 1s - loss: 0.3267 - accuracy: 0.8658 - val_loss: 0.3449 - val_accuracy: 0.8758 - 944ms/epoch - 5ms/step\n",
      "Epoch 396/1000\n",
      "181/181 - 1s - loss: 0.3287 - accuracy: 0.8663 - val_loss: 0.3457 - val_accuracy: 0.8634 - 922ms/epoch - 5ms/step\n",
      "Epoch 397/1000\n",
      "181/181 - 1s - loss: 0.3266 - accuracy: 0.8695 - val_loss: 0.3459 - val_accuracy: 0.8758 - 872ms/epoch - 5ms/step\n",
      "Epoch 398/1000\n",
      "181/181 - 1s - loss: 0.3300 - accuracy: 0.8672 - val_loss: 0.3493 - val_accuracy: 0.8727 - 855ms/epoch - 5ms/step\n",
      "Epoch 399/1000\n",
      "181/181 - 1s - loss: 0.3268 - accuracy: 0.8714 - val_loss: 0.3644 - val_accuracy: 0.8758 - 845ms/epoch - 5ms/step\n",
      "Epoch 400/1000\n",
      "181/181 - 1s - loss: 0.3294 - accuracy: 0.8667 - val_loss: 0.3434 - val_accuracy: 0.8727 - 833ms/epoch - 5ms/step\n",
      "Epoch 401/1000\n",
      "181/181 - 1s - loss: 0.3271 - accuracy: 0.8677 - val_loss: 0.3503 - val_accuracy: 0.8758 - 828ms/epoch - 5ms/step\n",
      "Epoch 402/1000\n",
      "181/181 - 1s - loss: 0.3286 - accuracy: 0.8667 - val_loss: 0.3436 - val_accuracy: 0.8711 - 843ms/epoch - 5ms/step\n",
      "Epoch 403/1000\n",
      "181/181 - 1s - loss: 0.3288 - accuracy: 0.8643 - val_loss: 0.3444 - val_accuracy: 0.8696 - 873ms/epoch - 5ms/step\n",
      "Epoch 404/1000\n",
      "181/181 - 1s - loss: 0.3261 - accuracy: 0.8701 - val_loss: 0.3655 - val_accuracy: 0.8571 - 839ms/epoch - 5ms/step\n",
      "Epoch 405/1000\n",
      "181/181 - 1s - loss: 0.3317 - accuracy: 0.8660 - val_loss: 0.3440 - val_accuracy: 0.8773 - 865ms/epoch - 5ms/step\n",
      "Epoch 406/1000\n",
      "181/181 - 1s - loss: 0.3294 - accuracy: 0.8663 - val_loss: 0.3428 - val_accuracy: 0.8680 - 857ms/epoch - 5ms/step\n",
      "Epoch 407/1000\n",
      "181/181 - 1s - loss: 0.3288 - accuracy: 0.8655 - val_loss: 0.3397 - val_accuracy: 0.8742 - 830ms/epoch - 5ms/step\n",
      "Epoch 408/1000\n",
      "181/181 - 1s - loss: 0.3291 - accuracy: 0.8667 - val_loss: 0.3496 - val_accuracy: 0.8711 - 837ms/epoch - 5ms/step\n",
      "Epoch 409/1000\n",
      "181/181 - 1s - loss: 0.3279 - accuracy: 0.8632 - val_loss: 0.3456 - val_accuracy: 0.8742 - 828ms/epoch - 5ms/step\n",
      "Epoch 410/1000\n",
      "181/181 - 1s - loss: 0.3303 - accuracy: 0.8674 - val_loss: 0.3462 - val_accuracy: 0.8789 - 833ms/epoch - 5ms/step\n",
      "Epoch 411/1000\n",
      "181/181 - 1s - loss: 0.3277 - accuracy: 0.8644 - val_loss: 0.3418 - val_accuracy: 0.8789 - 832ms/epoch - 5ms/step\n",
      "Epoch 412/1000\n",
      "181/181 - 1s - loss: 0.3289 - accuracy: 0.8672 - val_loss: 0.3478 - val_accuracy: 0.8773 - 839ms/epoch - 5ms/step\n",
      "Epoch 413/1000\n",
      "181/181 - 1s - loss: 0.3292 - accuracy: 0.8665 - val_loss: 0.3483 - val_accuracy: 0.8758 - 853ms/epoch - 5ms/step\n",
      "Epoch 414/1000\n",
      "181/181 - 1s - loss: 0.3264 - accuracy: 0.8670 - val_loss: 0.3367 - val_accuracy: 0.8742 - 864ms/epoch - 5ms/step\n",
      "Epoch 415/1000\n",
      "181/181 - 1s - loss: 0.3282 - accuracy: 0.8674 - val_loss: 0.3436 - val_accuracy: 0.8742 - 853ms/epoch - 5ms/step\n",
      "Epoch 416/1000\n",
      "181/181 - 1s - loss: 0.3249 - accuracy: 0.8667 - val_loss: 0.3412 - val_accuracy: 0.8727 - 860ms/epoch - 5ms/step\n",
      "Epoch 417/1000\n",
      "181/181 - 1s - loss: 0.3282 - accuracy: 0.8643 - val_loss: 0.3480 - val_accuracy: 0.8680 - 858ms/epoch - 5ms/step\n",
      "Epoch 418/1000\n",
      "181/181 - 1s - loss: 0.3280 - accuracy: 0.8669 - val_loss: 0.3541 - val_accuracy: 0.8742 - 849ms/epoch - 5ms/step\n",
      "Epoch 419/1000\n",
      "181/181 - 1s - loss: 0.3263 - accuracy: 0.8653 - val_loss: 0.3466 - val_accuracy: 0.8758 - 856ms/epoch - 5ms/step\n",
      "Epoch 420/1000\n",
      "181/181 - 1s - loss: 0.3250 - accuracy: 0.8658 - val_loss: 0.3445 - val_accuracy: 0.8680 - 854ms/epoch - 5ms/step\n",
      "Epoch 421/1000\n",
      "181/181 - 1s - loss: 0.3333 - accuracy: 0.8651 - val_loss: 0.3546 - val_accuracy: 0.8634 - 859ms/epoch - 5ms/step\n",
      "Epoch 422/1000\n",
      "181/181 - 1s - loss: 0.3266 - accuracy: 0.8670 - val_loss: 0.3438 - val_accuracy: 0.8742 - 854ms/epoch - 5ms/step\n",
      "Epoch 423/1000\n",
      "181/181 - 1s - loss: 0.3275 - accuracy: 0.8651 - val_loss: 0.3426 - val_accuracy: 0.8804 - 851ms/epoch - 5ms/step\n",
      "Epoch 424/1000\n",
      "181/181 - 1s - loss: 0.3279 - accuracy: 0.8667 - val_loss: 0.3432 - val_accuracy: 0.8773 - 860ms/epoch - 5ms/step\n",
      "Epoch 425/1000\n",
      "181/181 - 1s - loss: 0.3290 - accuracy: 0.8672 - val_loss: 0.3446 - val_accuracy: 0.8727 - 870ms/epoch - 5ms/step\n",
      "Epoch 426/1000\n",
      "181/181 - 1s - loss: 0.3271 - accuracy: 0.8672 - val_loss: 0.3430 - val_accuracy: 0.8696 - 850ms/epoch - 5ms/step\n",
      "Epoch 427/1000\n",
      "181/181 - 1s - loss: 0.3282 - accuracy: 0.8660 - val_loss: 0.3420 - val_accuracy: 0.8727 - 854ms/epoch - 5ms/step\n",
      "Epoch 428/1000\n",
      "181/181 - 1s - loss: 0.3255 - accuracy: 0.8700 - val_loss: 0.3367 - val_accuracy: 0.8727 - 853ms/epoch - 5ms/step\n",
      "Epoch 429/1000\n",
      "181/181 - 1s - loss: 0.3258 - accuracy: 0.8665 - val_loss: 0.3424 - val_accuracy: 0.8773 - 854ms/epoch - 5ms/step\n",
      "Epoch 430/1000\n",
      "181/181 - 1s - loss: 0.3254 - accuracy: 0.8696 - val_loss: 0.3376 - val_accuracy: 0.8727 - 890ms/epoch - 5ms/step\n",
      "Epoch 431/1000\n",
      "181/181 - 1s - loss: 0.3259 - accuracy: 0.8660 - val_loss: 0.3540 - val_accuracy: 0.8773 - 1s/epoch - 7ms/step\n",
      "Epoch 432/1000\n",
      "181/181 - 2s - loss: 0.3245 - accuracy: 0.8679 - val_loss: 0.3411 - val_accuracy: 0.8773 - 2s/epoch - 9ms/step\n",
      "Epoch 433/1000\n",
      "181/181 - 2s - loss: 0.3240 - accuracy: 0.8712 - val_loss: 0.3554 - val_accuracy: 0.8835 - 2s/epoch - 9ms/step\n",
      "Epoch 434/1000\n",
      "181/181 - 2s - loss: 0.3266 - accuracy: 0.8672 - val_loss: 0.3442 - val_accuracy: 0.8742 - 2s/epoch - 9ms/step\n",
      "Epoch 435/1000\n",
      "181/181 - 2s - loss: 0.3244 - accuracy: 0.8714 - val_loss: 0.3438 - val_accuracy: 0.8742 - 2s/epoch - 9ms/step\n",
      "Epoch 436/1000\n",
      "181/181 - 1s - loss: 0.3249 - accuracy: 0.8686 - val_loss: 0.3557 - val_accuracy: 0.8820 - 993ms/epoch - 5ms/step\n",
      "Epoch 437/1000\n",
      "181/181 - 1s - loss: 0.3270 - accuracy: 0.8682 - val_loss: 0.3461 - val_accuracy: 0.8758 - 997ms/epoch - 6ms/step\n",
      "Epoch 438/1000\n",
      "181/181 - 1s - loss: 0.3247 - accuracy: 0.8674 - val_loss: 0.3446 - val_accuracy: 0.8804 - 946ms/epoch - 5ms/step\n",
      "Epoch 439/1000\n",
      "181/181 - 1s - loss: 0.3252 - accuracy: 0.8679 - val_loss: 0.3369 - val_accuracy: 0.8742 - 1s/epoch - 6ms/step\n",
      "Epoch 440/1000\n",
      "181/181 - 1s - loss: 0.3258 - accuracy: 0.8679 - val_loss: 0.3512 - val_accuracy: 0.8758 - 1s/epoch - 6ms/step\n",
      "Epoch 441/1000\n",
      "181/181 - 1s - loss: 0.3257 - accuracy: 0.8688 - val_loss: 0.3437 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 442/1000\n",
      "181/181 - 1s - loss: 0.3260 - accuracy: 0.8667 - val_loss: 0.3419 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 443/1000\n",
      "181/181 - 1s - loss: 0.3233 - accuracy: 0.8710 - val_loss: 0.3429 - val_accuracy: 0.8758 - 915ms/epoch - 5ms/step\n",
      "Epoch 444/1000\n",
      "181/181 - 1s - loss: 0.3262 - accuracy: 0.8676 - val_loss: 0.3407 - val_accuracy: 0.8758 - 875ms/epoch - 5ms/step\n",
      "Epoch 445/1000\n",
      "181/181 - 1s - loss: 0.3238 - accuracy: 0.8695 - val_loss: 0.3492 - val_accuracy: 0.8804 - 859ms/epoch - 5ms/step\n",
      "Epoch 446/1000\n",
      "181/181 - 1s - loss: 0.3252 - accuracy: 0.8681 - val_loss: 0.3439 - val_accuracy: 0.8773 - 971ms/epoch - 5ms/step\n",
      "Epoch 447/1000\n",
      "181/181 - 1s - loss: 0.3245 - accuracy: 0.8677 - val_loss: 0.3438 - val_accuracy: 0.8742 - 833ms/epoch - 5ms/step\n",
      "Epoch 448/1000\n",
      "181/181 - 1s - loss: 0.3253 - accuracy: 0.8701 - val_loss: 0.3390 - val_accuracy: 0.8742 - 827ms/epoch - 5ms/step\n",
      "Epoch 449/1000\n",
      "181/181 - 1s - loss: 0.3274 - accuracy: 0.8703 - val_loss: 0.3407 - val_accuracy: 0.8742 - 837ms/epoch - 5ms/step\n",
      "Epoch 450/1000\n",
      "181/181 - 1s - loss: 0.3247 - accuracy: 0.8665 - val_loss: 0.3412 - val_accuracy: 0.8773 - 848ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1000\n",
      "181/181 - 1s - loss: 0.3270 - accuracy: 0.8665 - val_loss: 0.3425 - val_accuracy: 0.8773 - 830ms/epoch - 5ms/step\n",
      "Epoch 452/1000\n",
      "181/181 - 1s - loss: 0.3241 - accuracy: 0.8676 - val_loss: 0.3432 - val_accuracy: 0.8727 - 835ms/epoch - 5ms/step\n",
      "Epoch 453/1000\n",
      "181/181 - 1s - loss: 0.3264 - accuracy: 0.8684 - val_loss: 0.3387 - val_accuracy: 0.8742 - 840ms/epoch - 5ms/step\n",
      "Epoch 454/1000\n",
      "181/181 - 1s - loss: 0.3246 - accuracy: 0.8679 - val_loss: 0.3411 - val_accuracy: 0.8804 - 836ms/epoch - 5ms/step\n",
      "Epoch 455/1000\n",
      "181/181 - 1s - loss: 0.3233 - accuracy: 0.8672 - val_loss: 0.3416 - val_accuracy: 0.8742 - 829ms/epoch - 5ms/step\n",
      "Epoch 456/1000\n",
      "181/181 - 1s - loss: 0.3260 - accuracy: 0.8700 - val_loss: 0.3565 - val_accuracy: 0.8571 - 825ms/epoch - 5ms/step\n",
      "Epoch 457/1000\n",
      "181/181 - 1s - loss: 0.3253 - accuracy: 0.8696 - val_loss: 0.3434 - val_accuracy: 0.8696 - 855ms/epoch - 5ms/step\n",
      "Epoch 458/1000\n",
      "181/181 - 1s - loss: 0.3238 - accuracy: 0.8688 - val_loss: 0.3423 - val_accuracy: 0.8835 - 849ms/epoch - 5ms/step\n",
      "Epoch 459/1000\n",
      "181/181 - 1s - loss: 0.3236 - accuracy: 0.8684 - val_loss: 0.3375 - val_accuracy: 0.8773 - 854ms/epoch - 5ms/step\n",
      "Epoch 460/1000\n",
      "181/181 - 1s - loss: 0.3244 - accuracy: 0.8676 - val_loss: 0.3492 - val_accuracy: 0.8773 - 852ms/epoch - 5ms/step\n",
      "Epoch 461/1000\n",
      "181/181 - 1s - loss: 0.3255 - accuracy: 0.8698 - val_loss: 0.3510 - val_accuracy: 0.8727 - 878ms/epoch - 5ms/step\n",
      "Epoch 462/1000\n",
      "181/181 - 1s - loss: 0.3242 - accuracy: 0.8689 - val_loss: 0.3441 - val_accuracy: 0.8711 - 884ms/epoch - 5ms/step\n",
      "Epoch 463/1000\n",
      "181/181 - 1s - loss: 0.3258 - accuracy: 0.8696 - val_loss: 0.3373 - val_accuracy: 0.8789 - 877ms/epoch - 5ms/step\n",
      "Epoch 464/1000\n",
      "181/181 - 1s - loss: 0.3272 - accuracy: 0.8672 - val_loss: 0.3637 - val_accuracy: 0.8727 - 875ms/epoch - 5ms/step\n",
      "Epoch 465/1000\n",
      "181/181 - 1s - loss: 0.3259 - accuracy: 0.8677 - val_loss: 0.3362 - val_accuracy: 0.8773 - 998ms/epoch - 6ms/step\n",
      "Epoch 466/1000\n",
      "181/181 - 1s - loss: 0.3234 - accuracy: 0.8720 - val_loss: 0.3403 - val_accuracy: 0.8742 - 915ms/epoch - 5ms/step\n",
      "Epoch 467/1000\n",
      "181/181 - 1s - loss: 0.3229 - accuracy: 0.8669 - val_loss: 0.3422 - val_accuracy: 0.8820 - 867ms/epoch - 5ms/step\n",
      "Epoch 468/1000\n",
      "181/181 - 1s - loss: 0.3256 - accuracy: 0.8696 - val_loss: 0.3397 - val_accuracy: 0.8773 - 851ms/epoch - 5ms/step\n",
      "Epoch 469/1000\n",
      "181/181 - 1s - loss: 0.3236 - accuracy: 0.8689 - val_loss: 0.3452 - val_accuracy: 0.8742 - 852ms/epoch - 5ms/step\n",
      "Epoch 470/1000\n",
      "181/181 - 1s - loss: 0.3244 - accuracy: 0.8695 - val_loss: 0.3340 - val_accuracy: 0.8758 - 856ms/epoch - 5ms/step\n",
      "Epoch 471/1000\n",
      "181/181 - 1s - loss: 0.3238 - accuracy: 0.8691 - val_loss: 0.3507 - val_accuracy: 0.8742 - 850ms/epoch - 5ms/step\n",
      "Epoch 472/1000\n",
      "181/181 - 1s - loss: 0.3237 - accuracy: 0.8693 - val_loss: 0.3432 - val_accuracy: 0.8773 - 833ms/epoch - 5ms/step\n",
      "Epoch 473/1000\n",
      "181/181 - 1s - loss: 0.3227 - accuracy: 0.8691 - val_loss: 0.3417 - val_accuracy: 0.8758 - 828ms/epoch - 5ms/step\n",
      "Epoch 474/1000\n",
      "181/181 - 1s - loss: 0.3238 - accuracy: 0.8688 - val_loss: 0.3522 - val_accuracy: 0.8634 - 833ms/epoch - 5ms/step\n",
      "Epoch 475/1000\n",
      "181/181 - 1s - loss: 0.3259 - accuracy: 0.8712 - val_loss: 0.3870 - val_accuracy: 0.8509 - 830ms/epoch - 5ms/step\n",
      "Epoch 476/1000\n",
      "181/181 - 1s - loss: 0.3250 - accuracy: 0.8689 - val_loss: 0.3394 - val_accuracy: 0.8773 - 838ms/epoch - 5ms/step\n",
      "Epoch 477/1000\n",
      "181/181 - 1s - loss: 0.3217 - accuracy: 0.8686 - val_loss: 0.3498 - val_accuracy: 0.8680 - 837ms/epoch - 5ms/step\n",
      "Epoch 478/1000\n",
      "181/181 - 1s - loss: 0.3256 - accuracy: 0.8691 - val_loss: 0.3465 - val_accuracy: 0.8711 - 831ms/epoch - 5ms/step\n",
      "Epoch 479/1000\n",
      "181/181 - 1s - loss: 0.3248 - accuracy: 0.8705 - val_loss: 0.3401 - val_accuracy: 0.8696 - 825ms/epoch - 5ms/step\n",
      "Epoch 480/1000\n",
      "181/181 - 1s - loss: 0.3207 - accuracy: 0.8719 - val_loss: 0.3482 - val_accuracy: 0.8696 - 843ms/epoch - 5ms/step\n",
      "Epoch 481/1000\n",
      "181/181 - 1s - loss: 0.3231 - accuracy: 0.8665 - val_loss: 0.3494 - val_accuracy: 0.8727 - 867ms/epoch - 5ms/step\n",
      "Epoch 482/1000\n",
      "181/181 - 1s - loss: 0.3233 - accuracy: 0.8674 - val_loss: 0.3476 - val_accuracy: 0.8696 - 837ms/epoch - 5ms/step\n",
      "Epoch 483/1000\n",
      "181/181 - 1s - loss: 0.3237 - accuracy: 0.8703 - val_loss: 0.3426 - val_accuracy: 0.8758 - 835ms/epoch - 5ms/step\n",
      "Epoch 484/1000\n",
      "181/181 - 1s - loss: 0.3232 - accuracy: 0.8672 - val_loss: 0.3394 - val_accuracy: 0.8789 - 835ms/epoch - 5ms/step\n",
      "Epoch 485/1000\n",
      "181/181 - 1s - loss: 0.3251 - accuracy: 0.8717 - val_loss: 0.3449 - val_accuracy: 0.8758 - 844ms/epoch - 5ms/step\n",
      "Epoch 486/1000\n",
      "181/181 - 1s - loss: 0.3230 - accuracy: 0.8720 - val_loss: 0.3467 - val_accuracy: 0.8665 - 832ms/epoch - 5ms/step\n",
      "Epoch 487/1000\n",
      "181/181 - 1s - loss: 0.3215 - accuracy: 0.8682 - val_loss: 0.3360 - val_accuracy: 0.8773 - 1s/epoch - 6ms/step\n",
      "Epoch 488/1000\n",
      "181/181 - 2s - loss: 0.3257 - accuracy: 0.8710 - val_loss: 0.3429 - val_accuracy: 0.8711 - 2s/epoch - 9ms/step\n",
      "Epoch 489/1000\n",
      "181/181 - 2s - loss: 0.3223 - accuracy: 0.8707 - val_loss: 0.3428 - val_accuracy: 0.8742 - 2s/epoch - 9ms/step\n",
      "Epoch 490/1000\n",
      "181/181 - 2s - loss: 0.3232 - accuracy: 0.8696 - val_loss: 0.3405 - val_accuracy: 0.8804 - 2s/epoch - 9ms/step\n",
      "Epoch 491/1000\n",
      "181/181 - 2s - loss: 0.3256 - accuracy: 0.8734 - val_loss: 0.3401 - val_accuracy: 0.8789 - 2s/epoch - 9ms/step\n",
      "Epoch 492/1000\n",
      "181/181 - 1s - loss: 0.3215 - accuracy: 0.8715 - val_loss: 0.3501 - val_accuracy: 0.8680 - 823ms/epoch - 5ms/step\n",
      "Epoch 493/1000\n",
      "181/181 - 1s - loss: 0.3220 - accuracy: 0.8719 - val_loss: 0.3380 - val_accuracy: 0.8696 - 820ms/epoch - 5ms/step\n",
      "Epoch 494/1000\n",
      "181/181 - 1s - loss: 0.3222 - accuracy: 0.8696 - val_loss: 0.3443 - val_accuracy: 0.8742 - 820ms/epoch - 5ms/step\n",
      "Epoch 495/1000\n",
      "181/181 - 1s - loss: 0.3235 - accuracy: 0.8689 - val_loss: 0.3468 - val_accuracy: 0.8820 - 824ms/epoch - 5ms/step\n",
      "Epoch 496/1000\n",
      "181/181 - 1s - loss: 0.3230 - accuracy: 0.8705 - val_loss: 0.3498 - val_accuracy: 0.8727 - 843ms/epoch - 5ms/step\n",
      "Epoch 497/1000\n",
      "181/181 - 1s - loss: 0.3227 - accuracy: 0.8689 - val_loss: 0.3346 - val_accuracy: 0.8758 - 891ms/epoch - 5ms/step\n",
      "Epoch 498/1000\n",
      "181/181 - 1s - loss: 0.3211 - accuracy: 0.8729 - val_loss: 0.3370 - val_accuracy: 0.8742 - 1s/epoch - 6ms/step\n",
      "Epoch 499/1000\n",
      "181/181 - 1s - loss: 0.3236 - accuracy: 0.8691 - val_loss: 0.3377 - val_accuracy: 0.8789 - 935ms/epoch - 5ms/step\n",
      "Epoch 500/1000\n",
      "181/181 - 1s - loss: 0.3220 - accuracy: 0.8733 - val_loss: 0.3379 - val_accuracy: 0.8742 - 966ms/epoch - 5ms/step\n",
      "Epoch 501/1000\n",
      "181/181 - 1s - loss: 0.3258 - accuracy: 0.8712 - val_loss: 0.3360 - val_accuracy: 0.8758 - 1s/epoch - 6ms/step\n",
      "Epoch 502/1000\n",
      "181/181 - 1s - loss: 0.3227 - accuracy: 0.8676 - val_loss: 0.3464 - val_accuracy: 0.8680 - 1s/epoch - 7ms/step\n",
      "Epoch 503/1000\n",
      "181/181 - 1s - loss: 0.3246 - accuracy: 0.8691 - val_loss: 0.3348 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 504/1000\n",
      "181/181 - 1s - loss: 0.3247 - accuracy: 0.8689 - val_loss: 0.3359 - val_accuracy: 0.8773 - 975ms/epoch - 5ms/step\n",
      "Epoch 505/1000\n",
      "181/181 - 1s - loss: 0.3251 - accuracy: 0.8696 - val_loss: 0.3394 - val_accuracy: 0.8820 - 904ms/epoch - 5ms/step\n",
      "Epoch 506/1000\n",
      "181/181 - 1s - loss: 0.3218 - accuracy: 0.8707 - val_loss: 0.3463 - val_accuracy: 0.8665 - 836ms/epoch - 5ms/step\n",
      "Epoch 507/1000\n",
      "181/181 - 1s - loss: 0.3228 - accuracy: 0.8701 - val_loss: 0.3410 - val_accuracy: 0.8820 - 846ms/epoch - 5ms/step\n",
      "Epoch 508/1000\n",
      "181/181 - 1s - loss: 0.3220 - accuracy: 0.8676 - val_loss: 0.3460 - val_accuracy: 0.8742 - 939ms/epoch - 5ms/step\n",
      "Epoch 509/1000\n",
      "181/181 - 1s - loss: 0.3201 - accuracy: 0.8707 - val_loss: 0.3391 - val_accuracy: 0.8742 - 1s/epoch - 6ms/step\n",
      "Epoch 510/1000\n",
      "181/181 - 1s - loss: 0.3225 - accuracy: 0.8707 - val_loss: 0.3403 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 511/1000\n",
      "181/181 - 1s - loss: 0.3217 - accuracy: 0.8703 - val_loss: 0.3453 - val_accuracy: 0.8773 - 1000ms/epoch - 6ms/step\n",
      "Epoch 512/1000\n",
      "181/181 - 1s - loss: 0.3216 - accuracy: 0.8717 - val_loss: 0.3410 - val_accuracy: 0.8742 - 1s/epoch - 6ms/step\n",
      "Epoch 513/1000\n",
      "181/181 - 1s - loss: 0.3251 - accuracy: 0.8698 - val_loss: 0.3446 - val_accuracy: 0.8696 - 1s/epoch - 6ms/step\n",
      "Epoch 514/1000\n",
      "181/181 - 1s - loss: 0.3218 - accuracy: 0.8705 - val_loss: 0.3394 - val_accuracy: 0.8727 - 934ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515/1000\n",
      "181/181 - 1s - loss: 0.3215 - accuracy: 0.8684 - val_loss: 0.3364 - val_accuracy: 0.8789 - 948ms/epoch - 5ms/step\n",
      "Epoch 516/1000\n",
      "181/181 - 1s - loss: 0.3207 - accuracy: 0.8712 - val_loss: 0.3407 - val_accuracy: 0.8773 - 931ms/epoch - 5ms/step\n",
      "Epoch 517/1000\n",
      "181/181 - 1s - loss: 0.3257 - accuracy: 0.8695 - val_loss: 0.3487 - val_accuracy: 0.8711 - 872ms/epoch - 5ms/step\n",
      "Epoch 518/1000\n",
      "181/181 - 1s - loss: 0.3226 - accuracy: 0.8691 - val_loss: 0.3666 - val_accuracy: 0.8634 - 827ms/epoch - 5ms/step\n",
      "Epoch 519/1000\n",
      "181/181 - 1s - loss: 0.3266 - accuracy: 0.8684 - val_loss: 0.3623 - val_accuracy: 0.8758 - 846ms/epoch - 5ms/step\n",
      "Epoch 520/1000\n",
      "181/181 - 1s - loss: 0.3240 - accuracy: 0.8677 - val_loss: 0.3391 - val_accuracy: 0.8835 - 917ms/epoch - 5ms/step\n",
      "Epoch 521/1000\n",
      "181/181 - 1s - loss: 0.3200 - accuracy: 0.8733 - val_loss: 0.3541 - val_accuracy: 0.8649 - 954ms/epoch - 5ms/step\n",
      "Epoch 522/1000\n",
      "181/181 - 1s - loss: 0.3261 - accuracy: 0.8720 - val_loss: 0.3405 - val_accuracy: 0.8758 - 875ms/epoch - 5ms/step\n",
      "Epoch 523/1000\n",
      "181/181 - 1s - loss: 0.3217 - accuracy: 0.8715 - val_loss: 0.3439 - val_accuracy: 0.8758 - 1s/epoch - 6ms/step\n",
      "Epoch 524/1000\n",
      "181/181 - 1s - loss: 0.3198 - accuracy: 0.8691 - val_loss: 0.3420 - val_accuracy: 0.8742 - 1s/epoch - 6ms/step\n",
      "Epoch 525/1000\n",
      "181/181 - 1s - loss: 0.3215 - accuracy: 0.8693 - val_loss: 0.3326 - val_accuracy: 0.8742 - 1s/epoch - 6ms/step\n",
      "Epoch 526/1000\n",
      "181/181 - 1s - loss: 0.3218 - accuracy: 0.8686 - val_loss: 0.3563 - val_accuracy: 0.8680 - 957ms/epoch - 5ms/step\n",
      "Epoch 527/1000\n",
      "181/181 - 1s - loss: 0.3217 - accuracy: 0.8665 - val_loss: 0.3374 - val_accuracy: 0.8789 - 843ms/epoch - 5ms/step\n",
      "Epoch 528/1000\n",
      "181/181 - 1s - loss: 0.3197 - accuracy: 0.8715 - val_loss: 0.3464 - val_accuracy: 0.8804 - 896ms/epoch - 5ms/step\n",
      "Epoch 529/1000\n",
      "181/181 - 1s - loss: 0.3218 - accuracy: 0.8701 - val_loss: 0.3477 - val_accuracy: 0.8835 - 899ms/epoch - 5ms/step\n",
      "Epoch 530/1000\n",
      "181/181 - 1s - loss: 0.3221 - accuracy: 0.8717 - val_loss: 0.3485 - val_accuracy: 0.8680 - 1s/epoch - 6ms/step\n",
      "Epoch 531/1000\n",
      "181/181 - 1s - loss: 0.3238 - accuracy: 0.8653 - val_loss: 0.3415 - val_accuracy: 0.8742 - 1s/epoch - 6ms/step\n",
      "Epoch 532/1000\n",
      "181/181 - 1s - loss: 0.3197 - accuracy: 0.8717 - val_loss: 0.3581 - val_accuracy: 0.8866 - 1s/epoch - 7ms/step\n",
      "Epoch 533/1000\n",
      "181/181 - 1s - loss: 0.3201 - accuracy: 0.8705 - val_loss: 0.3465 - val_accuracy: 0.8866 - 1s/epoch - 6ms/step\n",
      "Epoch 534/1000\n",
      "181/181 - 1s - loss: 0.3207 - accuracy: 0.8693 - val_loss: 0.3435 - val_accuracy: 0.8742 - 973ms/epoch - 5ms/step\n",
      "Epoch 535/1000\n",
      "181/181 - 1s - loss: 0.3216 - accuracy: 0.8686 - val_loss: 0.3463 - val_accuracy: 0.8727 - 869ms/epoch - 5ms/step\n",
      "Epoch 536/1000\n",
      "181/181 - 1s - loss: 0.3210 - accuracy: 0.8693 - val_loss: 0.3416 - val_accuracy: 0.8866 - 858ms/epoch - 5ms/step\n",
      "Epoch 537/1000\n",
      "181/181 - 1s - loss: 0.3201 - accuracy: 0.8720 - val_loss: 0.3393 - val_accuracy: 0.8789 - 921ms/epoch - 5ms/step\n",
      "Epoch 538/1000\n",
      "181/181 - 1s - loss: 0.3219 - accuracy: 0.8710 - val_loss: 0.3434 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 539/1000\n",
      "181/181 - 1s - loss: 0.3196 - accuracy: 0.8724 - val_loss: 0.3569 - val_accuracy: 0.8820 - 1s/epoch - 7ms/step\n",
      "Epoch 540/1000\n",
      "181/181 - 1s - loss: 0.3207 - accuracy: 0.8719 - val_loss: 0.3580 - val_accuracy: 0.8820 - 900ms/epoch - 5ms/step\n",
      "Epoch 541/1000\n",
      "181/181 - 1s - loss: 0.3192 - accuracy: 0.8693 - val_loss: 0.3403 - val_accuracy: 0.8758 - 1s/epoch - 6ms/step\n",
      "Epoch 542/1000\n",
      "181/181 - 1s - loss: 0.3216 - accuracy: 0.8715 - val_loss: 0.3474 - val_accuracy: 0.8804 - 993ms/epoch - 5ms/step\n",
      "Epoch 543/1000\n",
      "181/181 - 1s - loss: 0.3202 - accuracy: 0.8719 - val_loss: 0.3364 - val_accuracy: 0.8773 - 834ms/epoch - 5ms/step\n",
      "Epoch 544/1000\n",
      "181/181 - 1s - loss: 0.3195 - accuracy: 0.8708 - val_loss: 0.3351 - val_accuracy: 0.8789 - 979ms/epoch - 5ms/step\n",
      "Epoch 545/1000\n",
      "181/181 - 1s - loss: 0.3203 - accuracy: 0.8717 - val_loss: 0.3454 - val_accuracy: 0.8773 - 934ms/epoch - 5ms/step\n",
      "Epoch 546/1000\n",
      "181/181 - 1s - loss: 0.3194 - accuracy: 0.8717 - val_loss: 0.3364 - val_accuracy: 0.8773 - 833ms/epoch - 5ms/step\n",
      "Epoch 547/1000\n",
      "181/181 - 1s - loss: 0.3203 - accuracy: 0.8726 - val_loss: 0.3507 - val_accuracy: 0.8727 - 1s/epoch - 6ms/step\n",
      "Epoch 548/1000\n",
      "181/181 - 1s - loss: 0.3190 - accuracy: 0.8727 - val_loss: 0.3372 - val_accuracy: 0.8773 - 842ms/epoch - 5ms/step\n",
      "Epoch 549/1000\n",
      "181/181 - 1s - loss: 0.3188 - accuracy: 0.8715 - val_loss: 0.3346 - val_accuracy: 0.8773 - 858ms/epoch - 5ms/step\n",
      "Epoch 550/1000\n",
      "181/181 - 1s - loss: 0.3195 - accuracy: 0.8703 - val_loss: 0.3403 - val_accuracy: 0.8835 - 870ms/epoch - 5ms/step\n",
      "Epoch 551/1000\n",
      "181/181 - 1s - loss: 0.3193 - accuracy: 0.8707 - val_loss: 0.3371 - val_accuracy: 0.8789 - 835ms/epoch - 5ms/step\n",
      "Epoch 552/1000\n",
      "181/181 - 1s - loss: 0.3195 - accuracy: 0.8689 - val_loss: 0.3409 - val_accuracy: 0.8680 - 900ms/epoch - 5ms/step\n",
      "Epoch 553/1000\n",
      "181/181 - 1s - loss: 0.3202 - accuracy: 0.8720 - val_loss: 0.3352 - val_accuracy: 0.8773 - 913ms/epoch - 5ms/step\n",
      "Epoch 554/1000\n",
      "181/181 - 2s - loss: 0.3156 - accuracy: 0.8753 - val_loss: 0.3329 - val_accuracy: 0.8789 - 2s/epoch - 11ms/step\n",
      "Epoch 555/1000\n",
      "181/181 - 2s - loss: 0.3165 - accuracy: 0.8733 - val_loss: 0.3303 - val_accuracy: 0.8773 - 2s/epoch - 10ms/step\n",
      "Epoch 556/1000\n",
      "181/181 - 2s - loss: 0.3179 - accuracy: 0.8698 - val_loss: 0.3378 - val_accuracy: 0.8711 - 2s/epoch - 10ms/step\n",
      "Epoch 557/1000\n",
      "181/181 - 2s - loss: 0.3163 - accuracy: 0.8743 - val_loss: 0.3356 - val_accuracy: 0.8804 - 2s/epoch - 12ms/step\n",
      "Epoch 558/1000\n",
      "181/181 - 1s - loss: 0.3168 - accuracy: 0.8734 - val_loss: 0.3393 - val_accuracy: 0.8835 - 1s/epoch - 6ms/step\n",
      "Epoch 559/1000\n",
      "181/181 - 1s - loss: 0.3185 - accuracy: 0.8727 - val_loss: 0.3349 - val_accuracy: 0.8851 - 1s/epoch - 6ms/step\n",
      "Epoch 560/1000\n",
      "181/181 - 1s - loss: 0.3190 - accuracy: 0.8750 - val_loss: 0.3332 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 561/1000\n",
      "181/181 - 1s - loss: 0.3184 - accuracy: 0.8724 - val_loss: 0.3339 - val_accuracy: 0.8804 - 1s/epoch - 7ms/step\n",
      "Epoch 562/1000\n",
      "181/181 - 1s - loss: 0.3189 - accuracy: 0.8755 - val_loss: 0.3370 - val_accuracy: 0.8835 - 993ms/epoch - 5ms/step\n",
      "Epoch 563/1000\n",
      "181/181 - 1s - loss: 0.3175 - accuracy: 0.8736 - val_loss: 0.3480 - val_accuracy: 0.8758 - 975ms/epoch - 5ms/step\n",
      "Epoch 564/1000\n",
      "181/181 - 1s - loss: 0.3142 - accuracy: 0.8724 - val_loss: 0.3391 - val_accuracy: 0.8804 - 967ms/epoch - 5ms/step\n",
      "Epoch 565/1000\n",
      "181/181 - 1s - loss: 0.3206 - accuracy: 0.8695 - val_loss: 0.3376 - val_accuracy: 0.8804 - 831ms/epoch - 5ms/step\n",
      "Epoch 566/1000\n",
      "181/181 - 1s - loss: 0.3161 - accuracy: 0.8722 - val_loss: 0.3351 - val_accuracy: 0.8804 - 834ms/epoch - 5ms/step\n",
      "Epoch 567/1000\n",
      "181/181 - 1s - loss: 0.3150 - accuracy: 0.8726 - val_loss: 0.3403 - val_accuracy: 0.8773 - 829ms/epoch - 5ms/step\n",
      "Epoch 568/1000\n",
      "181/181 - 1s - loss: 0.3177 - accuracy: 0.8736 - val_loss: 0.3436 - val_accuracy: 0.8758 - 849ms/epoch - 5ms/step\n",
      "Epoch 569/1000\n",
      "181/181 - 1s - loss: 0.3146 - accuracy: 0.8726 - val_loss: 0.3446 - val_accuracy: 0.8742 - 836ms/epoch - 5ms/step\n",
      "Epoch 570/1000\n",
      "181/181 - 1s - loss: 0.3173 - accuracy: 0.8708 - val_loss: 0.3352 - val_accuracy: 0.8804 - 833ms/epoch - 5ms/step\n",
      "Epoch 571/1000\n",
      "181/181 - 1s - loss: 0.3189 - accuracy: 0.8729 - val_loss: 0.3370 - val_accuracy: 0.8727 - 837ms/epoch - 5ms/step\n",
      "Epoch 572/1000\n",
      "181/181 - 1s - loss: 0.3134 - accuracy: 0.8739 - val_loss: 0.3414 - val_accuracy: 0.8804 - 964ms/epoch - 5ms/step\n",
      "Epoch 573/1000\n",
      "181/181 - 1s - loss: 0.3171 - accuracy: 0.8741 - val_loss: 0.3376 - val_accuracy: 0.8773 - 935ms/epoch - 5ms/step\n",
      "Epoch 574/1000\n",
      "181/181 - 1s - loss: 0.3162 - accuracy: 0.8705 - val_loss: 0.3342 - val_accuracy: 0.8820 - 879ms/epoch - 5ms/step\n",
      "Epoch 575/1000\n",
      "181/181 - 1s - loss: 0.3189 - accuracy: 0.8719 - val_loss: 0.3304 - val_accuracy: 0.8758 - 988ms/epoch - 5ms/step\n",
      "Epoch 576/1000\n",
      "181/181 - 1s - loss: 0.3169 - accuracy: 0.8727 - val_loss: 0.3404 - val_accuracy: 0.8789 - 961ms/epoch - 5ms/step\n",
      "Epoch 577/1000\n",
      "181/181 - 1s - loss: 0.3184 - accuracy: 0.8715 - val_loss: 0.3283 - val_accuracy: 0.8820 - 961ms/epoch - 5ms/step\n",
      "Epoch 578/1000\n",
      "181/181 - 1s - loss: 0.3164 - accuracy: 0.8734 - val_loss: 0.3332 - val_accuracy: 0.8758 - 965ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 579/1000\n",
      "181/181 - 1s - loss: 0.3171 - accuracy: 0.8715 - val_loss: 0.3376 - val_accuracy: 0.8898 - 853ms/epoch - 5ms/step\n",
      "Epoch 580/1000\n",
      "181/181 - 1s - loss: 0.3158 - accuracy: 0.8752 - val_loss: 0.3345 - val_accuracy: 0.8742 - 904ms/epoch - 5ms/step\n",
      "Epoch 581/1000\n",
      "181/181 - 1s - loss: 0.3161 - accuracy: 0.8719 - val_loss: 0.3295 - val_accuracy: 0.8727 - 894ms/epoch - 5ms/step\n",
      "Epoch 582/1000\n",
      "181/181 - 1s - loss: 0.3175 - accuracy: 0.8726 - val_loss: 0.3577 - val_accuracy: 0.8882 - 857ms/epoch - 5ms/step\n",
      "Epoch 583/1000\n",
      "181/181 - 1s - loss: 0.3182 - accuracy: 0.8715 - val_loss: 0.3458 - val_accuracy: 0.8789 - 855ms/epoch - 5ms/step\n",
      "Epoch 584/1000\n",
      "181/181 - 1s - loss: 0.3170 - accuracy: 0.8736 - val_loss: 0.3335 - val_accuracy: 0.8820 - 838ms/epoch - 5ms/step\n",
      "Epoch 585/1000\n",
      "181/181 - 1s - loss: 0.3168 - accuracy: 0.8719 - val_loss: 0.3356 - val_accuracy: 0.8742 - 837ms/epoch - 5ms/step\n",
      "Epoch 586/1000\n",
      "181/181 - 1s - loss: 0.3185 - accuracy: 0.8712 - val_loss: 0.3328 - val_accuracy: 0.8804 - 840ms/epoch - 5ms/step\n",
      "Epoch 587/1000\n",
      "181/181 - 1s - loss: 0.3169 - accuracy: 0.8736 - val_loss: 0.3406 - val_accuracy: 0.8820 - 1s/epoch - 8ms/step\n",
      "Epoch 588/1000\n",
      "181/181 - 2s - loss: 0.3164 - accuracy: 0.8736 - val_loss: 0.3340 - val_accuracy: 0.8820 - 2s/epoch - 9ms/step\n",
      "Epoch 589/1000\n",
      "181/181 - 2s - loss: 0.3164 - accuracy: 0.8741 - val_loss: 0.3338 - val_accuracy: 0.8758 - 2s/epoch - 10ms/step\n",
      "Epoch 590/1000\n",
      "181/181 - 2s - loss: 0.3169 - accuracy: 0.8717 - val_loss: 0.3410 - val_accuracy: 0.8789 - 2s/epoch - 10ms/step\n",
      "Epoch 591/1000\n",
      "181/181 - 1s - loss: 0.3188 - accuracy: 0.8708 - val_loss: 0.3491 - val_accuracy: 0.8727 - 1s/epoch - 7ms/step\n",
      "Epoch 592/1000\n",
      "181/181 - 1s - loss: 0.3159 - accuracy: 0.8724 - val_loss: 0.3326 - val_accuracy: 0.8804 - 819ms/epoch - 5ms/step\n",
      "Epoch 593/1000\n",
      "181/181 - 1s - loss: 0.3159 - accuracy: 0.8733 - val_loss: 0.3494 - val_accuracy: 0.8696 - 901ms/epoch - 5ms/step\n",
      "Epoch 594/1000\n",
      "181/181 - 1s - loss: 0.3143 - accuracy: 0.8708 - val_loss: 0.3327 - val_accuracy: 0.8835 - 935ms/epoch - 5ms/step\n",
      "Epoch 595/1000\n",
      "181/181 - 1s - loss: 0.3128 - accuracy: 0.8765 - val_loss: 0.3325 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 596/1000\n",
      "181/181 - 1s - loss: 0.3154 - accuracy: 0.8739 - val_loss: 0.3394 - val_accuracy: 0.8742 - 1s/epoch - 7ms/step\n",
      "Epoch 597/1000\n",
      "181/181 - 1s - loss: 0.3170 - accuracy: 0.8712 - val_loss: 0.3415 - val_accuracy: 0.8711 - 864ms/epoch - 5ms/step\n",
      "Epoch 598/1000\n",
      "181/181 - 1s - loss: 0.3177 - accuracy: 0.8708 - val_loss: 0.3438 - val_accuracy: 0.8680 - 850ms/epoch - 5ms/step\n",
      "Epoch 599/1000\n",
      "181/181 - 1s - loss: 0.3150 - accuracy: 0.8743 - val_loss: 0.3486 - val_accuracy: 0.8882 - 892ms/epoch - 5ms/step\n",
      "Epoch 600/1000\n",
      "181/181 - 1s - loss: 0.3164 - accuracy: 0.8715 - val_loss: 0.3436 - val_accuracy: 0.8680 - 846ms/epoch - 5ms/step\n",
      "Epoch 601/1000\n",
      "181/181 - 1s - loss: 0.3151 - accuracy: 0.8719 - val_loss: 0.3273 - val_accuracy: 0.8804 - 825ms/epoch - 5ms/step\n",
      "Epoch 602/1000\n",
      "181/181 - 1s - loss: 0.3166 - accuracy: 0.8727 - val_loss: 0.3302 - val_accuracy: 0.8789 - 834ms/epoch - 5ms/step\n",
      "Epoch 603/1000\n",
      "181/181 - 1s - loss: 0.3159 - accuracy: 0.8741 - val_loss: 0.3344 - val_accuracy: 0.8711 - 834ms/epoch - 5ms/step\n",
      "Epoch 604/1000\n",
      "181/181 - 1s - loss: 0.3122 - accuracy: 0.8750 - val_loss: 0.3460 - val_accuracy: 0.8742 - 833ms/epoch - 5ms/step\n",
      "Epoch 605/1000\n",
      "181/181 - 1s - loss: 0.3153 - accuracy: 0.8738 - val_loss: 0.3343 - val_accuracy: 0.8882 - 831ms/epoch - 5ms/step\n",
      "Epoch 606/1000\n",
      "181/181 - 1s - loss: 0.3152 - accuracy: 0.8738 - val_loss: 0.3288 - val_accuracy: 0.8804 - 826ms/epoch - 5ms/step\n",
      "Epoch 607/1000\n",
      "181/181 - 1s - loss: 0.3146 - accuracy: 0.8736 - val_loss: 0.3649 - val_accuracy: 0.8540 - 828ms/epoch - 5ms/step\n",
      "Epoch 608/1000\n",
      "181/181 - 1s - loss: 0.3155 - accuracy: 0.8741 - val_loss: 0.3533 - val_accuracy: 0.8898 - 825ms/epoch - 5ms/step\n",
      "Epoch 609/1000\n",
      "181/181 - 1s - loss: 0.3140 - accuracy: 0.8717 - val_loss: 0.3295 - val_accuracy: 0.8789 - 832ms/epoch - 5ms/step\n",
      "Epoch 610/1000\n",
      "181/181 - 1s - loss: 0.3150 - accuracy: 0.8715 - val_loss: 0.3343 - val_accuracy: 0.8696 - 832ms/epoch - 5ms/step\n",
      "Epoch 611/1000\n",
      "181/181 - 1s - loss: 0.3187 - accuracy: 0.8712 - val_loss: 0.3392 - val_accuracy: 0.8696 - 828ms/epoch - 5ms/step\n",
      "Epoch 612/1000\n",
      "181/181 - 1s - loss: 0.3142 - accuracy: 0.8726 - val_loss: 0.3298 - val_accuracy: 0.8835 - 829ms/epoch - 5ms/step\n",
      "Epoch 613/1000\n",
      "181/181 - 1s - loss: 0.3137 - accuracy: 0.8772 - val_loss: 0.3321 - val_accuracy: 0.8820 - 833ms/epoch - 5ms/step\n",
      "Epoch 614/1000\n",
      "181/181 - 1s - loss: 0.3143 - accuracy: 0.8748 - val_loss: 0.3329 - val_accuracy: 0.8866 - 831ms/epoch - 5ms/step\n",
      "Epoch 615/1000\n",
      "181/181 - 1s - loss: 0.3123 - accuracy: 0.8733 - val_loss: 0.3315 - val_accuracy: 0.8835 - 831ms/epoch - 5ms/step\n",
      "Epoch 616/1000\n",
      "181/181 - 1s - loss: 0.3160 - accuracy: 0.8714 - val_loss: 0.3341 - val_accuracy: 0.8742 - 830ms/epoch - 5ms/step\n",
      "Epoch 617/1000\n",
      "181/181 - 1s - loss: 0.3145 - accuracy: 0.8715 - val_loss: 0.3276 - val_accuracy: 0.8789 - 888ms/epoch - 5ms/step\n",
      "Epoch 618/1000\n",
      "181/181 - 1s - loss: 0.3125 - accuracy: 0.8767 - val_loss: 0.3459 - val_accuracy: 0.8835 - 941ms/epoch - 5ms/step\n",
      "Epoch 619/1000\n",
      "181/181 - 1s - loss: 0.3171 - accuracy: 0.8707 - val_loss: 0.3314 - val_accuracy: 0.8773 - 943ms/epoch - 5ms/step\n",
      "Epoch 620/1000\n",
      "181/181 - 1s - loss: 0.3164 - accuracy: 0.8729 - val_loss: 0.3302 - val_accuracy: 0.8835 - 963ms/epoch - 5ms/step\n",
      "Epoch 621/1000\n",
      "181/181 - 1s - loss: 0.3178 - accuracy: 0.8729 - val_loss: 0.3369 - val_accuracy: 0.8742 - 955ms/epoch - 5ms/step\n",
      "Epoch 622/1000\n",
      "181/181 - 1s - loss: 0.3160 - accuracy: 0.8715 - val_loss: 0.3396 - val_accuracy: 0.8820 - 937ms/epoch - 5ms/step\n",
      "Epoch 623/1000\n",
      "181/181 - 1s - loss: 0.3153 - accuracy: 0.8720 - val_loss: 0.3288 - val_accuracy: 0.8835 - 997ms/epoch - 6ms/step\n",
      "Epoch 624/1000\n",
      "181/181 - 1s - loss: 0.3143 - accuracy: 0.8724 - val_loss: 0.3351 - val_accuracy: 0.8898 - 984ms/epoch - 5ms/step\n",
      "Epoch 625/1000\n",
      "181/181 - 1s - loss: 0.3162 - accuracy: 0.8719 - val_loss: 0.3343 - val_accuracy: 0.8835 - 889ms/epoch - 5ms/step\n",
      "Epoch 626/1000\n",
      "181/181 - 1s - loss: 0.3125 - accuracy: 0.8750 - val_loss: 0.3286 - val_accuracy: 0.8851 - 833ms/epoch - 5ms/step\n",
      "Epoch 627/1000\n",
      "181/181 - 1s - loss: 0.3145 - accuracy: 0.8746 - val_loss: 0.3518 - val_accuracy: 0.8773 - 836ms/epoch - 5ms/step\n",
      "Epoch 628/1000\n",
      "181/181 - 1s - loss: 0.3150 - accuracy: 0.8731 - val_loss: 0.3363 - val_accuracy: 0.8851 - 902ms/epoch - 5ms/step\n",
      "Epoch 629/1000\n",
      "181/181 - 1s - loss: 0.3138 - accuracy: 0.8738 - val_loss: 0.3584 - val_accuracy: 0.8602 - 1s/epoch - 6ms/step\n",
      "Epoch 630/1000\n",
      "181/181 - 1s - loss: 0.3142 - accuracy: 0.8729 - val_loss: 0.3276 - val_accuracy: 0.8696 - 966ms/epoch - 5ms/step\n",
      "Epoch 631/1000\n",
      "181/181 - 1s - loss: 0.3120 - accuracy: 0.8753 - val_loss: 0.3332 - val_accuracy: 0.8773 - 944ms/epoch - 5ms/step\n",
      "Epoch 632/1000\n",
      "181/181 - 1s - loss: 0.3148 - accuracy: 0.8741 - val_loss: 0.3391 - val_accuracy: 0.8789 - 932ms/epoch - 5ms/step\n",
      "Epoch 633/1000\n",
      "181/181 - 1s - loss: 0.3147 - accuracy: 0.8741 - val_loss: 0.3326 - val_accuracy: 0.8773 - 895ms/epoch - 5ms/step\n",
      "Epoch 634/1000\n",
      "181/181 - 1s - loss: 0.3141 - accuracy: 0.8753 - val_loss: 0.3339 - val_accuracy: 0.8820 - 863ms/epoch - 5ms/step\n",
      "Epoch 635/1000\n",
      "181/181 - 1s - loss: 0.3128 - accuracy: 0.8736 - val_loss: 0.3366 - val_accuracy: 0.8696 - 1s/epoch - 6ms/step\n",
      "Epoch 636/1000\n",
      "181/181 - 1s - loss: 0.3144 - accuracy: 0.8715 - val_loss: 0.3390 - val_accuracy: 0.8711 - 856ms/epoch - 5ms/step\n",
      "Epoch 637/1000\n",
      "181/181 - 1s - loss: 0.3151 - accuracy: 0.8727 - val_loss: 0.3284 - val_accuracy: 0.8820 - 842ms/epoch - 5ms/step\n",
      "Epoch 638/1000\n",
      "181/181 - 1s - loss: 0.3144 - accuracy: 0.8701 - val_loss: 0.3357 - val_accuracy: 0.8758 - 838ms/epoch - 5ms/step\n",
      "Epoch 639/1000\n",
      "181/181 - 1s - loss: 0.3134 - accuracy: 0.8720 - val_loss: 0.3350 - val_accuracy: 0.8758 - 881ms/epoch - 5ms/step\n",
      "Epoch 640/1000\n",
      "181/181 - 1s - loss: 0.3124 - accuracy: 0.8743 - val_loss: 0.3284 - val_accuracy: 0.8804 - 868ms/epoch - 5ms/step\n",
      "Epoch 641/1000\n",
      "181/181 - 1s - loss: 0.3144 - accuracy: 0.8734 - val_loss: 0.3350 - val_accuracy: 0.8773 - 956ms/epoch - 5ms/step\n",
      "Epoch 642/1000\n",
      "181/181 - 1s - loss: 0.3141 - accuracy: 0.8746 - val_loss: 0.3377 - val_accuracy: 0.8773 - 975ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 643/1000\n",
      "181/181 - 1s - loss: 0.3134 - accuracy: 0.8736 - val_loss: 0.3327 - val_accuracy: 0.8727 - 922ms/epoch - 5ms/step\n",
      "Epoch 644/1000\n",
      "181/181 - 1s - loss: 0.3112 - accuracy: 0.8757 - val_loss: 0.3343 - val_accuracy: 0.8820 - 886ms/epoch - 5ms/step\n",
      "Epoch 645/1000\n",
      "181/181 - 1s - loss: 0.3129 - accuracy: 0.8752 - val_loss: 0.3369 - val_accuracy: 0.8773 - 945ms/epoch - 5ms/step\n",
      "Epoch 646/1000\n",
      "181/181 - 1s - loss: 0.3149 - accuracy: 0.8722 - val_loss: 0.3307 - val_accuracy: 0.8758 - 1s/epoch - 7ms/step\n",
      "Epoch 647/1000\n",
      "181/181 - 2s - loss: 0.3155 - accuracy: 0.8729 - val_loss: 0.3362 - val_accuracy: 0.8727 - 2s/epoch - 10ms/step\n",
      "Epoch 648/1000\n",
      "181/181 - 2s - loss: 0.3129 - accuracy: 0.8727 - val_loss: 0.3445 - val_accuracy: 0.8851 - 2s/epoch - 10ms/step\n",
      "Epoch 649/1000\n",
      "181/181 - 2s - loss: 0.3141 - accuracy: 0.8729 - val_loss: 0.3328 - val_accuracy: 0.8851 - 2s/epoch - 11ms/step\n",
      "Epoch 650/1000\n",
      "181/181 - 1s - loss: 0.3138 - accuracy: 0.8727 - val_loss: 0.3279 - val_accuracy: 0.8851 - 1s/epoch - 7ms/step\n",
      "Epoch 651/1000\n",
      "181/181 - 1s - loss: 0.3140 - accuracy: 0.8717 - val_loss: 0.3322 - val_accuracy: 0.8758 - 819ms/epoch - 5ms/step\n",
      "Epoch 652/1000\n",
      "181/181 - 1s - loss: 0.3134 - accuracy: 0.8752 - val_loss: 0.3329 - val_accuracy: 0.8820 - 868ms/epoch - 5ms/step\n",
      "Epoch 653/1000\n",
      "181/181 - 1s - loss: 0.3142 - accuracy: 0.8739 - val_loss: 0.3314 - val_accuracy: 0.8773 - 841ms/epoch - 5ms/step\n",
      "Epoch 654/1000\n",
      "181/181 - 1s - loss: 0.3118 - accuracy: 0.8726 - val_loss: 0.3345 - val_accuracy: 0.8820 - 894ms/epoch - 5ms/step\n",
      "Epoch 655/1000\n",
      "181/181 - 1s - loss: 0.3113 - accuracy: 0.8743 - val_loss: 0.3432 - val_accuracy: 0.8789 - 959ms/epoch - 5ms/step\n",
      "Epoch 656/1000\n",
      "181/181 - 1s - loss: 0.3145 - accuracy: 0.8731 - val_loss: 0.3316 - val_accuracy: 0.8835 - 927ms/epoch - 5ms/step\n",
      "Epoch 657/1000\n",
      "181/181 - 1s - loss: 0.3143 - accuracy: 0.8701 - val_loss: 0.3274 - val_accuracy: 0.8820 - 833ms/epoch - 5ms/step\n",
      "Epoch 658/1000\n",
      "181/181 - 1s - loss: 0.3123 - accuracy: 0.8738 - val_loss: 0.3284 - val_accuracy: 0.8820 - 823ms/epoch - 5ms/step\n",
      "Epoch 659/1000\n",
      "181/181 - 1s - loss: 0.3125 - accuracy: 0.8753 - val_loss: 0.3252 - val_accuracy: 0.8804 - 840ms/epoch - 5ms/step\n",
      "Epoch 660/1000\n",
      "181/181 - 1s - loss: 0.3122 - accuracy: 0.8738 - val_loss: 0.3341 - val_accuracy: 0.8851 - 826ms/epoch - 5ms/step\n",
      "Epoch 661/1000\n",
      "181/181 - 1s - loss: 0.3171 - accuracy: 0.8708 - val_loss: 0.3275 - val_accuracy: 0.8835 - 876ms/epoch - 5ms/step\n",
      "Epoch 662/1000\n",
      "181/181 - 1s - loss: 0.3132 - accuracy: 0.8710 - val_loss: 0.3302 - val_accuracy: 0.8804 - 875ms/epoch - 5ms/step\n",
      "Epoch 663/1000\n",
      "181/181 - 1s - loss: 0.3137 - accuracy: 0.8752 - val_loss: 0.3314 - val_accuracy: 0.8789 - 878ms/epoch - 5ms/step\n",
      "Epoch 664/1000\n",
      "181/181 - 1s - loss: 0.3122 - accuracy: 0.8734 - val_loss: 0.3376 - val_accuracy: 0.8820 - 1s/epoch - 6ms/step\n",
      "Epoch 665/1000\n",
      "181/181 - 1s - loss: 0.3128 - accuracy: 0.8724 - val_loss: 0.3305 - val_accuracy: 0.8820 - 978ms/epoch - 5ms/step\n",
      "Epoch 666/1000\n",
      "181/181 - 1s - loss: 0.3139 - accuracy: 0.8755 - val_loss: 0.3281 - val_accuracy: 0.8758 - 1s/epoch - 6ms/step\n",
      "Epoch 667/1000\n",
      "181/181 - 1s - loss: 0.3118 - accuracy: 0.8752 - val_loss: 0.3295 - val_accuracy: 0.8835 - 1s/epoch - 6ms/step\n",
      "Epoch 668/1000\n",
      "181/181 - 1s - loss: 0.3127 - accuracy: 0.8753 - val_loss: 0.3333 - val_accuracy: 0.8758 - 925ms/epoch - 5ms/step\n",
      "Epoch 669/1000\n",
      "181/181 - 1s - loss: 0.3124 - accuracy: 0.8739 - val_loss: 0.3294 - val_accuracy: 0.8773 - 859ms/epoch - 5ms/step\n",
      "Epoch 670/1000\n",
      "181/181 - 1s - loss: 0.3126 - accuracy: 0.8729 - val_loss: 0.3267 - val_accuracy: 0.8804 - 893ms/epoch - 5ms/step\n",
      "Epoch 671/1000\n",
      "181/181 - 1s - loss: 0.3119 - accuracy: 0.8750 - val_loss: 0.3287 - val_accuracy: 0.8773 - 867ms/epoch - 5ms/step\n",
      "Epoch 672/1000\n",
      "181/181 - 1s - loss: 0.3121 - accuracy: 0.8733 - val_loss: 0.3308 - val_accuracy: 0.8835 - 866ms/epoch - 5ms/step\n",
      "Epoch 673/1000\n",
      "181/181 - 1s - loss: 0.3131 - accuracy: 0.8734 - val_loss: 0.3316 - val_accuracy: 0.8773 - 888ms/epoch - 5ms/step\n",
      "Epoch 674/1000\n",
      "181/181 - 1s - loss: 0.3121 - accuracy: 0.8762 - val_loss: 0.3306 - val_accuracy: 0.8804 - 882ms/epoch - 5ms/step\n",
      "Epoch 675/1000\n",
      "181/181 - 1s - loss: 0.3147 - accuracy: 0.8688 - val_loss: 0.3267 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 676/1000\n",
      "181/181 - 1s - loss: 0.3109 - accuracy: 0.8734 - val_loss: 0.3305 - val_accuracy: 0.8773 - 978ms/epoch - 5ms/step\n",
      "Epoch 677/1000\n",
      "181/181 - 1s - loss: 0.3121 - accuracy: 0.8741 - val_loss: 0.3363 - val_accuracy: 0.8820 - 900ms/epoch - 5ms/step\n",
      "Epoch 678/1000\n",
      "181/181 - 1s - loss: 0.3125 - accuracy: 0.8736 - val_loss: 0.3297 - val_accuracy: 0.8835 - 974ms/epoch - 5ms/step\n",
      "Epoch 679/1000\n",
      "181/181 - 4s - loss: 0.3153 - accuracy: 0.8746 - val_loss: 0.3409 - val_accuracy: 0.8851 - 4s/epoch - 22ms/step\n",
      "Epoch 680/1000\n",
      "181/181 - 1s - loss: 0.3109 - accuracy: 0.8762 - val_loss: 0.3427 - val_accuracy: 0.8696 - 1s/epoch - 6ms/step\n",
      "Epoch 681/1000\n",
      "181/181 - 1s - loss: 0.3128 - accuracy: 0.8757 - val_loss: 0.3286 - val_accuracy: 0.8851 - 1s/epoch - 7ms/step\n",
      "Epoch 682/1000\n",
      "181/181 - 2s - loss: 0.3152 - accuracy: 0.8714 - val_loss: 0.3257 - val_accuracy: 0.8773 - 2s/epoch - 13ms/step\n",
      "Epoch 683/1000\n",
      "181/181 - 1s - loss: 0.3112 - accuracy: 0.8752 - val_loss: 0.3394 - val_accuracy: 0.8820 - 1s/epoch - 7ms/step\n",
      "Epoch 684/1000\n",
      "181/181 - 1s - loss: 0.3113 - accuracy: 0.8724 - val_loss: 0.3317 - val_accuracy: 0.8866 - 1s/epoch - 7ms/step\n",
      "Epoch 685/1000\n",
      "181/181 - 2s - loss: 0.3117 - accuracy: 0.8736 - val_loss: 0.3401 - val_accuracy: 0.8835 - 2s/epoch - 13ms/step\n",
      "Epoch 686/1000\n",
      "181/181 - 2s - loss: 0.3125 - accuracy: 0.8714 - val_loss: 0.3389 - val_accuracy: 0.8711 - 2s/epoch - 14ms/step\n",
      "Epoch 687/1000\n",
      "181/181 - 1s - loss: 0.3121 - accuracy: 0.8753 - val_loss: 0.3374 - val_accuracy: 0.8804 - 986ms/epoch - 5ms/step\n",
      "Epoch 688/1000\n",
      "181/181 - 1s - loss: 0.3136 - accuracy: 0.8726 - val_loss: 0.3372 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 689/1000\n",
      "181/181 - 1s - loss: 0.3119 - accuracy: 0.8719 - val_loss: 0.3371 - val_accuracy: 0.8742 - 1s/epoch - 6ms/step\n",
      "Epoch 690/1000\n",
      "181/181 - 1s - loss: 0.3150 - accuracy: 0.8745 - val_loss: 0.3370 - val_accuracy: 0.8804 - 1s/epoch - 8ms/step\n",
      "Epoch 691/1000\n",
      "181/181 - 1s - loss: 0.3120 - accuracy: 0.8726 - val_loss: 0.3324 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 692/1000\n",
      "181/181 - 1s - loss: 0.3120 - accuracy: 0.8736 - val_loss: 0.3322 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 693/1000\n",
      "181/181 - 1s - loss: 0.3102 - accuracy: 0.8755 - val_loss: 0.3396 - val_accuracy: 0.8665 - 1s/epoch - 6ms/step\n",
      "Epoch 694/1000\n",
      "181/181 - 1s - loss: 0.3094 - accuracy: 0.8765 - val_loss: 0.3371 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 695/1000\n",
      "181/181 - 1s - loss: 0.3129 - accuracy: 0.8733 - val_loss: 0.3307 - val_accuracy: 0.8773 - 876ms/epoch - 5ms/step\n",
      "Epoch 696/1000\n",
      "181/181 - 1s - loss: 0.3119 - accuracy: 0.8745 - val_loss: 0.3260 - val_accuracy: 0.8789 - 932ms/epoch - 5ms/step\n",
      "Epoch 697/1000\n",
      "181/181 - 1s - loss: 0.3131 - accuracy: 0.8719 - val_loss: 0.3291 - val_accuracy: 0.8851 - 893ms/epoch - 5ms/step\n",
      "Epoch 698/1000\n",
      "181/181 - 1s - loss: 0.3116 - accuracy: 0.8745 - val_loss: 0.3333 - val_accuracy: 0.8851 - 883ms/epoch - 5ms/step\n",
      "Epoch 699/1000\n",
      "181/181 - 1s - loss: 0.3088 - accuracy: 0.8753 - val_loss: 0.3297 - val_accuracy: 0.8758 - 1s/epoch - 6ms/step\n",
      "Epoch 700/1000\n",
      "181/181 - 1s - loss: 0.3098 - accuracy: 0.8719 - val_loss: 0.3269 - val_accuracy: 0.8773 - 931ms/epoch - 5ms/step\n",
      "Epoch 701/1000\n",
      "181/181 - 1s - loss: 0.3110 - accuracy: 0.8757 - val_loss: 0.3305 - val_accuracy: 0.8742 - 977ms/epoch - 5ms/step\n",
      "Epoch 702/1000\n",
      "181/181 - 1s - loss: 0.3104 - accuracy: 0.8738 - val_loss: 0.3286 - val_accuracy: 0.8835 - 1s/epoch - 6ms/step\n",
      "Epoch 703/1000\n",
      "181/181 - 1s - loss: 0.3097 - accuracy: 0.8736 - val_loss: 0.3263 - val_accuracy: 0.8820 - 909ms/epoch - 5ms/step\n",
      "Epoch 704/1000\n",
      "181/181 - 1s - loss: 0.3100 - accuracy: 0.8739 - val_loss: 0.3297 - val_accuracy: 0.8820 - 929ms/epoch - 5ms/step\n",
      "Epoch 705/1000\n",
      "181/181 - 1s - loss: 0.3096 - accuracy: 0.8758 - val_loss: 0.3309 - val_accuracy: 0.8789 - 954ms/epoch - 5ms/step\n",
      "Epoch 706/1000\n",
      "181/181 - 1s - loss: 0.3136 - accuracy: 0.8736 - val_loss: 0.3317 - val_accuracy: 0.8758 - 878ms/epoch - 5ms/step\n",
      "Epoch 707/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 - 1s - loss: 0.3123 - accuracy: 0.8733 - val_loss: 0.3281 - val_accuracy: 0.8804 - 844ms/epoch - 5ms/step\n",
      "Epoch 708/1000\n",
      "181/181 - 1s - loss: 0.3081 - accuracy: 0.8784 - val_loss: 0.3443 - val_accuracy: 0.8851 - 837ms/epoch - 5ms/step\n",
      "Epoch 709/1000\n",
      "181/181 - 1s - loss: 0.3116 - accuracy: 0.8739 - val_loss: 0.3268 - val_accuracy: 0.8742 - 832ms/epoch - 5ms/step\n",
      "Epoch 710/1000\n",
      "181/181 - 1s - loss: 0.3127 - accuracy: 0.8733 - val_loss: 0.3274 - val_accuracy: 0.8820 - 850ms/epoch - 5ms/step\n",
      "Epoch 711/1000\n",
      "181/181 - 1s - loss: 0.3118 - accuracy: 0.8717 - val_loss: 0.3302 - val_accuracy: 0.8804 - 866ms/epoch - 5ms/step\n",
      "Epoch 712/1000\n",
      "181/181 - 1s - loss: 0.3121 - accuracy: 0.8726 - val_loss: 0.3310 - val_accuracy: 0.8835 - 849ms/epoch - 5ms/step\n",
      "Epoch 713/1000\n",
      "181/181 - 1s - loss: 0.3107 - accuracy: 0.8739 - val_loss: 0.3415 - val_accuracy: 0.8851 - 837ms/epoch - 5ms/step\n",
      "Epoch 714/1000\n",
      "181/181 - 1s - loss: 0.3156 - accuracy: 0.8733 - val_loss: 0.3324 - val_accuracy: 0.8820 - 906ms/epoch - 5ms/step\n",
      "Epoch 715/1000\n",
      "181/181 - 1s - loss: 0.3112 - accuracy: 0.8726 - val_loss: 0.3256 - val_accuracy: 0.8758 - 851ms/epoch - 5ms/step\n",
      "Epoch 716/1000\n",
      "181/181 - 1s - loss: 0.3099 - accuracy: 0.8727 - val_loss: 0.3316 - val_accuracy: 0.8804 - 858ms/epoch - 5ms/step\n",
      "Epoch 717/1000\n",
      "181/181 - 1s - loss: 0.3104 - accuracy: 0.8733 - val_loss: 0.3258 - val_accuracy: 0.8696 - 874ms/epoch - 5ms/step\n",
      "Epoch 718/1000\n",
      "181/181 - 1s - loss: 0.3098 - accuracy: 0.8750 - val_loss: 0.3340 - val_accuracy: 0.8742 - 841ms/epoch - 5ms/step\n",
      "Epoch 719/1000\n",
      "181/181 - 1s - loss: 0.3096 - accuracy: 0.8746 - val_loss: 0.3385 - val_accuracy: 0.8789 - 841ms/epoch - 5ms/step\n",
      "Epoch 720/1000\n",
      "181/181 - 1s - loss: 0.3120 - accuracy: 0.8745 - val_loss: 0.3352 - val_accuracy: 0.8835 - 853ms/epoch - 5ms/step\n",
      "Epoch 721/1000\n",
      "181/181 - 1s - loss: 0.3131 - accuracy: 0.8726 - val_loss: 0.3333 - val_accuracy: 0.8820 - 903ms/epoch - 5ms/step\n",
      "Epoch 722/1000\n",
      "181/181 - 1s - loss: 0.3111 - accuracy: 0.8734 - val_loss: 0.3268 - val_accuracy: 0.8820 - 960ms/epoch - 5ms/step\n",
      "Epoch 723/1000\n",
      "181/181 - 1s - loss: 0.3104 - accuracy: 0.8750 - val_loss: 0.3323 - val_accuracy: 0.8804 - 895ms/epoch - 5ms/step\n",
      "Epoch 724/1000\n",
      "181/181 - 1s - loss: 0.3104 - accuracy: 0.8733 - val_loss: 0.3410 - val_accuracy: 0.8727 - 1s/epoch - 6ms/step\n",
      "Epoch 725/1000\n",
      "181/181 - 1s - loss: 0.3102 - accuracy: 0.8733 - val_loss: 0.3261 - val_accuracy: 0.8742 - 965ms/epoch - 5ms/step\n",
      "Epoch 726/1000\n",
      "181/181 - 1s - loss: 0.3117 - accuracy: 0.8762 - val_loss: 0.3275 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 727/1000\n",
      "181/181 - 1s - loss: 0.3103 - accuracy: 0.8707 - val_loss: 0.3282 - val_accuracy: 0.8820 - 998ms/epoch - 6ms/step\n",
      "Epoch 728/1000\n",
      "181/181 - 1s - loss: 0.3130 - accuracy: 0.8753 - val_loss: 0.3272 - val_accuracy: 0.8804 - 981ms/epoch - 5ms/step\n",
      "Epoch 729/1000\n",
      "181/181 - 1s - loss: 0.3108 - accuracy: 0.8743 - val_loss: 0.3271 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 730/1000\n",
      "181/181 - 1s - loss: 0.3084 - accuracy: 0.8769 - val_loss: 0.3272 - val_accuracy: 0.8773 - 934ms/epoch - 5ms/step\n",
      "Epoch 731/1000\n",
      "181/181 - 1s - loss: 0.3106 - accuracy: 0.8739 - val_loss: 0.3276 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 732/1000\n",
      "181/181 - 1s - loss: 0.3104 - accuracy: 0.8743 - val_loss: 0.3244 - val_accuracy: 0.8835 - 1s/epoch - 7ms/step\n",
      "Epoch 733/1000\n",
      "181/181 - 1s - loss: 0.3155 - accuracy: 0.8719 - val_loss: 0.3248 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 734/1000\n",
      "181/181 - 1s - loss: 0.3091 - accuracy: 0.8738 - val_loss: 0.3298 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 735/1000\n",
      "181/181 - 1s - loss: 0.3106 - accuracy: 0.8733 - val_loss: 0.3264 - val_accuracy: 0.8711 - 1s/epoch - 6ms/step\n",
      "Epoch 736/1000\n",
      "181/181 - 1s - loss: 0.3117 - accuracy: 0.8733 - val_loss: 0.3275 - val_accuracy: 0.8742 - 989ms/epoch - 5ms/step\n",
      "Epoch 737/1000\n",
      "181/181 - 1s - loss: 0.3088 - accuracy: 0.8750 - val_loss: 0.3546 - val_accuracy: 0.8851 - 968ms/epoch - 5ms/step\n",
      "Epoch 738/1000\n",
      "181/181 - 1s - loss: 0.3118 - accuracy: 0.8752 - val_loss: 0.3236 - val_accuracy: 0.8789 - 993ms/epoch - 5ms/step\n",
      "Epoch 739/1000\n",
      "181/181 - 1s - loss: 0.3098 - accuracy: 0.8755 - val_loss: 0.3274 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 740/1000\n",
      "181/181 - 1s - loss: 0.3100 - accuracy: 0.8757 - val_loss: 0.3315 - val_accuracy: 0.8820 - 859ms/epoch - 5ms/step\n",
      "Epoch 741/1000\n",
      "181/181 - 1s - loss: 0.3124 - accuracy: 0.8739 - val_loss: 0.3357 - val_accuracy: 0.8866 - 868ms/epoch - 5ms/step\n",
      "Epoch 742/1000\n",
      "181/181 - 1s - loss: 0.3108 - accuracy: 0.8741 - val_loss: 0.3355 - val_accuracy: 0.8835 - 868ms/epoch - 5ms/step\n",
      "Epoch 743/1000\n",
      "181/181 - 1s - loss: 0.3116 - accuracy: 0.8755 - val_loss: 0.3285 - val_accuracy: 0.8727 - 864ms/epoch - 5ms/step\n",
      "Epoch 744/1000\n",
      "181/181 - 1s - loss: 0.3121 - accuracy: 0.8714 - val_loss: 0.3431 - val_accuracy: 0.8727 - 976ms/epoch - 5ms/step\n",
      "Epoch 745/1000\n",
      "181/181 - 1s - loss: 0.3104 - accuracy: 0.8745 - val_loss: 0.3309 - val_accuracy: 0.8789 - 870ms/epoch - 5ms/step\n",
      "Epoch 746/1000\n",
      "181/181 - 1s - loss: 0.3121 - accuracy: 0.8708 - val_loss: 0.3381 - val_accuracy: 0.8758 - 899ms/epoch - 5ms/step\n",
      "Epoch 747/1000\n",
      "181/181 - 1s - loss: 0.3097 - accuracy: 0.8736 - val_loss: 0.3296 - val_accuracy: 0.8789 - 884ms/epoch - 5ms/step\n",
      "Epoch 748/1000\n",
      "181/181 - 1s - loss: 0.3123 - accuracy: 0.8729 - val_loss: 0.3252 - val_accuracy: 0.8758 - 907ms/epoch - 5ms/step\n",
      "Epoch 749/1000\n",
      "181/181 - 1s - loss: 0.3107 - accuracy: 0.8736 - val_loss: 0.3302 - val_accuracy: 0.8820 - 882ms/epoch - 5ms/step\n",
      "Epoch 750/1000\n",
      "181/181 - 1s - loss: 0.3108 - accuracy: 0.8720 - val_loss: 0.3282 - val_accuracy: 0.8804 - 894ms/epoch - 5ms/step\n",
      "Epoch 751/1000\n",
      "181/181 - 1s - loss: 0.3096 - accuracy: 0.8722 - val_loss: 0.3243 - val_accuracy: 0.8773 - 886ms/epoch - 5ms/step\n",
      "Epoch 752/1000\n",
      "181/181 - 1s - loss: 0.3108 - accuracy: 0.8739 - val_loss: 0.3259 - val_accuracy: 0.8851 - 852ms/epoch - 5ms/step\n",
      "Epoch 753/1000\n",
      "181/181 - 1s - loss: 0.3099 - accuracy: 0.8739 - val_loss: 0.3270 - val_accuracy: 0.8804 - 853ms/epoch - 5ms/step\n",
      "Epoch 754/1000\n",
      "181/181 - 1s - loss: 0.3069 - accuracy: 0.8774 - val_loss: 0.3275 - val_accuracy: 0.8758 - 857ms/epoch - 5ms/step\n",
      "Epoch 755/1000\n",
      "181/181 - 1s - loss: 0.3116 - accuracy: 0.8720 - val_loss: 0.3249 - val_accuracy: 0.8820 - 876ms/epoch - 5ms/step\n",
      "Epoch 756/1000\n",
      "181/181 - 1s - loss: 0.3091 - accuracy: 0.8755 - val_loss: 0.3321 - val_accuracy: 0.8820 - 866ms/epoch - 5ms/step\n",
      "Epoch 757/1000\n",
      "181/181 - 1s - loss: 0.3084 - accuracy: 0.8767 - val_loss: 0.3244 - val_accuracy: 0.8758 - 872ms/epoch - 5ms/step\n",
      "Epoch 758/1000\n",
      "181/181 - 1s - loss: 0.3118 - accuracy: 0.8726 - val_loss: 0.3332 - val_accuracy: 0.8758 - 874ms/epoch - 5ms/step\n",
      "Epoch 759/1000\n",
      "181/181 - 1s - loss: 0.3099 - accuracy: 0.8696 - val_loss: 0.3262 - val_accuracy: 0.8758 - 860ms/epoch - 5ms/step\n",
      "Epoch 760/1000\n",
      "181/181 - 1s - loss: 0.3108 - accuracy: 0.8748 - val_loss: 0.3281 - val_accuracy: 0.8835 - 859ms/epoch - 5ms/step\n",
      "Epoch 761/1000\n",
      "181/181 - 1s - loss: 0.3128 - accuracy: 0.8748 - val_loss: 0.3296 - val_accuracy: 0.8851 - 872ms/epoch - 5ms/step\n",
      "Epoch 762/1000\n",
      "181/181 - 1s - loss: 0.3083 - accuracy: 0.8748 - val_loss: 0.3506 - val_accuracy: 0.8820 - 906ms/epoch - 5ms/step\n",
      "Epoch 763/1000\n",
      "181/181 - 1s - loss: 0.3098 - accuracy: 0.8750 - val_loss: 0.3326 - val_accuracy: 0.8820 - 859ms/epoch - 5ms/step\n",
      "Epoch 764/1000\n",
      "181/181 - 1s - loss: 0.3092 - accuracy: 0.8739 - val_loss: 0.3483 - val_accuracy: 0.8634 - 851ms/epoch - 5ms/step\n",
      "Epoch 765/1000\n",
      "181/181 - 1s - loss: 0.3106 - accuracy: 0.8755 - val_loss: 0.3537 - val_accuracy: 0.8773 - 859ms/epoch - 5ms/step\n",
      "Epoch 766/1000\n",
      "181/181 - 1s - loss: 0.3118 - accuracy: 0.8786 - val_loss: 0.3265 - val_accuracy: 0.8758 - 883ms/epoch - 5ms/step\n",
      "Epoch 767/1000\n",
      "181/181 - 1s - loss: 0.3094 - accuracy: 0.8765 - val_loss: 0.3284 - val_accuracy: 0.8804 - 855ms/epoch - 5ms/step\n",
      "Epoch 768/1000\n",
      "181/181 - 1s - loss: 0.3117 - accuracy: 0.8745 - val_loss: 0.3342 - val_accuracy: 0.8835 - 903ms/epoch - 5ms/step\n",
      "Epoch 769/1000\n",
      "181/181 - 1s - loss: 0.3101 - accuracy: 0.8739 - val_loss: 0.3307 - val_accuracy: 0.8742 - 935ms/epoch - 5ms/step\n",
      "Epoch 770/1000\n",
      "181/181 - 1s - loss: 0.3091 - accuracy: 0.8745 - val_loss: 0.3284 - val_accuracy: 0.8789 - 932ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 771/1000\n",
      "181/181 - 1s - loss: 0.3087 - accuracy: 0.8753 - val_loss: 0.3460 - val_accuracy: 0.8602 - 901ms/epoch - 5ms/step\n",
      "Epoch 772/1000\n",
      "181/181 - 1s - loss: 0.3100 - accuracy: 0.8746 - val_loss: 0.3256 - val_accuracy: 0.8804 - 932ms/epoch - 5ms/step\n",
      "Epoch 773/1000\n",
      "181/181 - 1s - loss: 0.3092 - accuracy: 0.8758 - val_loss: 0.3251 - val_accuracy: 0.8742 - 979ms/epoch - 5ms/step\n",
      "Epoch 774/1000\n",
      "181/181 - 1s - loss: 0.3102 - accuracy: 0.8748 - val_loss: 0.3314 - val_accuracy: 0.8773 - 988ms/epoch - 5ms/step\n",
      "Epoch 775/1000\n",
      "181/181 - 1s - loss: 0.3101 - accuracy: 0.8733 - val_loss: 0.3258 - val_accuracy: 0.8773 - 931ms/epoch - 5ms/step\n",
      "Epoch 776/1000\n",
      "181/181 - 1s - loss: 0.3108 - accuracy: 0.8739 - val_loss: 0.3254 - val_accuracy: 0.8789 - 913ms/epoch - 5ms/step\n",
      "Epoch 777/1000\n",
      "181/181 - 1s - loss: 0.3094 - accuracy: 0.8748 - val_loss: 0.3349 - val_accuracy: 0.8742 - 890ms/epoch - 5ms/step\n",
      "Epoch 778/1000\n",
      "181/181 - 1s - loss: 0.3081 - accuracy: 0.8755 - val_loss: 0.3285 - val_accuracy: 0.8804 - 874ms/epoch - 5ms/step\n",
      "Epoch 779/1000\n",
      "181/181 - 1s - loss: 0.3108 - accuracy: 0.8757 - val_loss: 0.3269 - val_accuracy: 0.8882 - 879ms/epoch - 5ms/step\n",
      "Epoch 780/1000\n",
      "181/181 - 1s - loss: 0.3120 - accuracy: 0.8717 - val_loss: 0.3292 - val_accuracy: 0.8882 - 860ms/epoch - 5ms/step\n",
      "Epoch 781/1000\n",
      "181/181 - 1s - loss: 0.3088 - accuracy: 0.8738 - val_loss: 0.3341 - val_accuracy: 0.8758 - 862ms/epoch - 5ms/step\n",
      "Epoch 782/1000\n",
      "181/181 - 1s - loss: 0.3080 - accuracy: 0.8764 - val_loss: 0.3326 - val_accuracy: 0.8758 - 860ms/epoch - 5ms/step\n",
      "Epoch 783/1000\n",
      "181/181 - 1s - loss: 0.3096 - accuracy: 0.8719 - val_loss: 0.3277 - val_accuracy: 0.8820 - 862ms/epoch - 5ms/step\n",
      "Epoch 784/1000\n",
      "181/181 - 1s - loss: 0.3096 - accuracy: 0.8727 - val_loss: 0.3326 - val_accuracy: 0.8742 - 863ms/epoch - 5ms/step\n",
      "Epoch 785/1000\n",
      "181/181 - 1s - loss: 0.3069 - accuracy: 0.8760 - val_loss: 0.3291 - val_accuracy: 0.8727 - 862ms/epoch - 5ms/step\n",
      "Epoch 786/1000\n",
      "181/181 - 1s - loss: 0.3115 - accuracy: 0.8769 - val_loss: 0.3373 - val_accuracy: 0.8804 - 858ms/epoch - 5ms/step\n",
      "Epoch 787/1000\n",
      "181/181 - 1s - loss: 0.3125 - accuracy: 0.8733 - val_loss: 0.3277 - val_accuracy: 0.8758 - 854ms/epoch - 5ms/step\n",
      "Epoch 788/1000\n",
      "181/181 - 1s - loss: 0.3123 - accuracy: 0.8736 - val_loss: 0.3375 - val_accuracy: 0.8789 - 851ms/epoch - 5ms/step\n",
      "Epoch 789/1000\n",
      "181/181 - 1s - loss: 0.3107 - accuracy: 0.8719 - val_loss: 0.3239 - val_accuracy: 0.8835 - 862ms/epoch - 5ms/step\n",
      "Epoch 790/1000\n",
      "181/181 - 1s - loss: 0.3092 - accuracy: 0.8752 - val_loss: 0.3293 - val_accuracy: 0.8742 - 894ms/epoch - 5ms/step\n",
      "Epoch 791/1000\n",
      "181/181 - 1s - loss: 0.3086 - accuracy: 0.8688 - val_loss: 0.3306 - val_accuracy: 0.8804 - 851ms/epoch - 5ms/step\n",
      "Epoch 792/1000\n",
      "181/181 - 1s - loss: 0.3104 - accuracy: 0.8743 - val_loss: 0.3277 - val_accuracy: 0.8789 - 905ms/epoch - 5ms/step\n",
      "Epoch 793/1000\n",
      "181/181 - 1s - loss: 0.3078 - accuracy: 0.8764 - val_loss: 0.3250 - val_accuracy: 0.8758 - 908ms/epoch - 5ms/step\n",
      "Epoch 794/1000\n",
      "181/181 - 1s - loss: 0.3066 - accuracy: 0.8722 - val_loss: 0.3315 - val_accuracy: 0.8804 - 887ms/epoch - 5ms/step\n",
      "Epoch 795/1000\n",
      "181/181 - 1s - loss: 0.3095 - accuracy: 0.8734 - val_loss: 0.3276 - val_accuracy: 0.8804 - 976ms/epoch - 5ms/step\n",
      "Epoch 796/1000\n",
      "181/181 - 1s - loss: 0.3083 - accuracy: 0.8727 - val_loss: 0.3295 - val_accuracy: 0.8773 - 933ms/epoch - 5ms/step\n",
      "Epoch 797/1000\n",
      "181/181 - 1s - loss: 0.3108 - accuracy: 0.8746 - val_loss: 0.3284 - val_accuracy: 0.8789 - 967ms/epoch - 5ms/step\n",
      "Epoch 798/1000\n",
      "181/181 - 1s - loss: 0.3080 - accuracy: 0.8736 - val_loss: 0.3353 - val_accuracy: 0.8680 - 1s/epoch - 6ms/step\n",
      "Epoch 799/1000\n",
      "181/181 - 1s - loss: 0.3080 - accuracy: 0.8757 - val_loss: 0.3323 - val_accuracy: 0.8835 - 998ms/epoch - 6ms/step\n",
      "Epoch 800/1000\n",
      "181/181 - 1s - loss: 0.3130 - accuracy: 0.8724 - val_loss: 0.3304 - val_accuracy: 0.8820 - 1s/epoch - 6ms/step\n",
      "Epoch 801/1000\n",
      "181/181 - 1s - loss: 0.3093 - accuracy: 0.8733 - val_loss: 0.3352 - val_accuracy: 0.8727 - 974ms/epoch - 5ms/step\n",
      "Epoch 802/1000\n",
      "181/181 - 1s - loss: 0.3107 - accuracy: 0.8764 - val_loss: 0.3534 - val_accuracy: 0.8851 - 997ms/epoch - 6ms/step\n",
      "Epoch 803/1000\n",
      "181/181 - 1s - loss: 0.3113 - accuracy: 0.8750 - val_loss: 0.3313 - val_accuracy: 0.8835 - 955ms/epoch - 5ms/step\n",
      "Epoch 804/1000\n",
      "181/181 - 1s - loss: 0.3103 - accuracy: 0.8722 - val_loss: 0.3279 - val_accuracy: 0.8835 - 1s/epoch - 6ms/step\n",
      "Epoch 805/1000\n",
      "181/181 - 1s - loss: 0.3132 - accuracy: 0.8733 - val_loss: 0.3315 - val_accuracy: 0.8789 - 966ms/epoch - 5ms/step\n",
      "Epoch 806/1000\n",
      "181/181 - 1s - loss: 0.3089 - accuracy: 0.8769 - val_loss: 0.3298 - val_accuracy: 0.8804 - 881ms/epoch - 5ms/step\n",
      "Epoch 807/1000\n",
      "181/181 - 1s - loss: 0.3094 - accuracy: 0.8741 - val_loss: 0.3358 - val_accuracy: 0.8773 - 886ms/epoch - 5ms/step\n",
      "Epoch 808/1000\n",
      "181/181 - 1s - loss: 0.3099 - accuracy: 0.8755 - val_loss: 0.3349 - val_accuracy: 0.8804 - 844ms/epoch - 5ms/step\n",
      "Epoch 809/1000\n",
      "181/181 - 1s - loss: 0.3087 - accuracy: 0.8762 - val_loss: 0.3269 - val_accuracy: 0.8820 - 845ms/epoch - 5ms/step\n",
      "Epoch 810/1000\n",
      "181/181 - 1s - loss: 0.3117 - accuracy: 0.8750 - val_loss: 0.3347 - val_accuracy: 0.8696 - 864ms/epoch - 5ms/step\n",
      "Epoch 811/1000\n",
      "181/181 - 1s - loss: 0.3089 - accuracy: 0.8776 - val_loss: 0.3247 - val_accuracy: 0.8804 - 847ms/epoch - 5ms/step\n",
      "Epoch 812/1000\n",
      "181/181 - 1s - loss: 0.3084 - accuracy: 0.8753 - val_loss: 0.3415 - val_accuracy: 0.8882 - 876ms/epoch - 5ms/step\n",
      "Epoch 813/1000\n",
      "181/181 - 1s - loss: 0.3090 - accuracy: 0.8753 - val_loss: 0.3278 - val_accuracy: 0.8820 - 865ms/epoch - 5ms/step\n",
      "Epoch 814/1000\n",
      "181/181 - 1s - loss: 0.3097 - accuracy: 0.8748 - val_loss: 0.3274 - val_accuracy: 0.8789 - 874ms/epoch - 5ms/step\n",
      "Epoch 815/1000\n",
      "181/181 - 1s - loss: 0.3074 - accuracy: 0.8746 - val_loss: 0.3237 - val_accuracy: 0.8789 - 895ms/epoch - 5ms/step\n",
      "Epoch 816/1000\n",
      "181/181 - 1s - loss: 0.3081 - accuracy: 0.8752 - val_loss: 0.3265 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 817/1000\n",
      "181/181 - 2s - loss: 0.3084 - accuracy: 0.8757 - val_loss: 0.3296 - val_accuracy: 0.8851 - 2s/epoch - 11ms/step\n",
      "Epoch 818/1000\n",
      "181/181 - 1s - loss: 0.3090 - accuracy: 0.8738 - val_loss: 0.3296 - val_accuracy: 0.8758 - 1s/epoch - 8ms/step\n",
      "Epoch 819/1000\n",
      "181/181 - 1s - loss: 0.3090 - accuracy: 0.8733 - val_loss: 0.3446 - val_accuracy: 0.8913 - 1s/epoch - 7ms/step\n",
      "Epoch 820/1000\n",
      "181/181 - 1s - loss: 0.3106 - accuracy: 0.8757 - val_loss: 0.3269 - val_accuracy: 0.8851 - 968ms/epoch - 5ms/step\n",
      "Epoch 821/1000\n",
      "181/181 - 1s - loss: 0.3078 - accuracy: 0.8777 - val_loss: 0.3256 - val_accuracy: 0.8773 - 1s/epoch - 6ms/step\n",
      "Epoch 822/1000\n",
      "181/181 - 1s - loss: 0.3109 - accuracy: 0.8769 - val_loss: 0.3436 - val_accuracy: 0.8773 - 961ms/epoch - 5ms/step\n",
      "Epoch 823/1000\n",
      "181/181 - 1s - loss: 0.3079 - accuracy: 0.8743 - val_loss: 0.3254 - val_accuracy: 0.8804 - 914ms/epoch - 5ms/step\n",
      "Epoch 824/1000\n",
      "181/181 - 1s - loss: 0.3088 - accuracy: 0.8755 - val_loss: 0.3275 - val_accuracy: 0.8773 - 857ms/epoch - 5ms/step\n",
      "Epoch 825/1000\n",
      "181/181 - 1s - loss: 0.3110 - accuracy: 0.8739 - val_loss: 0.3385 - val_accuracy: 0.8851 - 892ms/epoch - 5ms/step\n",
      "Epoch 826/1000\n",
      "181/181 - 1s - loss: 0.3115 - accuracy: 0.8734 - val_loss: 0.3338 - val_accuracy: 0.8789 - 1s/epoch - 7ms/step\n",
      "Epoch 827/1000\n",
      "181/181 - 1s - loss: 0.3095 - accuracy: 0.8753 - val_loss: 0.3366 - val_accuracy: 0.8742 - 896ms/epoch - 5ms/step\n",
      "Epoch 828/1000\n",
      "181/181 - 1s - loss: 0.3085 - accuracy: 0.8741 - val_loss: 0.3256 - val_accuracy: 0.8835 - 972ms/epoch - 5ms/step\n",
      "Epoch 829/1000\n",
      "181/181 - 1s - loss: 0.3085 - accuracy: 0.8734 - val_loss: 0.3240 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 830/1000\n",
      "181/181 - 1s - loss: 0.3098 - accuracy: 0.8731 - val_loss: 0.3323 - val_accuracy: 0.8820 - 1s/epoch - 6ms/step\n",
      "Epoch 831/1000\n",
      "181/181 - 1s - loss: 0.3087 - accuracy: 0.8739 - val_loss: 0.3340 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 832/1000\n",
      "181/181 - 1s - loss: 0.3084 - accuracy: 0.8767 - val_loss: 0.3302 - val_accuracy: 0.8851 - 1s/epoch - 8ms/step\n",
      "Epoch 833/1000\n",
      "181/181 - 2s - loss: 0.3073 - accuracy: 0.8748 - val_loss: 0.3242 - val_accuracy: 0.8804 - 2s/epoch - 10ms/step\n",
      "Epoch 834/1000\n",
      "181/181 - 2s - loss: 0.3078 - accuracy: 0.8753 - val_loss: 0.3331 - val_accuracy: 0.8773 - 2s/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835/1000\n",
      "181/181 - 2s - loss: 0.3078 - accuracy: 0.8752 - val_loss: 0.3317 - val_accuracy: 0.8851 - 2s/epoch - 9ms/step\n",
      "Epoch 836/1000\n",
      "181/181 - 2s - loss: 0.3089 - accuracy: 0.8757 - val_loss: 0.3274 - val_accuracy: 0.8835 - 2s/epoch - 13ms/step\n",
      "Epoch 837/1000\n",
      "181/181 - 3s - loss: 0.3083 - accuracy: 0.8746 - val_loss: 0.3228 - val_accuracy: 0.8773 - 3s/epoch - 14ms/step\n",
      "Epoch 838/1000\n",
      "181/181 - 2s - loss: 0.3090 - accuracy: 0.8769 - val_loss: 0.3293 - val_accuracy: 0.8773 - 2s/epoch - 10ms/step\n",
      "Epoch 839/1000\n",
      "181/181 - 2s - loss: 0.3067 - accuracy: 0.8753 - val_loss: 0.3289 - val_accuracy: 0.8758 - 2s/epoch - 10ms/step\n",
      "Epoch 840/1000\n",
      "181/181 - 2s - loss: 0.3085 - accuracy: 0.8758 - val_loss: 0.3312 - val_accuracy: 0.8820 - 2s/epoch - 12ms/step\n",
      "Epoch 841/1000\n",
      "181/181 - 2s - loss: 0.3090 - accuracy: 0.8734 - val_loss: 0.3368 - val_accuracy: 0.8742 - 2s/epoch - 10ms/step\n",
      "Epoch 842/1000\n",
      "181/181 - 2s - loss: 0.3082 - accuracy: 0.8746 - val_loss: 0.3461 - val_accuracy: 0.8804 - 2s/epoch - 9ms/step\n",
      "Epoch 843/1000\n",
      "181/181 - 1s - loss: 0.3094 - accuracy: 0.8748 - val_loss: 0.3245 - val_accuracy: 0.8711 - 1s/epoch - 7ms/step\n",
      "Epoch 844/1000\n",
      "181/181 - 1s - loss: 0.3083 - accuracy: 0.8760 - val_loss: 0.3300 - val_accuracy: 0.8727 - 1s/epoch - 8ms/step\n",
      "Epoch 845/1000\n",
      "181/181 - 1s - loss: 0.3083 - accuracy: 0.8746 - val_loss: 0.3262 - val_accuracy: 0.8789 - 1s/epoch - 7ms/step\n",
      "Epoch 846/1000\n",
      "181/181 - 2s - loss: 0.3119 - accuracy: 0.8750 - val_loss: 0.3248 - val_accuracy: 0.8758 - 2s/epoch - 11ms/step\n",
      "Epoch 847/1000\n",
      "181/181 - 2s - loss: 0.3069 - accuracy: 0.8762 - val_loss: 0.3268 - val_accuracy: 0.8758 - 2s/epoch - 9ms/step\n",
      "Epoch 848/1000\n",
      "181/181 - 2s - loss: 0.3084 - accuracy: 0.8758 - val_loss: 0.3266 - val_accuracy: 0.8835 - 2s/epoch - 10ms/step\n",
      "Epoch 849/1000\n",
      "181/181 - 3s - loss: 0.3078 - accuracy: 0.8802 - val_loss: 0.3465 - val_accuracy: 0.8820 - 3s/epoch - 15ms/step\n",
      "Epoch 850/1000\n",
      "181/181 - 2s - loss: 0.3080 - accuracy: 0.8752 - val_loss: 0.3359 - val_accuracy: 0.8742 - 2s/epoch - 12ms/step\n",
      "Epoch 851/1000\n",
      "181/181 - 2s - loss: 0.3082 - accuracy: 0.8788 - val_loss: 0.3315 - val_accuracy: 0.8680 - 2s/epoch - 9ms/step\n",
      "Epoch 852/1000\n",
      "181/181 - 1s - loss: 0.3089 - accuracy: 0.8746 - val_loss: 0.3306 - val_accuracy: 0.8820 - 1s/epoch - 8ms/step\n",
      "Epoch 853/1000\n",
      "181/181 - 2s - loss: 0.3110 - accuracy: 0.8767 - val_loss: 0.3460 - val_accuracy: 0.8851 - 2s/epoch - 8ms/step\n",
      "Epoch 854/1000\n",
      "181/181 - 1s - loss: 0.3110 - accuracy: 0.8745 - val_loss: 0.3318 - val_accuracy: 0.8851 - 1s/epoch - 7ms/step\n",
      "Epoch 855/1000\n",
      "181/181 - 1s - loss: 0.3082 - accuracy: 0.8758 - val_loss: 0.3317 - val_accuracy: 0.8804 - 1s/epoch - 7ms/step\n",
      "Epoch 856/1000\n",
      "181/181 - 1s - loss: 0.3102 - accuracy: 0.8758 - val_loss: 0.3312 - val_accuracy: 0.8820 - 1s/epoch - 7ms/step\n",
      "Epoch 857/1000\n",
      "181/181 - 1s - loss: 0.3071 - accuracy: 0.8758 - val_loss: 0.3280 - val_accuracy: 0.8804 - 1s/epoch - 7ms/step\n",
      "Epoch 858/1000\n",
      "181/181 - 1s - loss: 0.3098 - accuracy: 0.8746 - val_loss: 0.3362 - val_accuracy: 0.8804 - 1s/epoch - 7ms/step\n",
      "Epoch 859/1000\n",
      "181/181 - 1s - loss: 0.3070 - accuracy: 0.8758 - val_loss: 0.3286 - val_accuracy: 0.8742 - 1s/epoch - 7ms/step\n",
      "Epoch 860/1000\n",
      "181/181 - 1s - loss: 0.3079 - accuracy: 0.8729 - val_loss: 0.3506 - val_accuracy: 0.8571 - 1s/epoch - 8ms/step\n",
      "Epoch 861/1000\n",
      "181/181 - 1s - loss: 0.3093 - accuracy: 0.8752 - val_loss: 0.3417 - val_accuracy: 0.8804 - 1s/epoch - 7ms/step\n",
      "Epoch 862/1000\n",
      "181/181 - 1s - loss: 0.3112 - accuracy: 0.8734 - val_loss: 0.3266 - val_accuracy: 0.8804 - 1s/epoch - 7ms/step\n",
      "Epoch 863/1000\n",
      "181/181 - 1s - loss: 0.3089 - accuracy: 0.8743 - val_loss: 0.3366 - val_accuracy: 0.8913 - 1s/epoch - 7ms/step\n",
      "Epoch 864/1000\n",
      "181/181 - 1s - loss: 0.3083 - accuracy: 0.8788 - val_loss: 0.3240 - val_accuracy: 0.8804 - 1s/epoch - 7ms/step\n",
      "Epoch 865/1000\n",
      "181/181 - 1s - loss: 0.3086 - accuracy: 0.8765 - val_loss: 0.3265 - val_accuracy: 0.8835 - 1s/epoch - 7ms/step\n",
      "Epoch 866/1000\n",
      "181/181 - 1s - loss: 0.3082 - accuracy: 0.8755 - val_loss: 0.3323 - val_accuracy: 0.8804 - 1s/epoch - 7ms/step\n",
      "Epoch 867/1000\n",
      "181/181 - 1s - loss: 0.3106 - accuracy: 0.8743 - val_loss: 0.3273 - val_accuracy: 0.8804 - 1s/epoch - 7ms/step\n",
      "Epoch 868/1000\n",
      "181/181 - 1s - loss: 0.3095 - accuracy: 0.8779 - val_loss: 0.3278 - val_accuracy: 0.8804 - 1s/epoch - 7ms/step\n",
      "Epoch 869/1000\n",
      "181/181 - 1s - loss: 0.3075 - accuracy: 0.8764 - val_loss: 0.3386 - val_accuracy: 0.8711 - 1s/epoch - 7ms/step\n",
      "Epoch 870/1000\n",
      "181/181 - 1s - loss: 0.3103 - accuracy: 0.8726 - val_loss: 0.3301 - val_accuracy: 0.8727 - 1s/epoch - 7ms/step\n",
      "Epoch 871/1000\n",
      "181/181 - 1s - loss: 0.3077 - accuracy: 0.8755 - val_loss: 0.3260 - val_accuracy: 0.8727 - 1s/epoch - 7ms/step\n",
      "Epoch 872/1000\n",
      "181/181 - 1s - loss: 0.3101 - accuracy: 0.8745 - val_loss: 0.3277 - val_accuracy: 0.8758 - 1s/epoch - 7ms/step\n",
      "Epoch 873/1000\n",
      "181/181 - 1s - loss: 0.3071 - accuracy: 0.8758 - val_loss: 0.3248 - val_accuracy: 0.8820 - 1s/epoch - 7ms/step\n",
      "Epoch 874/1000\n",
      "181/181 - 1s - loss: 0.3096 - accuracy: 0.8705 - val_loss: 0.3318 - val_accuracy: 0.8789 - 1s/epoch - 7ms/step\n",
      "Epoch 875/1000\n",
      "181/181 - 1s - loss: 0.3062 - accuracy: 0.8748 - val_loss: 0.3221 - val_accuracy: 0.8789 - 1s/epoch - 7ms/step\n",
      "Epoch 876/1000\n",
      "181/181 - 1s - loss: 0.3067 - accuracy: 0.8753 - val_loss: 0.3238 - val_accuracy: 0.8727 - 1s/epoch - 7ms/step\n",
      "Epoch 877/1000\n",
      "181/181 - 1s - loss: 0.3099 - accuracy: 0.8757 - val_loss: 0.3285 - val_accuracy: 0.8773 - 1s/epoch - 7ms/step\n",
      "Epoch 878/1000\n",
      "181/181 - 1s - loss: 0.3083 - accuracy: 0.8733 - val_loss: 0.3425 - val_accuracy: 0.8727 - 1s/epoch - 7ms/step\n",
      "Epoch 879/1000\n",
      "181/181 - 1s - loss: 0.3108 - accuracy: 0.8724 - val_loss: 0.3554 - val_accuracy: 0.8773 - 1s/epoch - 7ms/step\n",
      "Epoch 880/1000\n",
      "181/181 - 1s - loss: 0.3072 - accuracy: 0.8764 - val_loss: 0.3292 - val_accuracy: 0.8851 - 1s/epoch - 8ms/step\n",
      "Epoch 881/1000\n",
      "181/181 - 1s - loss: 0.3071 - accuracy: 0.8758 - val_loss: 0.3233 - val_accuracy: 0.8696 - 1s/epoch - 7ms/step\n",
      "Epoch 882/1000\n",
      "181/181 - 1s - loss: 0.3102 - accuracy: 0.8738 - val_loss: 0.3273 - val_accuracy: 0.8804 - 1s/epoch - 7ms/step\n",
      "Epoch 883/1000\n",
      "181/181 - 1s - loss: 0.3103 - accuracy: 0.8724 - val_loss: 0.3251 - val_accuracy: 0.8835 - 1s/epoch - 7ms/step\n",
      "Epoch 884/1000\n",
      "181/181 - 1s - loss: 0.3082 - accuracy: 0.8748 - val_loss: 0.3278 - val_accuracy: 0.8742 - 1s/epoch - 7ms/step\n",
      "Epoch 885/1000\n",
      "181/181 - 1s - loss: 0.3079 - accuracy: 0.8739 - val_loss: 0.3308 - val_accuracy: 0.8665 - 1s/epoch - 7ms/step\n",
      "Epoch 886/1000\n",
      "181/181 - 1s - loss: 0.3102 - accuracy: 0.8758 - val_loss: 0.3257 - val_accuracy: 0.8851 - 1s/epoch - 7ms/step\n",
      "Epoch 887/1000\n",
      "181/181 - 1s - loss: 0.3076 - accuracy: 0.8746 - val_loss: 0.3310 - val_accuracy: 0.8820 - 1s/epoch - 7ms/step\n",
      "Epoch 888/1000\n",
      "181/181 - 1s - loss: 0.3112 - accuracy: 0.8764 - val_loss: 0.3313 - val_accuracy: 0.8711 - 1s/epoch - 7ms/step\n",
      "Epoch 889/1000\n",
      "181/181 - 1s - loss: 0.3081 - accuracy: 0.8734 - val_loss: 0.3379 - val_accuracy: 0.8820 - 1s/epoch - 8ms/step\n",
      "Epoch 890/1000\n",
      "181/181 - 1s - loss: 0.3112 - accuracy: 0.8753 - val_loss: 0.3249 - val_accuracy: 0.8773 - 1s/epoch - 8ms/step\n",
      "Epoch 891/1000\n",
      "181/181 - 1s - loss: 0.3074 - accuracy: 0.8726 - val_loss: 0.3238 - val_accuracy: 0.8820 - 1s/epoch - 8ms/step\n",
      "Epoch 892/1000\n",
      "181/181 - 1s - loss: 0.3087 - accuracy: 0.8760 - val_loss: 0.3364 - val_accuracy: 0.8742 - 1s/epoch - 8ms/step\n",
      "Epoch 893/1000\n",
      "181/181 - 1s - loss: 0.3093 - accuracy: 0.8741 - val_loss: 0.3422 - val_accuracy: 0.8804 - 1s/epoch - 8ms/step\n",
      "Epoch 894/1000\n",
      "181/181 - 2s - loss: 0.3091 - accuracy: 0.8783 - val_loss: 0.3274 - val_accuracy: 0.8742 - 2s/epoch - 8ms/step\n",
      "Epoch 895/1000\n",
      "181/181 - 2s - loss: 0.3079 - accuracy: 0.8774 - val_loss: 0.3282 - val_accuracy: 0.8835 - 2s/epoch - 9ms/step\n",
      "Epoch 896/1000\n",
      "181/181 - 2s - loss: 0.3084 - accuracy: 0.8743 - val_loss: 0.3443 - val_accuracy: 0.8727 - 2s/epoch - 9ms/step\n",
      "Epoch 897/1000\n",
      "181/181 - 1s - loss: 0.3080 - accuracy: 0.8755 - val_loss: 0.3293 - val_accuracy: 0.8727 - 1s/epoch - 8ms/step\n",
      "Epoch 898/1000\n",
      "181/181 - 1s - loss: 0.3066 - accuracy: 0.8755 - val_loss: 0.3241 - val_accuracy: 0.8789 - 1s/epoch - 7ms/step\n",
      "Epoch 899/1000\n",
      "181/181 - 1s - loss: 0.3116 - accuracy: 0.8739 - val_loss: 0.3263 - val_accuracy: 0.8789 - 1s/epoch - 7ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1000\n",
      "181/181 - 1s - loss: 0.3078 - accuracy: 0.8745 - val_loss: 0.3281 - val_accuracy: 0.8804 - 1s/epoch - 8ms/step\n",
      "Epoch 901/1000\n",
      "181/181 - 1s - loss: 0.3069 - accuracy: 0.8748 - val_loss: 0.3466 - val_accuracy: 0.8680 - 1s/epoch - 6ms/step\n",
      "Epoch 902/1000\n",
      "181/181 - 1s - loss: 0.3068 - accuracy: 0.8764 - val_loss: 0.3313 - val_accuracy: 0.8758 - 1s/epoch - 6ms/step\n",
      "Epoch 903/1000\n",
      "181/181 - 1s - loss: 0.3071 - accuracy: 0.8734 - val_loss: 0.3327 - val_accuracy: 0.8851 - 1s/epoch - 6ms/step\n",
      "Epoch 904/1000\n",
      "181/181 - 1s - loss: 0.3080 - accuracy: 0.8748 - val_loss: 0.3380 - val_accuracy: 0.8742 - 1s/epoch - 7ms/step\n",
      "Epoch 905/1000\n",
      "181/181 - 1s - loss: 0.3087 - accuracy: 0.8734 - val_loss: 0.3301 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 906/1000\n",
      "181/181 - 1s - loss: 0.3070 - accuracy: 0.8746 - val_loss: 0.3294 - val_accuracy: 0.8789 - 995ms/epoch - 5ms/step\n",
      "Epoch 907/1000\n",
      "181/181 - 1s - loss: 0.3056 - accuracy: 0.8790 - val_loss: 0.3424 - val_accuracy: 0.8727 - 1s/epoch - 6ms/step\n",
      "Epoch 908/1000\n",
      "181/181 - 1s - loss: 0.3071 - accuracy: 0.8734 - val_loss: 0.3328 - val_accuracy: 0.8882 - 951ms/epoch - 5ms/step\n",
      "Epoch 909/1000\n",
      "181/181 - 1s - loss: 0.3082 - accuracy: 0.8753 - val_loss: 0.3243 - val_accuracy: 0.8898 - 1s/epoch - 6ms/step\n",
      "Epoch 910/1000\n",
      "181/181 - 1s - loss: 0.3098 - accuracy: 0.8696 - val_loss: 0.3307 - val_accuracy: 0.8758 - 1s/epoch - 6ms/step\n",
      "Epoch 911/1000\n",
      "181/181 - 1s - loss: 0.3073 - accuracy: 0.8765 - val_loss: 0.3543 - val_accuracy: 0.8711 - 1s/epoch - 6ms/step\n",
      "Epoch 912/1000\n",
      "181/181 - 1s - loss: 0.3084 - accuracy: 0.8710 - val_loss: 0.3292 - val_accuracy: 0.8820 - 958ms/epoch - 5ms/step\n",
      "Epoch 913/1000\n",
      "181/181 - 1s - loss: 0.3078 - accuracy: 0.8726 - val_loss: 0.3317 - val_accuracy: 0.8866 - 898ms/epoch - 5ms/step\n",
      "Epoch 914/1000\n",
      "181/181 - 1s - loss: 0.3081 - accuracy: 0.8764 - val_loss: 0.3288 - val_accuracy: 0.8758 - 964ms/epoch - 5ms/step\n",
      "Epoch 915/1000\n",
      "181/181 - 1s - loss: 0.3072 - accuracy: 0.8758 - val_loss: 0.3344 - val_accuracy: 0.8696 - 916ms/epoch - 5ms/step\n",
      "Epoch 916/1000\n",
      "181/181 - 1s - loss: 0.3063 - accuracy: 0.8762 - val_loss: 0.3296 - val_accuracy: 0.8804 - 903ms/epoch - 5ms/step\n",
      "Epoch 917/1000\n",
      "181/181 - 1s - loss: 0.3087 - accuracy: 0.8769 - val_loss: 0.3292 - val_accuracy: 0.8851 - 892ms/epoch - 5ms/step\n",
      "Epoch 918/1000\n",
      "181/181 - 1s - loss: 0.3075 - accuracy: 0.8748 - val_loss: 0.3224 - val_accuracy: 0.8727 - 898ms/epoch - 5ms/step\n",
      "Epoch 919/1000\n",
      "181/181 - 1s - loss: 0.3083 - accuracy: 0.8750 - val_loss: 0.3250 - val_accuracy: 0.8742 - 903ms/epoch - 5ms/step\n",
      "Epoch 920/1000\n",
      "181/181 - 1s - loss: 0.3064 - accuracy: 0.8750 - val_loss: 0.3363 - val_accuracy: 0.8804 - 897ms/epoch - 5ms/step\n",
      "Epoch 921/1000\n",
      "181/181 - 1s - loss: 0.3083 - accuracy: 0.8743 - val_loss: 0.3279 - val_accuracy: 0.8804 - 889ms/epoch - 5ms/step\n",
      "Epoch 922/1000\n",
      "181/181 - 1s - loss: 0.3091 - accuracy: 0.8765 - val_loss: 0.3272 - val_accuracy: 0.8820 - 869ms/epoch - 5ms/step\n",
      "Epoch 923/1000\n",
      "181/181 - 1s - loss: 0.3062 - accuracy: 0.8757 - val_loss: 0.3277 - val_accuracy: 0.8727 - 866ms/epoch - 5ms/step\n",
      "Epoch 924/1000\n",
      "181/181 - 1s - loss: 0.3084 - accuracy: 0.8746 - val_loss: 0.3304 - val_accuracy: 0.8773 - 866ms/epoch - 5ms/step\n",
      "Epoch 925/1000\n",
      "181/181 - 1s - loss: 0.3075 - accuracy: 0.8743 - val_loss: 0.3345 - val_accuracy: 0.8866 - 902ms/epoch - 5ms/step\n",
      "Epoch 926/1000\n",
      "181/181 - 1s - loss: 0.3093 - accuracy: 0.8755 - val_loss: 0.3274 - val_accuracy: 0.8820 - 880ms/epoch - 5ms/step\n",
      "Epoch 927/1000\n",
      "181/181 - 1s - loss: 0.3072 - accuracy: 0.8758 - val_loss: 0.3287 - val_accuracy: 0.8835 - 867ms/epoch - 5ms/step\n",
      "Epoch 928/1000\n",
      "181/181 - 1s - loss: 0.3079 - accuracy: 0.8748 - val_loss: 0.3310 - val_accuracy: 0.8804 - 864ms/epoch - 5ms/step\n",
      "Epoch 929/1000\n",
      "181/181 - 1s - loss: 0.3075 - accuracy: 0.8752 - val_loss: 0.3338 - val_accuracy: 0.8742 - 869ms/epoch - 5ms/step\n",
      "Epoch 930/1000\n",
      "181/181 - 1s - loss: 0.3070 - accuracy: 0.8752 - val_loss: 0.3306 - val_accuracy: 0.8804 - 866ms/epoch - 5ms/step\n",
      "Epoch 931/1000\n",
      "181/181 - 1s - loss: 0.3073 - accuracy: 0.8757 - val_loss: 0.3463 - val_accuracy: 0.8804 - 866ms/epoch - 5ms/step\n",
      "Epoch 932/1000\n",
      "181/181 - 1s - loss: 0.3087 - accuracy: 0.8715 - val_loss: 0.3368 - val_accuracy: 0.8696 - 868ms/epoch - 5ms/step\n",
      "Epoch 933/1000\n",
      "181/181 - 1s - loss: 0.3060 - accuracy: 0.8764 - val_loss: 0.3361 - val_accuracy: 0.8665 - 864ms/epoch - 5ms/step\n",
      "Epoch 934/1000\n",
      "181/181 - 1s - loss: 0.3080 - accuracy: 0.8743 - val_loss: 0.3338 - val_accuracy: 0.8835 - 868ms/epoch - 5ms/step\n",
      "Epoch 935/1000\n",
      "181/181 - 1s - loss: 0.3064 - accuracy: 0.8738 - val_loss: 0.3288 - val_accuracy: 0.8773 - 864ms/epoch - 5ms/step\n",
      "Epoch 936/1000\n",
      "181/181 - 1s - loss: 0.3065 - accuracy: 0.8764 - val_loss: 0.3377 - val_accuracy: 0.8820 - 865ms/epoch - 5ms/step\n",
      "Epoch 937/1000\n",
      "181/181 - 1s - loss: 0.3077 - accuracy: 0.8727 - val_loss: 0.3377 - val_accuracy: 0.8758 - 863ms/epoch - 5ms/step\n",
      "Epoch 938/1000\n",
      "181/181 - 1s - loss: 0.3082 - accuracy: 0.8743 - val_loss: 0.3264 - val_accuracy: 0.8773 - 891ms/epoch - 5ms/step\n",
      "Epoch 939/1000\n",
      "181/181 - 1s - loss: 0.3066 - accuracy: 0.8758 - val_loss: 0.3279 - val_accuracy: 0.8758 - 932ms/epoch - 5ms/step\n",
      "Epoch 940/1000\n",
      "181/181 - 1s - loss: 0.3065 - accuracy: 0.8764 - val_loss: 0.3273 - val_accuracy: 0.8773 - 933ms/epoch - 5ms/step\n",
      "Epoch 941/1000\n",
      "181/181 - 1s - loss: 0.3101 - accuracy: 0.8739 - val_loss: 0.3243 - val_accuracy: 0.8680 - 911ms/epoch - 5ms/step\n",
      "Epoch 942/1000\n",
      "181/181 - 1s - loss: 0.3092 - accuracy: 0.8760 - val_loss: 0.3305 - val_accuracy: 0.8882 - 912ms/epoch - 5ms/step\n",
      "Epoch 943/1000\n",
      "181/181 - 1s - loss: 0.3085 - accuracy: 0.8791 - val_loss: 0.3408 - val_accuracy: 0.8711 - 887ms/epoch - 5ms/step\n",
      "Epoch 944/1000\n",
      "181/181 - 1s - loss: 0.3074 - accuracy: 0.8745 - val_loss: 0.3354 - val_accuracy: 0.8773 - 894ms/epoch - 5ms/step\n",
      "Epoch 945/1000\n",
      "181/181 - 1s - loss: 0.3061 - accuracy: 0.8755 - val_loss: 0.3316 - val_accuracy: 0.8789 - 924ms/epoch - 5ms/step\n",
      "Epoch 946/1000\n",
      "181/181 - 1s - loss: 0.3073 - accuracy: 0.8745 - val_loss: 0.3278 - val_accuracy: 0.8711 - 1s/epoch - 6ms/step\n",
      "Epoch 947/1000\n",
      "181/181 - 1s - loss: 0.3097 - accuracy: 0.8753 - val_loss: 0.3309 - val_accuracy: 0.8866 - 1s/epoch - 6ms/step\n",
      "Epoch 948/1000\n",
      "181/181 - 1s - loss: 0.3058 - accuracy: 0.8748 - val_loss: 0.3278 - val_accuracy: 0.8742 - 1s/epoch - 6ms/step\n",
      "Epoch 949/1000\n",
      "181/181 - 1s - loss: 0.3109 - accuracy: 0.8726 - val_loss: 0.3294 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 950/1000\n",
      "181/181 - 1s - loss: 0.3084 - accuracy: 0.8739 - val_loss: 0.3264 - val_accuracy: 0.8758 - 979ms/epoch - 5ms/step\n",
      "Epoch 951/1000\n",
      "181/181 - 1s - loss: 0.3078 - accuracy: 0.8757 - val_loss: 0.3375 - val_accuracy: 0.8758 - 1s/epoch - 7ms/step\n",
      "Epoch 952/1000\n",
      "181/181 - 1s - loss: 0.3089 - accuracy: 0.8746 - val_loss: 0.3465 - val_accuracy: 0.8696 - 1s/epoch - 6ms/step\n",
      "Epoch 953/1000\n",
      "181/181 - 1s - loss: 0.3067 - accuracy: 0.8746 - val_loss: 0.3263 - val_accuracy: 0.8742 - 1s/epoch - 7ms/step\n",
      "Epoch 954/1000\n",
      "181/181 - 1s - loss: 0.3083 - accuracy: 0.8715 - val_loss: 0.3393 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 955/1000\n",
      "181/181 - 1s - loss: 0.3082 - accuracy: 0.8753 - val_loss: 0.3396 - val_accuracy: 0.8696 - 943ms/epoch - 5ms/step\n",
      "Epoch 956/1000\n",
      "181/181 - 1s - loss: 0.3084 - accuracy: 0.8753 - val_loss: 0.3309 - val_accuracy: 0.8711 - 1s/epoch - 6ms/step\n",
      "Epoch 957/1000\n",
      "181/181 - 1s - loss: 0.3072 - accuracy: 0.8726 - val_loss: 0.3306 - val_accuracy: 0.8866 - 1000ms/epoch - 6ms/step\n",
      "Epoch 958/1000\n",
      "181/181 - 1s - loss: 0.3040 - accuracy: 0.8786 - val_loss: 0.3446 - val_accuracy: 0.8773 - 884ms/epoch - 5ms/step\n",
      "Epoch 959/1000\n",
      "181/181 - 1s - loss: 0.3067 - accuracy: 0.8762 - val_loss: 0.3312 - val_accuracy: 0.8820 - 932ms/epoch - 5ms/step\n",
      "Epoch 960/1000\n",
      "181/181 - 1s - loss: 0.3069 - accuracy: 0.8750 - val_loss: 0.3371 - val_accuracy: 0.8835 - 920ms/epoch - 5ms/step\n",
      "Epoch 961/1000\n",
      "181/181 - 1s - loss: 0.3082 - accuracy: 0.8757 - val_loss: 0.3420 - val_accuracy: 0.8851 - 914ms/epoch - 5ms/step\n",
      "Epoch 962/1000\n",
      "181/181 - 1s - loss: 0.3087 - accuracy: 0.8741 - val_loss: 0.3256 - val_accuracy: 0.8758 - 943ms/epoch - 5ms/step\n",
      "Epoch 963/1000\n",
      "181/181 - 1s - loss: 0.3063 - accuracy: 0.8772 - val_loss: 0.3422 - val_accuracy: 0.8711 - 952ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 964/1000\n",
      "181/181 - 1s - loss: 0.3096 - accuracy: 0.8748 - val_loss: 0.3276 - val_accuracy: 0.8742 - 937ms/epoch - 5ms/step\n",
      "Epoch 965/1000\n",
      "181/181 - 1s - loss: 0.3050 - accuracy: 0.8765 - val_loss: 0.3339 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 966/1000\n",
      "181/181 - 1s - loss: 0.3072 - accuracy: 0.8724 - val_loss: 0.3238 - val_accuracy: 0.8773 - 1s/epoch - 6ms/step\n",
      "Epoch 967/1000\n",
      "181/181 - 1s - loss: 0.3059 - accuracy: 0.8755 - val_loss: 0.3341 - val_accuracy: 0.8773 - 1s/epoch - 6ms/step\n",
      "Epoch 968/1000\n",
      "181/181 - 1s - loss: 0.3057 - accuracy: 0.8736 - val_loss: 0.3285 - val_accuracy: 0.8789 - 1s/epoch - 6ms/step\n",
      "Epoch 969/1000\n",
      "181/181 - 1s - loss: 0.3070 - accuracy: 0.8772 - val_loss: 0.3293 - val_accuracy: 0.8758 - 988ms/epoch - 5ms/step\n",
      "Epoch 970/1000\n",
      "181/181 - 1s - loss: 0.3097 - accuracy: 0.8755 - val_loss: 0.3410 - val_accuracy: 0.8680 - 867ms/epoch - 5ms/step\n",
      "Epoch 971/1000\n",
      "181/181 - 1s - loss: 0.3079 - accuracy: 0.8752 - val_loss: 0.3354 - val_accuracy: 0.8804 - 946ms/epoch - 5ms/step\n",
      "Epoch 972/1000\n",
      "181/181 - 1s - loss: 0.3068 - accuracy: 0.8755 - val_loss: 0.3351 - val_accuracy: 0.8773 - 1s/epoch - 8ms/step\n",
      "Epoch 973/1000\n",
      "181/181 - 2s - loss: 0.3068 - accuracy: 0.8731 - val_loss: 0.3320 - val_accuracy: 0.8820 - 2s/epoch - 9ms/step\n",
      "Epoch 974/1000\n",
      "181/181 - 2s - loss: 0.3073 - accuracy: 0.8771 - val_loss: 0.3309 - val_accuracy: 0.8773 - 2s/epoch - 12ms/step\n",
      "Epoch 975/1000\n",
      "181/181 - 2s - loss: 0.3065 - accuracy: 0.8748 - val_loss: 0.3307 - val_accuracy: 0.8711 - 2s/epoch - 11ms/step\n",
      "Epoch 976/1000\n",
      "181/181 - 1s - loss: 0.3083 - accuracy: 0.8739 - val_loss: 0.3238 - val_accuracy: 0.8804 - 1s/epoch - 6ms/step\n",
      "Epoch 977/1000\n",
      "181/181 - 1s - loss: 0.3072 - accuracy: 0.8784 - val_loss: 0.3316 - val_accuracy: 0.8773 - 1s/epoch - 6ms/step\n",
      "Epoch 978/1000\n",
      "181/181 - 1s - loss: 0.3065 - accuracy: 0.8774 - val_loss: 0.3514 - val_accuracy: 0.8758 - 910ms/epoch - 5ms/step\n",
      "Epoch 979/1000\n",
      "181/181 - 1s - loss: 0.3063 - accuracy: 0.8757 - val_loss: 0.3289 - val_accuracy: 0.8773 - 859ms/epoch - 5ms/step\n",
      "Epoch 980/1000\n",
      "181/181 - 1s - loss: 0.3063 - accuracy: 0.8757 - val_loss: 0.3475 - val_accuracy: 0.8634 - 843ms/epoch - 5ms/step\n",
      "Epoch 981/1000\n",
      "181/181 - 1s - loss: 0.3064 - accuracy: 0.8771 - val_loss: 0.3321 - val_accuracy: 0.8742 - 1000ms/epoch - 6ms/step\n",
      "Epoch 982/1000\n",
      "181/181 - 1s - loss: 0.3067 - accuracy: 0.8767 - val_loss: 0.3274 - val_accuracy: 0.8742 - 1s/epoch - 6ms/step\n",
      "Epoch 983/1000\n",
      "181/181 - 1s - loss: 0.3078 - accuracy: 0.8734 - val_loss: 0.3263 - val_accuracy: 0.8835 - 1000ms/epoch - 6ms/step\n",
      "Epoch 984/1000\n",
      "181/181 - 1s - loss: 0.3067 - accuracy: 0.8739 - val_loss: 0.3466 - val_accuracy: 0.8649 - 1s/epoch - 6ms/step\n",
      "Epoch 985/1000\n",
      "181/181 - 1s - loss: 0.3064 - accuracy: 0.8731 - val_loss: 0.3310 - val_accuracy: 0.8789 - 954ms/epoch - 5ms/step\n",
      "Epoch 986/1000\n",
      "181/181 - 1s - loss: 0.3063 - accuracy: 0.8757 - val_loss: 0.3433 - val_accuracy: 0.8773 - 912ms/epoch - 5ms/step\n",
      "Epoch 987/1000\n",
      "181/181 - 1s - loss: 0.3066 - accuracy: 0.8752 - val_loss: 0.3259 - val_accuracy: 0.8758 - 929ms/epoch - 5ms/step\n",
      "Epoch 988/1000\n",
      "181/181 - 1s - loss: 0.3066 - accuracy: 0.8748 - val_loss: 0.3344 - val_accuracy: 0.8773 - 939ms/epoch - 5ms/step\n",
      "Epoch 989/1000\n",
      "181/181 - 1s - loss: 0.3072 - accuracy: 0.8746 - val_loss: 0.3291 - val_accuracy: 0.8696 - 1s/epoch - 6ms/step\n",
      "Epoch 990/1000\n",
      "181/181 - 1s - loss: 0.3056 - accuracy: 0.8767 - val_loss: 0.3259 - val_accuracy: 0.8773 - 956ms/epoch - 5ms/step\n",
      "Epoch 991/1000\n",
      "181/181 - 1s - loss: 0.3089 - accuracy: 0.8745 - val_loss: 0.3280 - val_accuracy: 0.8866 - 1s/epoch - 6ms/step\n",
      "Epoch 992/1000\n",
      "181/181 - 1s - loss: 0.3074 - accuracy: 0.8777 - val_loss: 0.3246 - val_accuracy: 0.8804 - 907ms/epoch - 5ms/step\n",
      "Epoch 993/1000\n",
      "181/181 - 1s - loss: 0.3054 - accuracy: 0.8815 - val_loss: 0.3292 - val_accuracy: 0.8804 - 911ms/epoch - 5ms/step\n",
      "Epoch 994/1000\n",
      "181/181 - 1s - loss: 0.3066 - accuracy: 0.8805 - val_loss: 0.3266 - val_accuracy: 0.8758 - 1s/epoch - 6ms/step\n",
      "Epoch 995/1000\n",
      "181/181 - 1s - loss: 0.3065 - accuracy: 0.8755 - val_loss: 0.3317 - val_accuracy: 0.8835 - 898ms/epoch - 5ms/step\n",
      "Epoch 996/1000\n",
      "181/181 - 1s - loss: 0.3061 - accuracy: 0.8741 - val_loss: 0.3390 - val_accuracy: 0.8727 - 884ms/epoch - 5ms/step\n",
      "Epoch 997/1000\n",
      "181/181 - 1s - loss: 0.3055 - accuracy: 0.8745 - val_loss: 0.3548 - val_accuracy: 0.8696 - 880ms/epoch - 5ms/step\n",
      "Epoch 998/1000\n",
      "181/181 - 1s - loss: 0.3071 - accuracy: 0.8776 - val_loss: 0.3313 - val_accuracy: 0.8851 - 879ms/epoch - 5ms/step\n",
      "Epoch 999/1000\n",
      "181/181 - 1s - loss: 0.3054 - accuracy: 0.8765 - val_loss: 0.3288 - val_accuracy: 0.8758 - 876ms/epoch - 5ms/step\n",
      "Epoch 1000/1000\n",
      "181/181 - 1s - loss: 0.3081 - accuracy: 0.8750 - val_loss: 0.3358 - val_accuracy: 0.8696 - 891ms/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x219e8b6b910>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( X_train,y_train,validation_data=(X_test,y_test),verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.04155264e-06, 4.61352849e-03, 1.31762701e-09, 1.95776639e-08,\n",
       "        1.79927088e-02, 9.77386653e-01],\n",
       "       [9.77200827e-08, 3.26351284e-08, 7.45643604e-07, 9.97607529e-01,\n",
       "        2.39149202e-03, 1.79546646e-07],\n",
       "       [9.90300464e-07, 0.00000000e+00, 3.07813241e-18, 9.99988377e-01,\n",
       "        1.06414645e-05, 6.07837790e-28],\n",
       "       [7.87383760e-05, 3.16001594e-01, 5.99923611e-01, 6.57531141e-09,\n",
       "        2.05015294e-06, 8.39940533e-02],\n",
       "       [2.57294300e-06, 3.47643252e-03, 8.49537996e-10, 3.50768137e-10,\n",
       "        1.79111061e-03, 9.94729877e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 3, 2, 5], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "argmax = np.argmax(y_pred,axis=1)\n",
    "argmax[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['very damp grey soil', 'red soil', 'red soil', 'grey soil',\n",
       "       'very damp grey soil'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_original = lbcode.inverse_transform(argmax)\n",
    "y_pred_original[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 0.3358 \n",
      "Test acc = 0.8696 \n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test,verbose=0)\n",
    "print('Test loss = {:.4f} '.format(loss))\n",
    "print('Test acc = {:.4f} '.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score:0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "print(f'Accuracy_score: {accuracy_score(y_test, argmax)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9801608342603786\n",
      "0.9797704335445243\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, y_pred,multi_class='ovr'))\n",
    "print(roc_auc_score(y_test, y_pred,multi_class='ovo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fv-HEIkBDBT4"
   },
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxs4paN5DBT4"
   },
   "source": [
    "If we continue to train the network, it may overfit. We can have a stop point where the accuracy may start falling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkNQAiUhDBT4"
   },
   "source": [
    "**Model Definition:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PqIjqfF8DBT4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tf.random.set_seed(2021)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(7, activation='relu',input_shape=(X_train.shape[1], )), \n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWScoC71DBT4"
   },
   "source": [
    "**Model Fitting:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cCXykJ1DBT4",
    "outputId": "5d879560-261f-4175-b7e2-b65cf664ffd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "181/181 - 4s - loss: 1.6567 - accuracy: 0.2179 - val_loss: 1.5813 - val_accuracy: 0.2547 - 4s/epoch - 21ms/step\n",
      "Epoch 2/1000\n",
      "181/181 - 1s - loss: 1.5307 - accuracy: 0.2892 - val_loss: 1.4785 - val_accuracy: 0.3121 - 839ms/epoch - 5ms/step\n",
      "Epoch 3/1000\n",
      "181/181 - 1s - loss: 1.4244 - accuracy: 0.4362 - val_loss: 1.3720 - val_accuracy: 0.4876 - 825ms/epoch - 5ms/step\n",
      "Epoch 4/1000\n",
      "181/181 - 1s - loss: 1.3009 - accuracy: 0.5745 - val_loss: 1.2389 - val_accuracy: 0.6413 - 829ms/epoch - 5ms/step\n",
      "Epoch 5/1000\n",
      "181/181 - 1s - loss: 1.1469 - accuracy: 0.6444 - val_loss: 1.0871 - val_accuracy: 0.6724 - 845ms/epoch - 5ms/step\n",
      "Epoch 6/1000\n",
      "181/181 - 1s - loss: 0.9985 - accuracy: 0.7007 - val_loss: 0.9680 - val_accuracy: 0.7081 - 1s/epoch - 6ms/step\n",
      "Epoch 7/1000\n",
      "181/181 - 1s - loss: 0.8932 - accuracy: 0.7275 - val_loss: 0.8816 - val_accuracy: 0.7453 - 1s/epoch - 6ms/step\n",
      "Epoch 8/1000\n",
      "181/181 - 1s - loss: 0.8226 - accuracy: 0.7531 - val_loss: 0.8236 - val_accuracy: 0.7748 - 1s/epoch - 6ms/step\n",
      "Epoch 9/1000\n",
      "181/181 - 1s - loss: 0.7674 - accuracy: 0.7753 - val_loss: 0.7787 - val_accuracy: 0.7842 - 1s/epoch - 6ms/step\n",
      "Epoch 10/1000\n",
      "181/181 - 1s - loss: 0.7245 - accuracy: 0.7812 - val_loss: 0.7457 - val_accuracy: 0.7857 - 984ms/epoch - 5ms/step\n",
      "Epoch 11/1000\n",
      "181/181 - 1s - loss: 0.6895 - accuracy: 0.7824 - val_loss: 0.7144 - val_accuracy: 0.7857 - 946ms/epoch - 5ms/step\n",
      "Epoch 12/1000\n",
      "181/181 - 1s - loss: 0.6612 - accuracy: 0.7855 - val_loss: 0.6894 - val_accuracy: 0.7873 - 941ms/epoch - 5ms/step\n",
      "Epoch 13/1000\n",
      "181/181 - 1s - loss: 0.6414 - accuracy: 0.7904 - val_loss: 0.6738 - val_accuracy: 0.7873 - 959ms/epoch - 5ms/step\n",
      "Epoch 14/1000\n",
      "181/181 - 1s - loss: 0.6197 - accuracy: 0.7954 - val_loss: 0.6603 - val_accuracy: 0.7919 - 941ms/epoch - 5ms/step\n",
      "Epoch 15/1000\n",
      "181/181 - 1s - loss: 0.6028 - accuracy: 0.7959 - val_loss: 0.6476 - val_accuracy: 0.7919 - 829ms/epoch - 5ms/step\n",
      "Epoch 16/1000\n",
      "181/181 - 1s - loss: 0.5874 - accuracy: 0.7983 - val_loss: 0.6207 - val_accuracy: 0.7904 - 843ms/epoch - 5ms/step\n",
      "Epoch 17/1000\n",
      "181/181 - 1s - loss: 0.5695 - accuracy: 0.8045 - val_loss: 0.6097 - val_accuracy: 0.7997 - 829ms/epoch - 5ms/step\n",
      "Epoch 18/1000\n",
      "181/181 - 1s - loss: 0.5581 - accuracy: 0.8063 - val_loss: 0.5911 - val_accuracy: 0.8012 - 830ms/epoch - 5ms/step\n",
      "Epoch 19/1000\n",
      "181/181 - 1s - loss: 0.5419 - accuracy: 0.8126 - val_loss: 0.5779 - val_accuracy: 0.8059 - 861ms/epoch - 5ms/step\n",
      "Epoch 20/1000\n",
      "181/181 - 1s - loss: 0.5308 - accuracy: 0.8156 - val_loss: 0.5659 - val_accuracy: 0.8121 - 829ms/epoch - 5ms/step\n",
      "Epoch 21/1000\n",
      "181/181 - 1s - loss: 0.5180 - accuracy: 0.8199 - val_loss: 0.5598 - val_accuracy: 0.8214 - 829ms/epoch - 5ms/step\n",
      "Epoch 22/1000\n",
      "181/181 - 1s - loss: 0.5061 - accuracy: 0.8221 - val_loss: 0.5439 - val_accuracy: 0.8152 - 828ms/epoch - 5ms/step\n",
      "Epoch 23/1000\n",
      "181/181 - 1s - loss: 0.4973 - accuracy: 0.8247 - val_loss: 0.5320 - val_accuracy: 0.8230 - 830ms/epoch - 5ms/step\n",
      "Epoch 24/1000\n",
      "181/181 - 1s - loss: 0.4882 - accuracy: 0.8251 - val_loss: 0.5247 - val_accuracy: 0.8261 - 830ms/epoch - 5ms/step\n",
      "Epoch 25/1000\n",
      "181/181 - 1s - loss: 0.4804 - accuracy: 0.8299 - val_loss: 0.5197 - val_accuracy: 0.8230 - 834ms/epoch - 5ms/step\n",
      "Epoch 26/1000\n",
      "181/181 - 1s - loss: 0.4734 - accuracy: 0.8323 - val_loss: 0.5118 - val_accuracy: 0.8276 - 861ms/epoch - 5ms/step\n",
      "Epoch 27/1000\n",
      "181/181 - 1s - loss: 0.4650 - accuracy: 0.8351 - val_loss: 0.5030 - val_accuracy: 0.8307 - 830ms/epoch - 5ms/step\n",
      "Epoch 28/1000\n",
      "181/181 - 1s - loss: 0.4612 - accuracy: 0.8373 - val_loss: 0.4982 - val_accuracy: 0.8307 - 828ms/epoch - 5ms/step\n",
      "Epoch 29/1000\n",
      "181/181 - 1s - loss: 0.4539 - accuracy: 0.8379 - val_loss: 0.4907 - val_accuracy: 0.8292 - 833ms/epoch - 5ms/step\n",
      "Epoch 30/1000\n",
      "181/181 - 1s - loss: 0.4501 - accuracy: 0.8373 - val_loss: 0.4916 - val_accuracy: 0.8401 - 829ms/epoch - 5ms/step\n",
      "Epoch 31/1000\n",
      "181/181 - 1s - loss: 0.4425 - accuracy: 0.8406 - val_loss: 0.4806 - val_accuracy: 0.8416 - 827ms/epoch - 5ms/step\n",
      "Epoch 32/1000\n",
      "181/181 - 1s - loss: 0.4395 - accuracy: 0.8429 - val_loss: 0.5001 - val_accuracy: 0.8323 - 844ms/epoch - 5ms/step\n",
      "Epoch 33/1000\n",
      "181/181 - 1s - loss: 0.4351 - accuracy: 0.8439 - val_loss: 0.4758 - val_accuracy: 0.8401 - 839ms/epoch - 5ms/step\n",
      "Epoch 34/1000\n",
      "181/181 - 1s - loss: 0.4343 - accuracy: 0.8456 - val_loss: 0.4803 - val_accuracy: 0.8416 - 827ms/epoch - 5ms/step\n",
      "Epoch 35/1000\n",
      "181/181 - 1s - loss: 0.4310 - accuracy: 0.8460 - val_loss: 0.4694 - val_accuracy: 0.8354 - 844ms/epoch - 5ms/step\n",
      "Epoch 36/1000\n",
      "181/181 - 1s - loss: 0.4253 - accuracy: 0.8467 - val_loss: 0.4634 - val_accuracy: 0.8401 - 903ms/epoch - 5ms/step\n",
      "Epoch 37/1000\n",
      "181/181 - 1s - loss: 0.4237 - accuracy: 0.8477 - val_loss: 0.4626 - val_accuracy: 0.8494 - 884ms/epoch - 5ms/step\n",
      "Epoch 38/1000\n",
      "181/181 - 1s - loss: 0.4204 - accuracy: 0.8515 - val_loss: 0.4637 - val_accuracy: 0.8401 - 881ms/epoch - 5ms/step\n",
      "Epoch 39/1000\n",
      "181/181 - 1s - loss: 0.4172 - accuracy: 0.8484 - val_loss: 0.4534 - val_accuracy: 0.8463 - 857ms/epoch - 5ms/step\n",
      "Epoch 40/1000\n",
      "181/181 - 1s - loss: 0.4164 - accuracy: 0.8451 - val_loss: 0.4796 - val_accuracy: 0.8354 - 871ms/epoch - 5ms/step\n",
      "Epoch 41/1000\n",
      "181/181 - 1s - loss: 0.4165 - accuracy: 0.8486 - val_loss: 0.4549 - val_accuracy: 0.8447 - 888ms/epoch - 5ms/step\n",
      "Epoch 42/1000\n",
      "181/181 - 1s - loss: 0.4093 - accuracy: 0.8492 - val_loss: 0.4513 - val_accuracy: 0.8416 - 832ms/epoch - 5ms/step\n",
      "Epoch 43/1000\n",
      "181/181 - 1s - loss: 0.4104 - accuracy: 0.8520 - val_loss: 0.4504 - val_accuracy: 0.8447 - 876ms/epoch - 5ms/step\n",
      "Epoch 44/1000\n",
      "181/181 - 1s - loss: 0.4083 - accuracy: 0.8499 - val_loss: 0.4453 - val_accuracy: 0.8478 - 925ms/epoch - 5ms/step\n",
      "Epoch 45/1000\n",
      "181/181 - 1s - loss: 0.4054 - accuracy: 0.8532 - val_loss: 0.4538 - val_accuracy: 0.8447 - 829ms/epoch - 5ms/step\n",
      "Epoch 46/1000\n",
      "181/181 - 1s - loss: 0.4029 - accuracy: 0.8524 - val_loss: 0.4640 - val_accuracy: 0.8370 - 831ms/epoch - 5ms/step\n",
      "Epoch 47/1000\n",
      "181/181 - 1s - loss: 0.4011 - accuracy: 0.8511 - val_loss: 0.4342 - val_accuracy: 0.8509 - 865ms/epoch - 5ms/step\n",
      "Epoch 48/1000\n",
      "181/181 - 1s - loss: 0.3970 - accuracy: 0.8532 - val_loss: 0.4338 - val_accuracy: 0.8432 - 884ms/epoch - 5ms/step\n",
      "Epoch 49/1000\n",
      "181/181 - 1s - loss: 0.3988 - accuracy: 0.8525 - val_loss: 0.4417 - val_accuracy: 0.8416 - 874ms/epoch - 5ms/step\n",
      "Epoch 50/1000\n",
      "181/181 - 1s - loss: 0.3956 - accuracy: 0.8551 - val_loss: 0.4263 - val_accuracy: 0.8509 - 1s/epoch - 6ms/step\n",
      "Epoch 51/1000\n",
      "181/181 - 1s - loss: 0.3928 - accuracy: 0.8548 - val_loss: 0.4233 - val_accuracy: 0.8463 - 988ms/epoch - 5ms/step\n",
      "Epoch 52/1000\n",
      "181/181 - 1s - loss: 0.3934 - accuracy: 0.8543 - val_loss: 0.4289 - val_accuracy: 0.8571 - 1s/epoch - 6ms/step\n",
      "Epoch 53/1000\n",
      "181/181 - 1s - loss: 0.3892 - accuracy: 0.8539 - val_loss: 0.4223 - val_accuracy: 0.8494 - 896ms/epoch - 5ms/step\n",
      "Epoch 54/1000\n",
      "181/181 - 1s - loss: 0.3884 - accuracy: 0.8508 - val_loss: 0.4202 - val_accuracy: 0.8556 - 893ms/epoch - 5ms/step\n",
      "Epoch 55/1000\n",
      "181/181 - 1s - loss: 0.3851 - accuracy: 0.8544 - val_loss: 0.4256 - val_accuracy: 0.8525 - 865ms/epoch - 5ms/step\n",
      "Epoch 56/1000\n",
      "181/181 - 1s - loss: 0.3891 - accuracy: 0.8525 - val_loss: 0.4297 - val_accuracy: 0.8463 - 869ms/epoch - 5ms/step\n",
      "Epoch 57/1000\n",
      "181/181 - 1s - loss: 0.3831 - accuracy: 0.8574 - val_loss: 0.4389 - val_accuracy: 0.8354 - 858ms/epoch - 5ms/step\n",
      "Epoch 58/1000\n",
      "181/181 - 1s - loss: 0.3825 - accuracy: 0.8579 - val_loss: 0.4163 - val_accuracy: 0.8478 - 836ms/epoch - 5ms/step\n",
      "Epoch 59/1000\n",
      "181/181 - 1s - loss: 0.3809 - accuracy: 0.8555 - val_loss: 0.4113 - val_accuracy: 0.8587 - 835ms/epoch - 5ms/step\n",
      "Epoch 60/1000\n",
      "181/181 - 1s - loss: 0.3792 - accuracy: 0.8548 - val_loss: 0.4061 - val_accuracy: 0.8525 - 864ms/epoch - 5ms/step\n",
      "Epoch 61/1000\n",
      "181/181 - 1s - loss: 0.3782 - accuracy: 0.8591 - val_loss: 0.4220 - val_accuracy: 0.8494 - 962ms/epoch - 5ms/step\n",
      "Epoch 62/1000\n",
      "181/181 - 1s - loss: 0.3795 - accuracy: 0.8551 - val_loss: 0.4043 - val_accuracy: 0.8571 - 919ms/epoch - 5ms/step\n",
      "Epoch 63/1000\n",
      "181/181 - 1s - loss: 0.3766 - accuracy: 0.8586 - val_loss: 0.4023 - val_accuracy: 0.8525 - 1s/epoch - 6ms/step\n",
      "Epoch 64/1000\n",
      "181/181 - 1s - loss: 0.3730 - accuracy: 0.8582 - val_loss: 0.4065 - val_accuracy: 0.8525 - 1s/epoch - 6ms/step\n",
      "Epoch 65/1000\n",
      "181/181 - 1s - loss: 0.3717 - accuracy: 0.8581 - val_loss: 0.4014 - val_accuracy: 0.8587 - 914ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000\n",
      "181/181 - 1s - loss: 0.3714 - accuracy: 0.8584 - val_loss: 0.4084 - val_accuracy: 0.8509 - 836ms/epoch - 5ms/step\n",
      "Epoch 67/1000\n",
      "181/181 - 1s - loss: 0.3694 - accuracy: 0.8591 - val_loss: 0.3997 - val_accuracy: 0.8571 - 834ms/epoch - 5ms/step\n",
      "Epoch 68/1000\n",
      "181/181 - 1s - loss: 0.3689 - accuracy: 0.8586 - val_loss: 0.3990 - val_accuracy: 0.8540 - 833ms/epoch - 5ms/step\n",
      "Epoch 69/1000\n",
      "181/181 - 1s - loss: 0.3691 - accuracy: 0.8625 - val_loss: 0.3931 - val_accuracy: 0.8478 - 833ms/epoch - 5ms/step\n",
      "Epoch 70/1000\n",
      "181/181 - 1s - loss: 0.3670 - accuracy: 0.8608 - val_loss: 0.4134 - val_accuracy: 0.8494 - 829ms/epoch - 5ms/step\n",
      "Epoch 71/1000\n",
      "181/181 - 1s - loss: 0.3689 - accuracy: 0.8581 - val_loss: 0.3935 - val_accuracy: 0.8509 - 831ms/epoch - 5ms/step\n",
      "Epoch 72/1000\n",
      "181/181 - 1s - loss: 0.3635 - accuracy: 0.8596 - val_loss: 0.4049 - val_accuracy: 0.8571 - 828ms/epoch - 5ms/step\n",
      "Epoch 73/1000\n",
      "181/181 - 1s - loss: 0.3665 - accuracy: 0.8582 - val_loss: 0.3877 - val_accuracy: 0.8478 - 903ms/epoch - 5ms/step\n",
      "Epoch 74/1000\n",
      "181/181 - 1s - loss: 0.3633 - accuracy: 0.8601 - val_loss: 0.3888 - val_accuracy: 0.8602 - 943ms/epoch - 5ms/step\n",
      "Epoch 75/1000\n",
      "181/181 - 1s - loss: 0.3638 - accuracy: 0.8639 - val_loss: 0.3892 - val_accuracy: 0.8525 - 941ms/epoch - 5ms/step\n",
      "Epoch 76/1000\n",
      "181/181 - 1s - loss: 0.3637 - accuracy: 0.8596 - val_loss: 0.3904 - val_accuracy: 0.8509 - 960ms/epoch - 5ms/step\n",
      "Epoch 77/1000\n",
      "181/181 - 1s - loss: 0.3606 - accuracy: 0.8615 - val_loss: 0.3916 - val_accuracy: 0.8556 - 947ms/epoch - 5ms/step\n",
      "Epoch 78/1000\n",
      "181/181 - 1s - loss: 0.3611 - accuracy: 0.8601 - val_loss: 0.3850 - val_accuracy: 0.8525 - 941ms/epoch - 5ms/step\n",
      "Epoch 79/1000\n",
      "181/181 - 1s - loss: 0.3578 - accuracy: 0.8641 - val_loss: 0.3894 - val_accuracy: 0.8602 - 951ms/epoch - 5ms/step\n",
      "Epoch 80/1000\n",
      "181/181 - 1s - loss: 0.3589 - accuracy: 0.8648 - val_loss: 0.3800 - val_accuracy: 0.8602 - 989ms/epoch - 5ms/step\n",
      "Epoch 81/1000\n",
      "181/181 - 1s - loss: 0.3578 - accuracy: 0.8629 - val_loss: 0.3957 - val_accuracy: 0.8478 - 876ms/epoch - 5ms/step\n",
      "Epoch 82/1000\n",
      "181/181 - 1s - loss: 0.3577 - accuracy: 0.8648 - val_loss: 0.3800 - val_accuracy: 0.8540 - 832ms/epoch - 5ms/step\n",
      "Epoch 83/1000\n",
      "181/181 - 1s - loss: 0.3610 - accuracy: 0.8613 - val_loss: 0.3802 - val_accuracy: 0.8571 - 833ms/epoch - 5ms/step\n",
      "Epoch 84/1000\n",
      "181/181 - 1s - loss: 0.3573 - accuracy: 0.8619 - val_loss: 0.3797 - val_accuracy: 0.8602 - 829ms/epoch - 5ms/step\n",
      "Epoch 85/1000\n",
      "181/181 - 1s - loss: 0.3558 - accuracy: 0.8646 - val_loss: 0.3764 - val_accuracy: 0.8556 - 836ms/epoch - 5ms/step\n",
      "Epoch 86/1000\n",
      "181/181 - 1s - loss: 0.3579 - accuracy: 0.8619 - val_loss: 0.3833 - val_accuracy: 0.8540 - 828ms/epoch - 5ms/step\n",
      "Epoch 87/1000\n",
      "181/181 - 1s - loss: 0.3530 - accuracy: 0.8658 - val_loss: 0.3756 - val_accuracy: 0.8587 - 937ms/epoch - 5ms/step\n",
      "Epoch 88/1000\n",
      "181/181 - 1s - loss: 0.3546 - accuracy: 0.8610 - val_loss: 0.3767 - val_accuracy: 0.8602 - 831ms/epoch - 5ms/step\n",
      "Epoch 89/1000\n",
      "181/181 - 1s - loss: 0.3518 - accuracy: 0.8636 - val_loss: 0.3800 - val_accuracy: 0.8525 - 830ms/epoch - 5ms/step\n",
      "Epoch 90/1000\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "181/181 - 1s - loss: 0.3501 - accuracy: 0.8655 - val_loss: 0.3789 - val_accuracy: 0.8556 - 866ms/epoch - 5ms/step\n",
      "Epoch 90: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto',\n",
    "        restore_best_weights=True)\n",
    "history = model.fit(X_train,y_train,validation_data=(X_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "X71Ri6ToDBT5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.3762105e-05, 3.4513686e-02, 1.0669038e-05, 1.6184011e-04,\n",
       "        1.0962557e-01, 8.5562450e-01],\n",
       "       [2.6579823e-09, 2.4922990e-04, 9.2511902e-05, 9.9794453e-01,\n",
       "        1.6949441e-03, 1.8720337e-05],\n",
       "       [1.0806624e-08, 1.8070019e-05, 5.5146381e-07, 9.8765868e-01,\n",
       "        1.2317667e-02, 5.0980598e-06],\n",
       "       [1.4104075e-05, 3.3962321e-01, 5.5053580e-01, 3.1584154e-06,\n",
       "        2.4586896e-05, 1.0979908e-01],\n",
       "       [3.5097295e-05, 3.0858142e-02, 7.9082974e-06, 6.4234038e-05,\n",
       "        5.9952643e-02, 9.0908188e-01]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xf4ZionDDBT5",
    "outputId": "99f2ebf3-41e1-4d8a-cb82-8be58c1891d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "3N5B7XzvDBT5",
    "outputId": "ee7a0d37-67ce-45e9-bfb9-ce644081bc46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.376211e-05</td>\n",
       "      <td>0.034514</td>\n",
       "      <td>1.066904e-05</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.109626</td>\n",
       "      <td>8.556245e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.657982e-09</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>9.251190e-05</td>\n",
       "      <td>0.997945</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>1.872034e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.080662e-08</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>5.514638e-07</td>\n",
       "      <td>0.987659</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>5.098060e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.410407e-05</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>5.505358e-01</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.097991e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.509730e-05</td>\n",
       "      <td>0.030858</td>\n",
       "      <td>7.908297e-06</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.059953</td>\n",
       "      <td>9.090819e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>4.453499e-11</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.243394e-07</td>\n",
       "      <td>0.999235</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>1.937975e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>2.635242e-02</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>7.521176e-05</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.933270</td>\n",
       "      <td>1.313641e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>9.733419e-01</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>5.394261e-04</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.022671</td>\n",
       "      <td>1.391492e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>1.054806e-04</td>\n",
       "      <td>0.017711</td>\n",
       "      <td>6.798477e-06</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.717705</td>\n",
       "      <td>2.592608e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1.900585e-06</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>1.995109e-05</td>\n",
       "      <td>0.900601</td>\n",
       "      <td>0.098501</td>\n",
       "      <td>2.682062e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2         3         4             5\n",
       "0    6.376211e-05  0.034514  1.066904e-05  0.000162  0.109626  8.556245e-01\n",
       "1    2.657982e-09  0.000249  9.251190e-05  0.997945  0.001695  1.872034e-05\n",
       "2    1.080662e-08  0.000018  5.514638e-07  0.987659  0.012318  5.098060e-06\n",
       "3    1.410407e-05  0.339623  5.505358e-01  0.000003  0.000025  1.097991e-01\n",
       "4    3.509730e-05  0.030858  7.908297e-06  0.000064  0.059953  9.090819e-01\n",
       "..            ...       ...           ...       ...       ...           ...\n",
       "639  4.453499e-11  0.000002  1.243394e-07  0.999235  0.000763  1.937975e-07\n",
       "640  2.635242e-02  0.006066  7.521176e-05  0.021100  0.933270  1.313641e-02\n",
       "641  9.733419e-01  0.001917  5.394261e-04  0.000139  0.022671  1.391492e-03\n",
       "642  1.054806e-04  0.017711  6.798477e-06  0.005210  0.717705  2.592608e-01\n",
       "643  1.900585e-06  0.000608  1.995109e-05  0.900601  0.098501  2.682062e-04\n",
       "\n",
       "[644 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6RshO4JrXHGT",
    "outputId": "7aa9dcdc-81de-4eab-e3c2-4290aa62b18c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 3, 2, 5], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "argmax = np.argmax(y_pred,axis=1)\n",
    "argmax[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['very damp grey soil', 'red soil', 'red soil', 'grey soil',\n",
       "       'very damp grey soil'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_original = lbcode.inverse_transform(argmax)\n",
    "y_pred_original[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 0.8555900621118012\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "print(f'Accuracy_score: {accuracy_score(y_test, argmax)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976199335059602\n",
      "0.9752917418640833\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, y_pred,multi_class='ovr'))\n",
    "print(roc_auc_score(y_test, y_pred,multi_class='ovo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-50LFLdDBT6",
    "outputId": "3a13b55a-d2f2-48fb-fc2b-af9e8fa9d5c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 0.3764 \n",
      "Test acc = 0.8556 \n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test,verbose=0)\n",
    "print('Test loss = {:.4f} '.format(loss))\n",
    "print('Test acc = {:.4f} '.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voFhstyVDBT6"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Multi-Class Classification - Label Encoding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
